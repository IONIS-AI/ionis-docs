{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"IONIS Sovereign AI Lab","text":"<p>\"The logs have been speaking for decades, but nobody is listening.\"</p> <p>Every day, millions of radio contacts are logged \u2014 WSPR beacons, RBN spots, contest QSOs, PSK Reporter decodes. They contain the ground truth of HF propagation: what actually worked, when, and under what conditions. Until now, that data sat in archives, unused for prediction.</p>"},{"location":"#what-is-ionis","title":"What is IONIS?","text":"<p>IONIS (Ionospheric Neural Inference System) is a machine learning engine that predicts HF radio propagation using real-world observations instead of theoretical models.</p> <p>IONIS answers one question: \"Can I work this path right now, on my mode?\"</p> <p>One model predicts the signal level. A mode-aware threshold layer converts that into operational verdicts for six mode families \u2014 from WSPR at -28 dB to SSB at +5 dB. One forward pass, six answers.</p>"},{"location":"#building-on-traditional-prediction","title":"Building on Traditional Prediction","text":"<p>Tools like VOACAP represent decades of ionospheric research and remain valuable references. But they have inherent limitations:</p> <ul> <li>Static models: Based on historical averages, updated infrequently</li> <li>Single-mode focus: Designed for SSB voice circuits, with no concept of digital mode thresholds</li> <li>Limited validation: No feedback loop \u2014 predictions are never checked against observations</li> <li>Coarse resolution: Monthly medians miss daily and hourly variations</li> </ul> <p>When FT8 operators use VOACAP and find \"closed\" paths that are wide open at -20 dB, that's not a VOACAP bug \u2014 it was never designed for the digital world.</p> <p>IONIS extends VOACAP's legacy by adding what it lacks: mode-aware thresholds, continuous learning from real-world observations, and a closed-loop feedback cycle. The two approaches validate each other \u2014 physics models provide theoretical grounding, while observational data reveals what actually happens.</p>"},{"location":"#the-ionis-approach","title":"The IONIS Approach","text":"<p>IONIS is built on four pillars:</p> <ol> <li>Massive observational data: 14B+ radio contacts from four independent networks (WSPR, RBN, contest logs, and PSK Reporter)</li> <li>Neural network with physics constraints: The model can't violate known ionospheric physics</li> <li>Mode-aware prediction: One SNR prediction yields six operational verdicts (WSPR, FT8, CW, RTTY, SSB)</li> <li>Closed-loop validation: Live PSK Reporter data continuously scores the model against observations it has never seen</li> </ol> <p>The model predicts signal-to-noise ratio \u2014 a physical quantity that is mode-agnostic. The threshold layer applies mode-specific decode limits to determine operational viability. The physics doesn't change by mode; only the minimum signal required to use it does.</p>"},{"location":"#current-status","title":"Current Status","text":"<p>IONIS V22-gamma + PhysicsOverrideLayer is the production model. Trained on 20M WSPR + 4.55M DXpedition (50x) + 6.34M Contest signatures (~31M rows), with a deterministic post-inference clamp for high-band night closure. It correctly predicts:</p> <ul> <li>Higher solar flux (SFI) improves propagation (monotonic)</li> <li>Geomagnetic storms (Kp) degrade propagation (monotonic)</li> <li>Path geometry, time of day, seasonal effects, and solar depression angle</li> <li>High-band closure at night (PhysicsOverrideLayer)</li> </ul> Metric Value Pearson correlation +0.492 RMSE 0.821\u03c3 (~5.5 dB) KI7MT operator tests 17/17 PASS TST-900 band x time 9/11 Parameters 205,621 <p>V22-gamma demonstrates consistent improvement over the ITS/NTIA reference model (VOACAP) on validated contest paths. PSK Reporter live validation confirms the model generalizes to data it has never seen. For digital modes (FT8, FT4, WSPR) and CW, IONIS provides predictions where no comparable reference model exists.</p>"},{"location":"#data-sources","title":"Data Sources","text":"Source Volume Mode Coverage Purpose WSPR 10.94B spots WSPR (-28 dB) Signal floor, continuous baseline RBN 2.26B spots CW, RTTY Machine-decoded SNR, DXpedition coverage Contest Logs 234M QSOs SSB, CW, RTTY, Digi Ground truth \u2014 proof the band was open PSK Reporter 514M+ spots (~26M/day, live) FT8, FT4, WSPR Real-time validation and future training Solar Indices 77K rows \u2014 SFI, Kp, SSN conditions (2000-2026)"},{"location":"#infrastructure","title":"Infrastructure","text":"<p>Self-hosted, no cloud dependencies:</p> Host Role Threadripper 9975WX Control node \u2014 ClickHouse, CUDA, Go pipelines Mac Studio M3 Ultra Sage node \u2014 PyTorch training EPYC 7302P Forge node \u2014 backup/replica"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Model \u2014 IonisGate architecture, training methodology, validation results</li> <li>Testing \u2014 Install, run, and report \u2014 beta testing for operators</li> <li>Pipeline Apps \u2014 WSPR, solar, contest, RBN, PSK Reporter ingesters</li> <li>DevOps \u2014 Hardware, pipeline runbook, operations</li> <li>About \u2014 Ethos, credits, data privacy</li> </ul>"},{"location":"#open-source","title":"Open Source","text":"<p>All code, data pipelines, and documentation are open source. The goal is a reproducible, verifiable propagation prediction system that anyone can run.</p> <p>Built by KI7MT. No cloud. No vendor lock-in. Just physics and data.</p>"},{"location":"about/","title":"About IONIS","text":"<p>IONIS is a scientific research project that studies ionospheric propagation using real-world amateur radio observations and physics-constrained machine learning. Built and maintained by Greg Beam, KI7MT.</p> <ul> <li>Ethos \u2014 Core principles and statement of intent</li> <li>Credits \u2014 Data sources, references, and acknowledgements</li> <li>Data Privacy \u2014 GDPR compliance and data authorization</li> </ul>"},{"location":"about/credits/","title":"Credits","text":"<p>This project exists because of the amateur radio community. Every observation in our dataset \u2014 13.18 billion and counting \u2014 was generated by a ham radio operator somewhere in the world, running a beacon, making a contact, or submitting a log. Without them, there is no data. Without the data, there is no IONIS.</p> <p>To every amateur radio operator who has ever transmitted a WSPR beacon, worked a contest, appeared on the Reverse Beacon Network, or shown up on PSK Reporter: thank you.</p>"},{"location":"about/credits/#data-sources","title":"Data Sources","text":"<ul> <li>Joe Taylor, K1JT \u2014 Creator of WSPR, WSJT, WSJT-X, and MAP65. Nobel Laureate   (Physics, 1993). The WSPR protocol and software that generates the observations   we study are his contributions to amateur radio.</li> <li>WSPRNet \u2014 The community-operated database that collects and   archives WSPR spot reports from operators worldwide.</li> <li>Reverse Beacon Network \u2014 N4ZR, PY1NB, VE3NEA, and   the global network of CW/RTTY skimmer operators who contribute spots.</li> <li>PSK Reporter \u2014 Created and operated by   Philip Gladstone, N1DQ. The largest real-time amateur radio reception   report network, with 27,000+ active monitors contributing millions of   FT8/FT4/WSPR spots daily. The MQTT real-time feed that powers our   <code>pskr-collector</code> is provided by Tom Sevart, M0LTE \u2014 making the   full firehose of reception data available to the community.</li> <li>CQ Contest Logs \u2014 World Wide Radio Operators Foundation (WWROF)</li> <li>ARRL Contest Logs \u2014 American Radio Relay League</li> <li>GFZ Potsdam \u2014 Helmholtz Centre Potsdam, German Research Centre for   Geosciences. Solar and geomagnetic indices (SSN, SFI, Kp).</li> </ul>"},{"location":"about/credits/#references","title":"References","text":""},{"location":"about/credits/#propagation-models","title":"Propagation Models","text":"<ul> <li>VOACAP \u2014 Voice of America Coverage Analysis Program, originally developed by NTIA/ITS (Institute for Telecommunication Sciences). The standard HF propagation prediction engine since the 1980s.</li> <li>voacapl \u2014 Linux port of VOACAP by James Watson, HZ1JW. Method 30, CCIR coefficients.</li> <li>VOACAP Online \u2014 Web-based VOACAP interface by Jari Perkiomaki, OH6BG.</li> </ul>"},{"location":"about/credits/#solar-geomagnetic-data","title":"Solar &amp; Geomagnetic Data","text":"<ul> <li>NOAA Space Weather Prediction Center \u2014 Real-time F10.7 solar flux, planetary Kp index, GOES X-ray flux.</li> <li>SIDC \u2014 Royal Observatory of Belgium \u2014 World Data Center for sunspot numbers (1749-present).</li> <li>GFZ Potsdam \u2014 Definitive Kp, ap, and Ap indices; composite SSN/SFI file (1932-present). See Data Sources above.</li> <li>Penticton / NRC \u2014 Dominion Radio Astrophysical Observatory, National Research Council Canada. The world's primary 10.7 cm solar flux measurement station.</li> </ul>"},{"location":"about/credits/#data-standards","title":"Data Standards","text":"<ul> <li>ADIF \u2014 Amateur Data Interchange Format. Band ID numbering used throughout the pipeline.</li> <li>Cabrillo \u2014 Contest log submission format (V2/V3), maintained by WWROF.</li> <li>Maidenhead Locator System \u2014 Grid square system for geographic coordinates in amateur radio.</li> </ul>"},{"location":"about/credits/#contest-dxpedition-organizations","title":"Contest &amp; DXpedition Organizations","text":"<ul> <li>WWROF \u2014 World Wide Radio Operators Foundation. Sponsors CQ WW, CQ WPX, and maintains the Cabrillo specification.</li> <li>ARRL \u2014 American Radio Relay League. Sponsors ARRL DX, Sweepstakes, RTTY Roundup, and other contest series.</li> <li>IARU \u2014 International Amateur Radio Union. Sponsors the IARU HF World Championship.</li> <li>GDXF Mega DXpeditions Honor Roll \u2014 Curated catalog of major DXpeditions by Bernd, DF3CB. Source for the dxpedition training data chain.</li> </ul>"},{"location":"about/credits/#regulatory","title":"Regulatory","text":"<ul> <li>ITU Radio Regulations \u2014 International Telecommunication Union. Governing framework for amateur radio spectrum allocation.</li> <li>FCC 47 CFR 97.119 \u2014 Station identification requirements for US amateur radio.</li> </ul>"},{"location":"about/credits/#giving-back","title":"Giving Back","text":"<p>When we publish results, we share our findings with the data providers and the amateur radio community \u2014 including the RBN community, who have asked that researchers share their analysis back. We are happy to do so.</p>"},{"location":"about/data-privacy/","title":"Data Privacy and GDPR Statement","text":""},{"location":"about/data-privacy/#our-position","title":"Our Position","text":"<p>IONIS is a scientific research project that studies ionospheric propagation patterns using publicly available amateur radio observations. We have zero interest in personal data. We study propagation paths between grid squares, not the operators who generated them.</p> <p>There is no commercial motive behind IONIS. There is no monetization plan. There is no startup. This is real research, built to provide a badly needed tool for the public and the greater ham radio community at large.</p> <p>All IONIS tools, models, and research results are free to the public under the GNU General Public License v3 (GPLv3). We credit every data source, share our insights back to the community, and redistribute only derived works (models and aggregated signatures) \u2014 never raw data.</p>"},{"location":"about/data-privacy/#data-sources-and-authorization","title":"Data Sources and Authorization","text":"<p>All source data used by IONIS is publicly available, provided by community organizations for public use, and downloaded with the explicit or implied consent of the data providers.</p> Source Authorization Policy WSPRNet Public archive, no restrictions \"The data collected are available to the public through this site\" Reverse Beacon Network Public, share results back (voluntary) \"Data from the RBN are freely available for study and analysis\" CQ Contest Logs Entrant consent to public posting CQ WW Rules Section XIII: entrants \"agreed the log entry may be made open to the public\" ARRL Contest Logs Publicly posted, no restriction found Logs published at contests.arrl.org since 2018; no terms prohibiting research use <p>Full details: WSPRNet Downloads | RBN Raw Data | CQ WW Public Logs | ARRL Public Logs</p>"},{"location":"about/data-privacy/#gdpr-compliance","title":"GDPR Compliance","text":""},{"location":"about/data-privacy/#why-callsigns-appear-in-our-pipeline","title":"Why Callsigns Appear in Our Pipeline","text":"<p>Amateur radio callsigns appear in the bronze (raw ingest) and silver (enrichment) layers of our data pipeline for one reason only: to link an observation to a geographic grid square when the source record does not include one directly (e.g., Reverse Beacon Network spots contain no grid square \u2014 only a callsign and DXCC prefix). This is the Rosetta Stone's sole function.</p> <p>By the time data reaches the gold layer (training-ready, model-facing), all callsigns have been removed. The model receives only: grid-pair, band, time of day, month, solar flux index (SFI), geomagnetic index (Kp), distance, and bearing. No callsign, no name, no address, no personal identifier of any kind.</p>"},{"location":"about/data-privacy/#gdpr-analysis","title":"GDPR Analysis","text":"<p>We have assessed our data processing against the EU General Data Protection Regulation (GDPR) and believe our use is compliant on multiple independent grounds:</p> <p>1. Anonymization (Recital 26)</p> <p>GDPR Recital 26 states: \"The principles of data protection should therefore not apply to anonymous information, namely information which does not relate to an identified or identifiable natural person or to personal data rendered anonymous in such a manner that the data subject is not or no longer identifiable. This Regulation does not therefore concern the processing of such anonymous information, including for statistical or research purposes.\"</p> <p>Our gold-layer output is anonymous by design. Callsigns are stripped. Grid squares are 4-character Maidenhead locators representing areas of approximately 100 km x 200 km \u2014 far too coarse to identify any individual. The model's input and output contain no personal data whatsoever.</p> <p>2. Publicly Available Data, Voluntarily Disclosed</p> <p>Every observation in our dataset was voluntarily made public by the operator:</p> <ul> <li>WSPR beacons are transmitted over public radio frequencies specifically to be   received and reported by anyone. Operators configure their software to upload   spots to WSPRNet's public database. This is a deliberate, affirmative act of   publication.</li> <li>RBN spots are machine-decoded from public radio transmissions. CW and RTTY   signals are broadcast on public amateur radio frequencies. The Reverse Beacon   Network provides these observations as a public service.</li> <li>Contest logs are submitted by operators who explicitly consent to public   posting. CQ WW rules require entrants to agree their \"log entry may be made   open to the public\" as a condition of participation. ARRL posts submitted logs   publicly at contests.arrl.org.</li> </ul> <p>Amateur radio is, by its nature, a public service. ITU Radio Regulations and national licensing authorities (FCC 47 CFR 97.119, Ofcom, BNetzA, etc.) require operators to identify themselves with their callsign during every transmission. Callsigns are broadcast over the air, published in national licensing databases, and printed in callbooks that have been publicly available for over 70 years. There is no expectation of privacy for amateur radio callsigns.</p> <p>3. Scientific Research Purpose (Article 89)</p> <p>GDPR Article 89 provides safeguards and derogations for processing personal data for scientific or historical research purposes and statistical purposes, provided appropriate technical and organizational measures are in place \u2014 particularly the principle of data minimization. Our pipeline exemplifies this:</p> <ul> <li>Callsigns are used only where necessary (grid resolution in silver layer)</li> <li>Callsigns are stripped as early as possible (before gold layer)</li> <li>The model never receives any personal identifier</li> <li>We do not attempt to identify, profile, or contact any individual</li> <li>Our purpose is exclusively scientific: understanding ionospheric propagation</li> </ul> <p>4. Data Minimization in Practice</p> <p>Our medallion architecture enforces data minimization structurally:</p> Layer Contains Callsigns? Purpose Bronze (raw ingest) Yes \u2014 as received from source Immutable archive, never modified Silver (enriched) Yes \u2014 used for grid resolution Cross-source validation, temporal grid matching Gold (training-ready) No Aggregated signatures: grid-pair, band, time, solar, SNR <p>The callsign does its job in the silver layer (linking observations to grids) and is permanently left behind. By the time any data touches the neural network, it contains only physics \u2014 no person.</p>"},{"location":"about/data-privacy/#what-we-do-not-do","title":"What We Do Not Do","text":"<ul> <li>We do not collect data directly from individuals</li> <li>We do not attempt to identify, track, or profile any operator</li> <li>We do not correlate callsigns with names, addresses, or other PII</li> <li>We do not redistribute raw data containing callsigns</li> <li>We do not use callsign data for any commercial purpose</li> <li>We do not store callsign data beyond what the public source already provides</li> <li>We do not contact operators based on data in our pipeline</li> </ul>"},{"location":"about/data-privacy/#what-we-redistribute","title":"What We Redistribute","text":"<p>We redistribute only:</p> <ul> <li>Open source tools (GPLv3) \u2014 ingesters, parsers, training scripts</li> <li>Trained model weights \u2014 callsign-free, anonymous</li> <li>Aggregated signature vectors \u2014 callsign-free, anonymous</li> <li>Published research results \u2014 shared with data providers and the public</li> </ul> <p>We do not redistribute raw WSPR spots, RBN spots, or contest logs. Anyone wanting the source data should download it from the original providers.</p>"},{"location":"about/data-privacy/#contact","title":"Contact","text":"<p>Questions about our data handling practices can be directed to:</p> <ul> <li>Greg Beam, KI7MT \u2014 Project lead</li> <li>Email: See QRZ.com listing for KI7MT</li> </ul> <p>Last updated: 2026-02-08 Status: Living Document</p>"},{"location":"about/ethos/","title":"The Sovereign AI Lab Ethos","text":"<p>The IONIS exists to advance the understanding of High Frequency (HF) radio propagation through the ethical application of deep learning. We view the amateur radio spectrum not just as a hobbyist playground, but as a massive, distributed scientific instrument.</p> <p>Our work is guided by five core principles that ensure our research remains accessible, reproducible, and beneficial to the global amateur radio community.</p>"},{"location":"about/ethos/#1-sovereign-infrastructure","title":"1. Sovereign Infrastructure","text":"<p>\"We own the stack, so the community can trust the result.\"</p> <p>We believe that scientific infrastructure should not depend on transient cloud credits or proprietary APIs.</p> <ul> <li>Local First: Our models (IONIS) and datasets are built on local silicon (Apple Silicon / Threadripper) using open-source storage (ZFS).</li> <li>No Black Boxes: We do not use closed-source AI APIs to generate our physics. Every weight in our neural networks is trained on data we hold, using code we wrote, which anyone can inspect.</li> <li>Long-Term Archival: We build systems designed to store propagation history for decades, independent of corporate roadmaps.</li> </ul>"},{"location":"about/ethos/#2-ethical-data-stewardship","title":"2. Ethical Data Stewardship","text":"<p>\"We are guests in the house of data.\"</p> <p>The datasets we rely on\u2014WSPR, RBN, and Contest Logs\u2014are the collective memory of the amateur radio community. We treat them with reverence.</p> <ul> <li>The Good Neighbor Policy: Our ingestion tools (<code>contest-download</code>, <code>rbn-download</code>) are designed to be polite. We enforce rate limits, identify ourselves honestly in User-Agents, and never hammer a volunteer-run server.</li> <li>Preservation: We do not just scrape; we archive. Our ZFS compression strategies are designed to preserve the \"Ground Truth\" of radio history efficiently, ensuring it is never lost.</li> <li>Attribution: We rigorously acknowledge the sources of our data (WWROF, WSPRnet, RBN) in every publication and model release.</li> </ul>"},{"location":"about/ethos/#3-physics-first-machine-learning","title":"3. Physics-First Machine Learning","text":"<p>\"The model must obey the Ionosphere.\"</p> <p>We do not simply throw data at a neural network and hope for a pattern. We engineer our models to respect the laws of physics.</p> <ul> <li>Constrained Architectures: We use Monotonic Constraints and Physics Sidecars to ensure our models cannot \"hallucinate\" unphysical outcomes (e.g., higher Solar Flux should not degrade HF propagation).</li> <li>Digital Twinning: Our goal is not just prediction, but simulation. We strive to create a \"Digital Twin\" of the ionosphere that behaves like the real thing.</li> </ul>"},{"location":"about/ethos/#4-reproducible-science","title":"4. Reproducible Science","text":"<p>\"If you can't rebuild it, it isn't science.\"</p> <p>A model is useless if only one person can run it.</p> <ul> <li>Open by Default: Our code, training pipelines, and documentation are open source.</li> <li>Deterministic Training: We log our seeds, hyperparameters, and dataset versions so that any researcher can reproduce our \"Platinum Burn\" results bit-for-bit.</li> <li>Documentation as Code: We treat documentation with the same rigor as production code, ensuring that the \"How\" and \"Why\" are preserved alongside the \"What.\"</li> </ul>"},{"location":"about/ethos/#5-community-utility","title":"5. Community Utility","text":"<p>\"We build tools, not just papers.\"</p> <p>Our research must yield tangible value for the operator at the key.</p> <ul> <li>Mode-Aware Answers: IONIS answers the question every operator asks: \"Can I work this path right now, on my mode?\" One prediction yields verdicts for SSB, CW, RTTY, FT8, and WSPR \u2014 because the physics is the same, but the operational threshold is not.</li> <li>Actionable Intelligence: We move beyond \"average\" predictions to real-time, data-driven insights. A path that VOACAP calls \"closed\" may be wide open for FT8 \u2014 IONIS tells you that.</li> <li>Bridge Building: We actively work to bridge the gap between distinct data silos (mapping machine spots from WSPR/PSK Reporter to human logs from contests) to create a unified view of propagation.</li> </ul>"},{"location":"about/ethos/#statement-of-intent","title":"Statement of Intent","text":"<p>This is real research, built to serve the amateur radio community. There is no commercial motive. There is no monetization plan. There is no startup behind this. There is no angle in it for anyone.</p> <p>IONIS exists because the amateur radio community deserves a propagation prediction tool that actually learns from real observations \u2014 not one running on frozen coefficients from ionosonde measurements taken before most of us were born. The data has been sitting there for decades. The compute is cheap. What was missing was someone willing to do the curation work honestly, document the landmines, credit the sources, and give it all away.</p> <p>Everything we build is open source (GPLv3). Everything we learn is shared back. Every data source is credited. We redistribute tools and models, never raw data. We have zero interest in personal data \u2014 only the propagation paths it represents.</p> <p>If grants or donations come along to fund the continual improvement of this project, they will be accepted \u2014 but funding is not the goal. It sustains the work; it does not drive it. The project existed before any grant application and will continue regardless.</p> <p>Adopted: February 2026 Status: Living Document</p>"},{"location":"benchmarks/","title":"IONIS Lab","text":"<p>Performance benchmarks for the IONIS sovereign infrastructure \u2014 ingestion, query, and cross-system comparisons on 10.8 billion WSPR rows.</p>"},{"location":"benchmarks/#system-overview","title":"System Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              IONIS SOVEREIGN AI DATA CENTER                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502  INGEST \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6   STORE \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6   THINK                     \u2502\n\u2502                                                                 \u2502\n\u2502  Threadripper       ClickHouse        DeepSeek-R1-70B           \u2502\n\u2502  9975WX             10.8B rows        RTX PRO 6000              \u2502\n\u2502  24.67 Mrps         ~200 GB           96 GB VRAM                \u2502\n\u2502  3.5 GB/s writes    60 GB/s scan      ~15 tok/s                 \u2502\n\u2502                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Layer Component Capacity Verified Ingest wspr-turbo @ 24 workers 24.67 Mrps (3.5 GB/s) 2026-02-01 Store ClickHouse (wspr.bronze) 10.8B rows, 60 GB/s scan 2026-02-01 Think DeepSeek-R1-Distill-70B (FP8) 96 GB VRAM, ~15 tok/s 2026-02-02"},{"location":"benchmarks/#hardware","title":"Hardware","text":""},{"location":"benchmarks/#control-node-threadripper-9975wx","title":"Control Node \u2014 Threadripper 9975WX","text":"<p>Primary ingestion and query engine. This server forms the core of the lab.</p> Spec Value CPU AMD Threadripper PRO 9975WX (32C/64T, 5.3 GHz boost, Zen 5) RAM 128 GB DDR5 (8-channel, ~384 GB/s bandwidth) GPU NVIDIA RTX PRO 6000 Blackwell (96 GB VRAM) Boot Device Micron 7450 NVMe 980GB 22110 Primary Storage 2x Samsung 9100 Pro NVMe 4TB, 3.6 TB ClickHouse, 3.6 TB working data Bulk Storage HighPoint NVMe carrier with 4x Samsung 990 Pro 4 TB in a 2x2 ZFS Primary NIC Intel X710 4-Port 10Gbe DAC Spare NIC Mellanox ConnectIX-5 2-Port 25Gbe DAC OS Rocky Linux 9.7 <p>I/O is decoupled: source files on one NVMe, ClickHouse writes to a separate NVMe. No contention during ingestion.</p>"},{"location":"benchmarks/#sage-node-mac-studio-m3-ultra","title":"Sage Node \u2014 Mac Studio M3 Ultra","text":"<p>Model training and evaluation.</p> Spec Value SoC Apple M3 Ultra RAM 96 GB unified memory Backend PyTorch MPS Management NIC 1x 10Gbe LAB NIC Thunderbold 5 40Gbe Role V20 training (100 epochs in 4h 16m)"},{"location":"benchmarks/#forge-node-epyc-7302p","title":"Forge Node \u2014 EPYC 7302P","text":"<p>Backup, replica, and VM host (Proxmox).</p> Spec Value CPU AMD EPYC 7302P (16C/32T, 3.0 GHz base, Zen 2) RAM 128 GB DDR4-3200 ECC (8-channel, ~204 GB/s bandwidth) GPU NVIDIA RTX 5080 (16 GB VRAM) Boot Device Micron 7450 NVMe 980GB 22110 Primary NIC Intel X710 4-Port 10Gbe DAC Spare NIC Mellanox ConnectIX-5 2-Port 25Gbe DAC NVMe Storage 4x Samsung 970 EVO Plus 1 TB (NVMe mirror) SSD Storage LSI HBA 9300-8i, 8x Samsung 870 EVO 2 TB (RAIDZ2)"},{"location":"benchmarks/#storage-node-truenas","title":"Storage Node \u2014 TrueNAS","text":"<p>NAS for bulk archive storage.</p> Spec Value CPU AMD Ryzen 9 5950X (16C/32T, Zen 3) RAM 128 GB DDR4 ECC Boot Device 2x Samsung 870 EVO 1TB 2x2 Mirror Primary NIC Intel X710-DAC 4-Port 10Gbe DAC Storage 8x Seagate IronWolf Pro 14 TB (3-way + 4-way mirror, ~28 TB usable)"},{"location":"benchmarks/#dac-network","title":"DAC Network","text":"<p>All inter-node links are direct-attach 10 Gbps point-to-point with jumbo frames (MTU 9000). No switches.</p> Link Subnet Endpoints Latency Thunderbolt 5 <code>10.60.1.0/24</code> 9975WX \u2014 M3 Ultra ~0.19 ms x710 SFP+ AOC <code>10.60.2.0/24</code> 9975WX \u2014 Proxmox/EPYC ~0.12 ms x710 SFP+ AOC <code>10.60.3.0/24</code> 9975WX \u2014 TrueNAS ~0.03 ms"},{"location":"benchmarks/#zfs-archive-pool","title":"ZFS Archive Pool","text":"<p>HighPoint NVMe carrier with 4x Samsung 990 Pro 4 TB in a 2x2 ZFS mirror (~7.12 TB usable) on the 9975WX.</p> Dataset Compression Purpose <code>wspr-data</code> lz4 WSPR raw CSV archives (.csv.gz) <code>contest-logs</code> zstd-9 CQ contest Cabrillo logs <code>rbn-data</code> lz4 RBN daily ZIP archives <code>pskr-data</code> lz4 PSK Reporter MQTT collection (live)"},{"location":"benchmarks/#ingestion-benchmarks","title":"Ingestion Benchmarks","text":"<p>All benchmarks on 10.8 billion WSPR rows using ch-go native protocol with LZ4 wire compression.</p>"},{"location":"benchmarks/#threadripper-9975wx-champion-results","title":"Threadripper 9975WX \u2014 Champion Results","text":"<p>wspr-turbo (streaming from .gz archives):</p> Workers Time Throughput I/O Rate Effective Write Memory 16 7m 54s 22.77 Mrps 399 MB/s 1.74 GB/s 45.3 GB 24 7m 18s 24.67 Mrps 433 MB/s 1.88 GB/s 71.5 GB <p>wspr-shredder (pre-decompressed CSV, 878 GB):</p> Workers Time Throughput I/O Rate 24 8m 15s 21.81 Mrps ~1.81 GB/s <p>wspr-parquet-native (Parquet files, 109 GB):</p> Workers Time Throughput I/O Rate 24 9m 39s 17.02 Mrps 193 MB/s"},{"location":"benchmarks/#ingestion-leaderboard","title":"Ingestion Leaderboard","text":"Method Throughput Time Bottleneck Verdict wspr-turbo (gzip) 24.67 Mrps 7m 18s Database merge Champion wspr-shredder (CSV) 21.81 Mrps 8m 15s Database merge Runner-up wspr-parquet-native 17.02 Mrps 9m 39s Library overhead Slowest"},{"location":"benchmarks/#key-findings","title":"Key Findings","text":"<ul> <li>Compression is free. wspr-turbo (gzip) beats wspr-shredder (raw CSV)   because both hit the same ClickHouse merge ceiling at ~3.5 GB/s sustained   writes. Decompression overhead is invisible.</li> <li>The 3.5 GB/s wall. All three tools hit ClickHouse's background merge   limit. The bottleneck is the database, not the ingester.</li> <li>The Parquet paradox. Parquet is faster for queries but 30% slower for   ingestion due to parquet-go serialization overhead.</li> <li>24 workers optimal. 8.3% faster than 16 workers, uses ~72 GB RAM.   32 workers exceeded 128 GB and OOM'd.</li> <li>Thermals. 74 C at full load (5.0 GHz sustained), no throttling.</li> <li>LLM coexistence. Running DeepSeek-R1-70B (SGLang) concurrently had   less than 1% impact on ingestion throughput.</li> </ul>"},{"location":"benchmarks/#query-benchmarks","title":"Query Benchmarks","text":""},{"location":"benchmarks/#threadripper-9975wx-108b-rows","title":"Threadripper 9975WX \u2014 10.8B Rows","text":"<pre><code>SELECT callsign, avg(snr) AS avg_snr, count(*) AS count\nFROM wspr.bronze\nGROUP BY callsign\nORDER BY count DESC\nLIMIT 10;\n</code></pre> Metric Result Time 3.050 sec Rows processed 10.80 billion Throughput 3.54 billion rows/s Data scanned 183.57 GB Scan rate 60.19 GB/s Peak memory 828.79 MiB <p>Top 5 transmitters by spot count:</p> Callsign Avg SNR Spots WW0WWV -12.79 dB 105.96M WB6CXC -12.47 dB 70.83M NI5F -11.68 dB 58.74M DL6NL -17.00 dB 53.28M TA4/G8SCU -12.46 dB 49.21M"},{"location":"benchmarks/#cross-system-comparison","title":"Cross-System Comparison","text":""},{"location":"benchmarks/#ingestion-wspr-turbo","title":"Ingestion (wspr-turbo)","text":"System Workers Time Throughput vs 9950X3D Threadripper 9975WX 24 7m 18s 24.67 Mrps 2.79x Threadripper 9975WX 16 7m 54s 22.77 Mrps 2.58x Ryzen 9 9950X3D 16 20m 13s 8.83 Mrps baseline EPYC 7302P 16 23m 27s 7.63 Mrps 0.86x"},{"location":"benchmarks/#query-group-by-over-108b-rows","title":"Query (GROUP BY over 10.8B rows)","text":"System Time Scan Rate Winner Threadripper 9975WX 3.05s 60.19 GB/s Yes Ryzen 9 9950X3D 3.88s ~47 GB/s EPYC 7302P 4.54s ~40 GB/s"},{"location":"benchmarks/#system-specifications","title":"System Specifications","text":"Spec Threadripper 9975WX 9950X3D EPYC 7302P Cores / Threads 32C/64T 16C/32T 16C/32T Architecture Zen 5 Zen 5 (3D V-Cache) Zen 2 Boost clock 5.3 GHz 5.4 GHz 3.0 GHz RAM 128 GB DDR5 64 GB DDR5-6000 128 GB DDR4-3200 ECC Memory channels 8 2 8 Memory bandwidth ~384 GB/s ~96 GB/s ~204 GB/s <p>The Threadripper 9975WX dominates all workloads. Eight-channel DDR5 combined with 32 Zen 5 cores finally unlocks the memory bandwidth needed for analytical queries while maintaining the single-threaded performance needed for gzip decompression.</p>"},{"location":"benchmarks/#wspr-turbo-architecture","title":"wspr-turbo Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  .csv.gz file   \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Stream Decomp   \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Vectorized     \u2502\n\u2502  (on disk)      \u2502     \u2502  (klauspost/gzip)\u2502     \u2502  CSV Parser     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                          \u2502\n                                                          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  ClickHouse     \u2502\u25c0\u2500\u2500\u2500\u2500\u2502  ch-go Native    \u2502\u25c0\u2500\u2500\u2500\u2500\u2502  Double Buffer  \u2502\n\u2502                 \u2502     \u2502  Blocks + LZ4    \u2502     \u2502  Fill A/Send B  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ul> <li>Stream decompress: klauspost/gzip (ASM-optimized, no disk extraction)</li> <li>Vectorized parse: custom scanner fills columnar slices directly (no row   structs)</li> <li>Double buffer: Block A fills while Block B sends over the wire</li> <li>Zero-alloc hot path: sync.Pool for 1M-row column blocks (~490 GC cycles   for 10B rows)</li> <li>Native protocol: proto.ColUInt64, proto.ColDateTime \u2014 binary wire format   with LZ4 compression</li> </ul>"},{"location":"benchmarks/#end-to-end-pipeline-comparison","title":"End-to-End Pipeline Comparison","text":"<p>Threadripper 9975WX:</p> Pipeline Steps Total Time Temp Disk Throughput wspr-turbo streaming Stream from .gz 7m 18s 0 GB 24.67 Mrps pigz + wspr-shredder Decompress + ingest 9m 31s 878 GB 21.81 Mrps pigz + parquet-native Decompress + convert + ingest ~12m 987 GB 17.02 Mrps <p>wspr-turbo requires zero intermediate storage. The \"compression is free\" finding means there is no benefit to pre-decompressing archives \u2014 the ClickHouse merge wall is the bottleneck, not gzip decompression.</p>"},{"location":"devops/","title":"Hardware Requirements","text":"<p>This page describes the hardware needed to reproduce the IONIS pipeline, from minimum viable to the reference build currently in production.</p>"},{"location":"devops/#minimum-recommended","title":"Minimum Recommended","text":"<p>These specs support the full pipeline end-to-end: ingest, embeddings, training, and inference.</p> Component Minimum Recommended CPU 16 cores (Zen 3+) 32+ cores (Threadripper/EPYC) RAM 64 GB 128 GB (<code>wspr-turbo</code> uses ~80 GB at 16 workers) GPU NVIDIA 8+ GB VRAM NVIDIA 24+ GB VRAM ClickHouse storage 2 TB NVMe 4 TB NVMe (separate from OS) Archive storage 2 TB 4+ TB (ZFS recommended) OS RHEL 9 / Rocky 9 / Fedora Rocky Linux 9.7 <p>GPU is optional</p> <p>GPU is only required for the silver layer (CUDA embeddings via <code>bulk-processor</code>). Training runs on Mac or Linux with PyTorch (CPU or MPS). You can skip straight from bronze to gold if you don't need embeddings.</p>"},{"location":"devops/#reference-build","title":"Reference Build","text":"<p>The production IONIS infrastructure uses three nodes connected by direct-attach 10 Gbps links with no switches.</p>"},{"location":"devops/#compute-nodes","title":"Compute Nodes","text":"Node Role CPU RAM GPU OS 9975WX (Control) Ingestion, ClickHouse, CUDA Threadripper PRO 9975WX (32C/64T, Zen 5) 128 GB DDR5 8-ch RTX PRO 6000 (96 GB) Rocky Linux 9.7 M3 Ultra (Sage) Model training, evaluation Apple M3 Ultra 96 GB unified Integrated (MPS) macOS EPYC 7302P (Forge) Proxmox VM/app server, backup EPYC 7302P (16C/32T) 128 GB DDR4 ECC RTX 5080 (16 GB) Proxmox VE"},{"location":"devops/#dac-network-direct-attach-copperoptical","title":"DAC Network (Direct Attach Copper/Optical)","text":"<p>All inter-node links are point-to-point with jumbo frames (MTU 9000).</p> Link Cable Subnet Host A Host B Latency Thunderbolt 4 USB4/TB4 <code>10.60.1.0/24</code> 9975WX <code>.1</code> M3 Ultra <code>.2</code> ~0.19 ms x710 SFP+ AOC FS.com 10G <code>10.60.2.0/24</code> 9975WX <code>.1</code> Proxmox <code>.2</code> ~0.12 ms x710 SFP+ AOC FS.com 10G <code>10.60.3.0/24</code> 9975WX <code>.1</code> TrueNAS <code>.2</code> ~0.03 ms <p>Training scripts target <code>10.60.1.1:8123</code> (HTTP) / <code>10.60.1.1:9000</code> (native) for ClickHouse queries over the DAC link.</p>"},{"location":"devops/#storage-layout-9975wx","title":"Storage Layout (9975WX)","text":"<p>Source data and ClickHouse are on separate NVMe drives to decouple read and write I/O during ingestion.</p> Drive Mount Size Purpose nvme2n1 <code>/</code> (LVM) ~1 TB OS (150 GB root, 4 GB swap, 739 GB home) nvme0n1 <code>/var/lib/clickhouse</code> 3.6 TB ClickHouse data (~200 GB used) nvme1n1 <code>/mnt/ai-stack</code> 3.6 TB Working data (repos, scripts)"},{"location":"devops/#zfs-archive-pool","title":"ZFS Archive Pool","text":"<p>Raw source archives live on a mirrored ZFS pool (<code>archive-pool</code>, 7.12 TB usable on Samsung 990 Pro SSDs). Compression varies by content:</p> Dataset Mountpoint Compression Purpose <code>archive-pool/wspr-data</code> <code>/mnt/wspr-data</code> lz4 WSPR raw CSV archives (.csv.gz) <code>archive-pool/contest-logs</code> <code>/mnt/contest-logs</code> zstd-9 CQ contest Cabrillo logs <code>archive-pool/rbn-data</code> <code>/mnt/rbn-data</code> lz4 RBN daily ZIP archives <code>archive-pool/pskr-data</code> <code>/mnt/pskr-data</code> lz4 PSK Reporter MQTT collection"},{"location":"devops/#benchmark-actuals","title":"Benchmark Actuals","text":"<p>Performance verified on the 9975WX reference build (2026-02-07):</p> Operation Throughput Wall Time WSPR ingest (<code>wspr-turbo</code> @ 16 workers) 21.91 Mrps 8 min RBN ingest (<code>rbn-ingest</code>) 10.30 Mrps 3 min 32 s Contest ingest (<code>contest-ingest</code>) -- 21 min 32 s ClickHouse scan (10.8B rows) 60 GB/s 0.64 s CUDA embeddings (<code>bulk-processor</code>) -- ~45 min V20 training (100 epochs, MPS) -- 4 h 16 min Full pipeline (clean slate to training-ready) -- ~2 hours"},{"location":"devops/maintenance/","title":"Operations &amp; Maintenance","text":"<p>Scheduled jobs, health checks, and common operational procedures for a running IONIS installation.</p>"},{"location":"devops/maintenance/#cron-schedule","title":"Cron Schedule","text":"<p>Seven automated jobs keep solar indices and propagation data current. Downloaders write to disk; ingesters read from disk into ClickHouse.</p> Job Schedule Command Purpose <code>solar-live-update</code> Every 15 min <code>solar-live-update</code> Real-time solar indices \u2192 <code>wspr.live_conditions</code> <code>solar-history-load</code> Every 6 hours <code>solar-history-load</code> Training-quality solar data \u2192 <code>solar.bronze</code> <code>pskr-ingest</code> Hourly at H+5 <code>pskr-ingest</code> JSONL files \u2192 <code>pskr.bronze</code> (watermark: <code>pskr.ingest_log</code>) <code>rbn-download</code> 16:00 UTC daily <code>rbn-download</code> Daily RBN ZIP archive \u2192 <code>/mnt/rbn-data</code> <code>rbn-ingest</code> 16:30 UTC daily <code>rbn-ingest</code> RBN ZIPs \u2192 <code>rbn.bronze</code> (watermark: <code>rbn.ingest_log</code>) <code>wspr-download</code> 18:00 UTC daily <code>wspr-download</code> Daily WSPR archive \u2192 <code>/mnt/wspr-data</code> <code>wspr-turbo</code> 19:00 UTC daily <code>wspr-turbo</code> WSPR archives \u2192 <code>wspr.bronze</code> (watermark: <code>wspr.ingest_log</code>) <p>Solar data freshness</p> <p><code>solar.bronze</code> (GFZ Potsdam source) lags ~1 day behind real-time. For live prediction and validation, use <code>wspr.live_conditions</code> which updates every 15 minutes from NOAA SWPC. SFI is published once daily (~20:00 UTC from Penticton); Kp updates every 3 hours.</p>"},{"location":"devops/maintenance/#daemons","title":"Daemons","text":""},{"location":"devops/maintenance/#pskr-collector","title":"pskr-collector","text":"<p>The PSK Reporter MQTT collector runs as a systemd service, streaming ~300 HF spots/sec (~26M spots/day) to hourly-rotated gzip JSONL files.</p> <pre><code># Check status\nsystemctl status pskr-collector\n\n# View recent logs\njournalctl -u pskr-collector --since \"1 hour ago\" --no-pager\n\n# Restart after config change\nsudo systemctl restart pskr-collector\n</code></pre> <p>Output files: <code>/mnt/pskr-data/YYYY/MM/DD/spots-HHMMSS.jsonl.gz</code></p>"},{"location":"devops/maintenance/#health-checks","title":"Health Checks","text":""},{"location":"devops/maintenance/#solar-data-freshness","title":"Solar Data Freshness","text":"<pre><code>-- Most recent solar record (should be within ~1 day)\nSELECT max(date) FROM solar.bronze;\n\n-- Live conditions (should be within ~15 min)\nSELECT max(timestamp) FROM wspr.live_conditions;\n</code></pre>"},{"location":"devops/maintenance/#psk-reporter-collection","title":"PSK Reporter Collection","text":"<pre><code># Service running?\nsystemctl is-active pskr-collector\n\n# Today's spot count\nclickhouse-client --query \"\n    SELECT count()\n    FROM pskr.bronze\n    WHERE toDate(timestamp) = today()\n\"\n</code></pre>"},{"location":"devops/maintenance/#clickhouse-disk-usage","title":"ClickHouse Disk Usage","text":"<pre><code>SELECT\n    name,\n    formatReadableSize(free_space) AS free,\n    formatReadableSize(total_space) AS total,\n    round(free_space / total_space * 100, 1) AS pct_free\nFROM system.disks;\n</code></pre>"},{"location":"devops/maintenance/#table-integrity","title":"Table Integrity","text":"<pre><code>db-validate --all\n</code></pre>"},{"location":"devops/maintenance/#common-operations","title":"Common Operations","text":""},{"location":"devops/maintenance/#full-solar-refresh","title":"Full Solar Refresh","text":"<p>Re-download and reload all historical solar data from GFZ Potsdam:</p> <pre><code>solar-backfill -ch-host 192.168.1.90:9000\n</code></pre> <p>This is idempotent \u2014 existing rows are replaced by primary key.</p>"},{"location":"devops/maintenance/#re-download-a-contest-year","title":"Re-download a Contest Year","text":"<pre><code># Download a specific contest/year\ncontest-download -contest CQWW-SSB -year 2024 -dest /mnt/contest-logs\n\n# Re-ingest (idempotent insert)\ncontest-ingest -host 192.168.1.90:9000 -src /mnt/contest-logs -enrich\n</code></pre>"},{"location":"devops/maintenance/#replay-pskr-files-after-schema-change","title":"Replay PSKR Files After Schema Change","text":"<p>If the <code>pskr.bronze</code> schema changes, replay collected JSONL files:</p> <pre><code># Stop the collector to avoid conflicts\nsudo systemctl stop pskr-collector\n\n# Full re-ingest (ignores watermark, reloads all files)\npskr-ingest --full --src /mnt/pskr-data --host 192.168.1.90:9000\n\n# Restart collector\nsudo systemctl start pskr-collector\n</code></pre>"},{"location":"devops/maintenance/#watermark-bootstrap-new-install-or-schema-change","title":"Watermark Bootstrap (New Install or Schema Change)","text":"<p>After a fresh install or schema change, bootstrap watermarks so incremental mode knows what's already loaded:</p> <pre><code># Prime all four ingest_log tables (marks files as loaded, row_count=0)\npskr-ingest --prime --src /mnt/pskr-data --host 192.168.1.90:9000\nrbn-ingest --prime --src /mnt/rbn-data --host 192.168.1.90:9000\nwspr-turbo --prime --source-dir /mnt/wspr-data --ch-host 192.168.1.90:9000\ncontest-ingest --prime --src /mnt/contest-logs --host 192.168.1.90:9000\n\n# Verify watermark counts\nclickhouse-client --query \"\nSELECT 'pskr' AS src, count() FROM pskr.ingest_log FINAL\nUNION ALL SELECT 'rbn', count() FROM rbn.ingest_log FINAL\nUNION ALL SELECT 'wspr', count() FROM wspr.ingest_log FINAL\nUNION ALL SELECT 'contest', count() FROM contest.ingest_log FINAL\nORDER BY 1\nFORMAT PrettyCompact\n\"\n</code></pre> <p>After priming, subsequent cron runs will only load new files.</p>"},{"location":"devops/maintenance/#full-re-ingest-any-source","title":"Full Re-ingest (Any Source)","text":"<p>All watermark-enabled ingesters support <code>--full</code> for complete reload:</p> <pre><code>rbn-ingest --full --src /mnt/rbn-data --host 192.168.1.90:9000\nwspr-turbo --full --source-dir /mnt/wspr-data --ch-host 192.168.1.90:9000\ncontest-ingest --full --src /mnt/contest-logs --host 192.168.1.90:9000\n</code></pre> <p><code>--full</code> drops partitions before reload and updates watermark entries. Use <code>--dry-run</code> to preview what would be processed.</p>"},{"location":"devops/maintenance/#manual-solar-backfill","title":"Manual Solar Backfill","text":"<p>For periods where the automated cron missed updates:</p> <pre><code>solar-backfill -ch-host 192.168.1.90:9000\n</code></pre>"},{"location":"devops/maintenance/#regenerate-signatures","title":"Regenerate Signatures","text":"<p>After a bronze re-ingest or schema change, rebuild derived tables:</p> <pre><code>bash /usr/share/ionis-core/scripts/populate_callsign_grid.sh\nbash /usr/share/ionis-core/scripts/populate_signatures.sh\nbash /usr/share/ionis-core/scripts/populate_rbn_signatures.sh\nbash /usr/share/ionis-core/scripts/populate_contest_signatures.sh\n</code></pre>"},{"location":"devops/pipeline-runbook/","title":"Pipeline Runbook","text":"<p>Step-by-step guide to build the full IONIS pipeline from a clean slate. This is the tested, dependency-ordered sequence \u2014 proven during the v3.0 migration rebuild (2026-02-13). Each phase links to the relevant Methodology page for detail; this page is the consolidated checklist with commands, expected counts, and wall times.</p> <p>Total wall time: ~2 hours on reference hardware (9975WX ingest + population), plus ~4 hours training on M3 Ultra.</p> <p>Path convention</p> <p>Commands in this runbook use <code>$IONIS_WORKSPACE</code> for the local clone directory (e.g. <code>~/workspace/ionis-ai</code>). Set it once per session: <code>export IONIS_WORKSPACE=~/workspace/ionis-ai</code></p>"},{"location":"devops/pipeline-runbook/#phase-1-install-packages-9975wx","title":"Phase 1: Install Packages (9975WX)","text":""},{"location":"devops/pipeline-runbook/#step-11-enable-copr-and-install","title":"Step 1.1: Enable COPR and install","text":"<pre><code>sudo dnf copr enable ki7mt/ionis-ai\nsudo dnf install ionis-core ionis-apps\n</code></pre>"},{"location":"devops/pipeline-runbook/#step-12-verify-installed-versions","title":"Step 1.2: Verify installed versions","text":"<pre><code>rpm -q ionis-core ionis-apps\n# Expected: ionis-core-3.0.3+, ionis-apps-3.0.1+\n</code></pre>"},{"location":"devops/pipeline-runbook/#step-13-verify-ddl-and-scripts-installed","title":"Step 1.3: Verify DDL and scripts installed","text":"<pre><code>ls /usr/share/ionis-core/ddl/*.sql | wc -l\n# Expected: 32\n\nls /usr/share/ionis-core/scripts/*.sh | wc -l\n# Expected: 12\n</code></pre>"},{"location":"devops/pipeline-runbook/#phase-2-create-database-schema-1-min","title":"Phase 2: Create Database Schema (&lt; 1 min)","text":"<p>All DDL files live in <code>/usr/share/ionis-core/ddl/</code>. Each is idempotent (<code>CREATE TABLE/VIEW IF NOT EXISTS</code>). Apply in numerical order \u2014 the sequence encodes dependencies.</p>"},{"location":"devops/pipeline-runbook/#step-21-apply-all-ddl","title":"Step 2.1: Apply all DDL","text":"<pre><code>ionis-db-init\n</code></pre> <p>Or manually:</p> <pre><code>for f in /usr/share/ionis-core/ddl/*.sql; do\n    echo \"Applying: $(basename $f)\"\n    clickhouse-client --multiquery &lt; \"$f\"\ndone\n</code></pre>"},{"location":"devops/pipeline-runbook/#step-22-ddl-inventory-32-files","title":"Step 2.2: DDL Inventory (32 files)","text":"<pre><code>  #   File                              Database      Creates\n  --  --------------------------------  -----------   ----------------------------------------\n  01  wspr_schema_v2.sql                wspr          bronze, mv_spots_daily\n  02  solar_indices.sql                 solar         bronze\n  03  solar_silver.sql                  solar         v_daily_indices\n  04  data_mgmt.sql                     data_mgmt     config\n  05  geo_functions.sql                 geo           v_grid_validation_example\n  06  lab_versions.sql                  data_mgmt     lab_versions\n  07  callsign_grid.sql                 wspr          callsign_grid\n  08  model_features.sql                wspr          silver\n  09  quality_distribution_mv.sql       wspr          v_quality_distribution (MV \u2192 silver)\n  10  rbn_schema_v1.sql                 rbn           bronze\n  11  contest_schema_v1.sql             contest       bronze\n  12  signatures_v1.sql                 wspr          signatures_v1\n  13  training_stratified.sql           wspr          gold_stratified\n  14  training_continuous.sql           wspr          gold_continuous\n  15  training_v6_clean.sql             wspr          gold_v6\n  16  validation_step_i.sql             validation    step_i_paths, step_i_voacap\n  17  balloon_callsigns.sql             wspr          balloon_callsigns\n  18  validation_quality_test.sql       validation    quality_test_paths, quality_test_voacap\n  19  dxpedition_synthesis.sql          dxpedition    catalog; rbn.dxpedition_paths\n  20  signatures_v2_terrestrial.sql     wspr          signatures_v2_terrestrial\n  21  balloon_callsigns_v2.sql          wspr          balloon_callsigns_v2\n  22  pskr_schema_v1.sql                pskr          bronze\n  23  contest_signatures.sql            contest       signatures\n  24  rbn_signatures.sql                rbn           signatures\n  25  live_conditions.sql               wspr          live_conditions\n  26  validation_model_results.sql      validation    model_results\n  27  mode_thresholds.sql               validation    mode_thresholds\n  28  pskr_ingest_log.sql               pskr          ingest_log\n  29  rbn_dxpedition_signatures.sql     rbn           dxpedition_signatures\n  30  rbn_ingest_log.sql                rbn           ingest_log\n  31  wspr_ingest_log.sql               wspr          ingest_log\n  32  contest_ingest_log.sql            contest       ingest_log\n</code></pre> <p>DDL 09 depends on DDL 08</p> <p>The <code>v_quality_distribution</code> materialized view reads from <code>wspr.silver</code>. DDL 08 must be applied first. Sequential numbering handles this automatically.</p>"},{"location":"devops/pipeline-runbook/#step-23-verify-table-count","title":"Step 2.3: Verify table count","text":"<pre><code>clickhouse-client --query \"\nSELECT count()\nFROM system.tables\nWHERE database NOT IN ('system', 'information_schema', 'INFORMATION_SCHEMA', 'default')\n  AND engine &lt;&gt; ''\n  AND name NOT LIKE '.inner_id%'\n\"\n# Expected: 38\n</code></pre> <p>See Bronze Stack \u2014 Step 1 for additional detail.</p>"},{"location":"devops/pipeline-runbook/#phase-3-bronze-ingest-35-min","title":"Phase 3: Bronze Ingest (~35 min)","text":"<p>Order matters. Solar must run first \u2014 downstream JOINs depend on it. Run <code>wspr-turbo</code> solo (it consumes ~80 GB RAM at 16 workers).</p>"},{"location":"devops/pipeline-runbook/#step-31-solar-backfill","title":"Step 3.1: Solar backfill","text":"<pre><code>solar-backfill -start 2000-01-01\nclickhouse-client --query \"OPTIMIZE TABLE solar.bronze FINAL\"\n</code></pre> <p>Additional solar sources</p> <p><code>solar-backfill</code> loads GFZ Potsdam historical data only. Additional solar data comes from <code>solar-history-load</code> (NOAA, 6-hour cron) and <code>solar-live-update</code> (SWPC, 15-min cron). Run those manually or wait for their cron cycles to fully populate <code>solar.bronze</code> and <code>wspr.live_conditions</code>.</p>"},{"location":"devops/pipeline-runbook/#step-32-wspr-ingest","title":"Step 3.2: WSPR ingest","text":"<pre><code>wspr-turbo --full --source-dir /mnt/wspr-data --ch-host 192.168.1.90:9000\n</code></pre> <p>Run wspr-turbo solo</p> <p>With 16 workers, wspr-turbo consumes ~80 GB RAM. Do not run other ingesters concurrently.</p> <p>Use <code>--full</code> for clean-slate builds. Subsequent cron runs use incremental mode (default) which detects cumulative file growth via <code>wspr.ingest_log</code>.</p>"},{"location":"devops/pipeline-runbook/#step-33-rbn-ingest","title":"Step 3.3: RBN ingest","text":"<pre><code>rbn-ingest --full --src /mnt/rbn-data --host 192.168.1.90:9000\n</code></pre> <p>Use <code>--full</code> for clean-slate builds. Daily cron uses incremental mode.</p>"},{"location":"devops/pipeline-runbook/#step-34-contest-ingest","title":"Step 3.4: Contest ingest","text":"<pre><code>contest-ingest --full --src /mnt/contest-logs --host 192.168.1.90:9000 --enrich\n</code></pre> <p>Use <code>--full</code> for clean-slate builds. Weekly cron uses incremental mode.</p>"},{"location":"devops/pipeline-runbook/#step-35-psk-reporter-ingest","title":"Step 3.5: PSK Reporter ingest","text":"<pre><code>pskr-ingest --src /mnt/pskr-data --host 192.168.1.90:9000\n</code></pre> <p>Incremental by default (watermark-tracked via <code>pskr.ingest_log</code>).</p>"},{"location":"devops/pipeline-runbook/#step-36-verify-all-bronze-tables","title":"Step 3.6: Verify all bronze tables","text":"<pre><code>clickhouse-client --query \"\nSELECT 'solar.bronze' AS tbl, count() AS rows FROM solar.bronze\nUNION ALL SELECT 'wspr.bronze', count() FROM wspr.bronze\nUNION ALL SELECT 'rbn.bronze', count() FROM rbn.bronze\nUNION ALL SELECT 'contest.bronze', count() FROM contest.bronze\nUNION ALL SELECT 'pskr.bronze', count() FROM pskr.bronze\nORDER BY 1\nFORMAT PrettyCompact\n\"\n</code></pre>"},{"location":"devops/pipeline-runbook/#qa-actuals","title":"QA Actuals","text":"<p>Clean-slate rebuild on 9975WX (2026-02-07):</p> Table Expected Rows Time Throughput <code>solar.bronze</code> ~76,000 &lt; 1 s \u2014 <code>wspr.bronze</code> ~10,800,000,000 ~8 min 21.91 Mrps <code>rbn.bronze</code> ~2,184,000,000 ~3 min 30 s 10.30 Mrps <code>contest.bronze</code> ~234,000,000 ~22 min \u2014 <code>pskr.bronze</code> ~81,000,000+ varies \u2014 <p>See Bronze Stack for per-step verification queries.</p>"},{"location":"devops/pipeline-runbook/#phase-4-populate-derived-tables-20-min","title":"Phase 4: Populate Derived Tables (~20 min)","text":"<p>All 12 population scripts live in <code>/usr/share/ionis-core/scripts/</code>. They accept <code>CH_HOST</code> env var (default: <code>192.168.1.90</code>, use <code>10.60.1.1</code> for DAC).</p> <p>Run in dependency order \u2014 three tiers.</p>"},{"location":"devops/pipeline-runbook/#tier-1-no-dependencies-beyond-bronze","title":"Tier 1: No dependencies beyond bronze","text":"<pre><code># 4.1 \u2014 Callsign\u2192Grid Rosetta Stone (depends on: wspr.bronze)\nbash /usr/share/ionis-core/scripts/populate_callsign_grid.sh\n# Expected: ~3.6M rows in wspr.callsign_grid\n\n# 4.2 \u2014 WSPR Signatures V1 (depends on: wspr.bronze, solar.bronze)\nbash /usr/share/ionis-core/scripts/populate_signatures.sh\n# Expected: ~93.8M rows in wspr.signatures_v1 (~3 min)\n\n# 4.3 \u2014 Continuous training set (depends on: wspr.bronze, solar.bronze)\nbash /usr/share/ionis-core/scripts/populate_continuous.sh\n# Expected: 10M rows in wspr.gold_continuous (~4 min)\n\n# 4.4 \u2014 Stratified training set (depends on: wspr.bronze, solar.bronze)\nbash /usr/share/ionis-core/scripts/populate_stratified.sh\n# Expected: 10M rows in wspr.gold_stratified (~7 min)\n</code></pre>"},{"location":"devops/pipeline-runbook/#tier-2-depends-on-tier-1-outputs","title":"Tier 2: Depends on Tier 1 outputs","text":"<pre><code># 4.5 \u2014 Balloon callsigns V2 (depends on: wspr.bronze, wspr.callsign_grid)\nbash /usr/share/ionis-core/scripts/populate_balloon_callsigns.sh\n# Expected: ~1,443 rows in wspr.balloon_callsigns_v2\n\n# 4.6 \u2014 RBN Signatures (depends on: rbn.bronze, wspr.callsign_grid, solar.bronze)\nbash /usr/share/ionis-core/scripts/populate_rbn_signatures.sh\n# Expected: ~56.7M rows in rbn.signatures\n\n# 4.7 \u2014 Contest Signatures (depends on: contest.bronze, wspr.callsign_grid, solar.bronze)\nbash /usr/share/ionis-core/scripts/populate_contest_signatures.sh\n# Expected: ~6.3M rows in contest.signatures\n\n# 4.8 \u2014 Quality test paths (depends on: wspr.signatures_v1)\nbash /usr/share/ionis-core/scripts/populate_quality_test_paths.sh\n# Expected: 100K rows in validation.quality_test_paths\n\n# 4.9 \u2014 V6 clean training set (depends on: wspr.gold_continuous)\nbash /usr/share/ionis-core/scripts/populate_v6_clean.sh\n# Expected: 10M rows in wspr.gold_v6\n</code></pre>"},{"location":"devops/pipeline-runbook/#dxpedition-chain-depends-on-tier-1-rbnbronze","title":"DXpedition chain (depends on Tier 1 + rbn.bronze)","text":"<pre><code># 4.10 \u2014 DXpedition catalog (depends on: static TSV data file)\nbash /usr/share/ionis-core/scripts/populate_dxpedition_catalog.sh\n# Expected: 332 rows in dxpedition.catalog\n\n# 4.11 \u2014 DXpedition paths + signatures (depends on: catalog, rbn.bronze, callsign_grid, solar.bronze)\nbash /usr/share/ionis-core/scripts/populate_dxpedition_paths.sh\n# Expected: ~3.9M rows in rbn.dxpedition_paths, ~260K rows in rbn.dxpedition_signatures\n</code></pre>"},{"location":"devops/pipeline-runbook/#tier-3-balloon-filtered-signatures","title":"Tier 3: Balloon-filtered signatures","text":"<pre><code># 4.12 \u2014 Signatures V2 Terrestrial (depends on: wspr.bronze, solar.bronze, balloon_callsigns_v2)\nbash /usr/share/ionis-core/scripts/populate_signatures_v2_terrestrial.sh\n# Expected: ~93.3M rows in wspr.signatures_v2_terrestrial\n</code></pre>"},{"location":"devops/pipeline-runbook/#step-413-verify-all-derived-tables","title":"Step 4.13: Verify all derived tables","text":"<pre><code>clickhouse-client --query \"\nSELECT 'wspr.callsign_grid' AS tbl, count() AS rows FROM wspr.callsign_grid\nUNION ALL SELECT 'wspr.signatures_v1', count() FROM wspr.signatures_v1\nUNION ALL SELECT 'wspr.signatures_v2_terrestrial', count() FROM wspr.signatures_v2_terrestrial\nUNION ALL SELECT 'wspr.balloon_callsigns_v2', count() FROM wspr.balloon_callsigns_v2\nUNION ALL SELECT 'wspr.gold_continuous', count() FROM wspr.gold_continuous\nUNION ALL SELECT 'wspr.gold_stratified', count() FROM wspr.gold_stratified\nUNION ALL SELECT 'wspr.gold_v6', count() FROM wspr.gold_v6\nUNION ALL SELECT 'rbn.signatures', count() FROM rbn.signatures\nUNION ALL SELECT 'contest.signatures', count() FROM contest.signatures\nUNION ALL SELECT 'dxpedition.catalog', count() FROM dxpedition.catalog\nUNION ALL SELECT 'rbn.dxpedition_paths', count() FROM rbn.dxpedition_paths\nUNION ALL SELECT 'rbn.dxpedition_signatures', count() FROM rbn.dxpedition_signatures\nUNION ALL SELECT 'validation.quality_test_paths', count() FROM validation.quality_test_paths\nORDER BY 1\nFORMAT PrettyCompact\n\"\n</code></pre>"},{"location":"devops/pipeline-runbook/#phase-5-silver-layer-50-min-optional","title":"Phase 5: Silver Layer (~50 min, optional)","text":"<p>Generate CUDA float4 embeddings from WSPR spots joined with solar indices.</p> <p>GPU required</p> <p><code>bulk-processor</code> requires an NVIDIA GPU. It is not yet packaged in the <code>ionis-cuda</code> RPM \u2014 build locally: <code>cd ionis-cuda &amp;&amp; mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; make</code></p> <pre><code>bulk-processor --host 192.168.1.90\n</code></pre> Target Table Expected Rows Time <code>wspr.silver</code> ~4.43B ~45 min <code>wspr.v_quality_distribution</code> ~6.1M auto (MV) <p>Verification:</p> <pre><code>clickhouse-client --query \"SELECT count() FROM wspr.silver\"\n# Expected: ~4,430,000,000\n</code></pre> <p>See Silver Layer for details.</p>"},{"location":"devops/pipeline-runbook/#phase-6-export-training-data","title":"Phase 6: Export Training Data","text":"<p>Export the gold_v6 training set as CSV and transfer to the training host.</p> <pre><code>clickhouse-client --query \"SELECT * FROM wspr.gold_v6 FORMAT CSV\" \\\n    &gt; $IONIS_WORKSPACE/ionis-training/data/gold_v6.csv\n\n# Transfer to M3 Ultra via DAC link\nscp $IONIS_WORKSPACE/ionis-training/data/gold_v6.csv &lt;user&gt;@&lt;sage-host&gt;:$IONIS_WORKSPACE/ionis-training/data/\n</code></pre> <p>Verification:</p> <pre><code>wc -l data/gold_v6.csv\n# Expected: 10,000,000\n\nls -lh data/gold_v6.csv\n# Expected: ~838 MB\n</code></pre> <p>See Gold Layer for training table lineage.</p>"},{"location":"devops/pipeline-runbook/#phase-7-verify-services-9975wx","title":"Phase 7: Verify Services (9975WX)","text":""},{"location":"devops/pipeline-runbook/#step-71-solar-live-update","title":"Step 7.1: Solar live update","text":"<pre><code>solar-live-update\nclickhouse-client --query \"SELECT * FROM wspr.live_conditions ORDER BY updated_at DESC LIMIT 1\"\n</code></pre>"},{"location":"devops/pipeline-runbook/#step-72-cron-jobs","title":"Step 7.2: Cron jobs","text":"<pre><code>crontab -l | grep -E 'solar|pskr|rbn|wspr'\n</code></pre> <p>See Operations &amp; Maintenance for the full cron schedule.</p>"},{"location":"devops/pipeline-runbook/#step-73-pskr-collector-service","title":"Step 7.3: pskr-collector service","text":"<pre><code>systemctl status pskr-collector\n# Expected: active (running)\n</code></pre>"},{"location":"devops/pipeline-runbook/#phase-8-m3-ultra-setup-sage-node","title":"Phase 8: M3 Ultra Setup (Sage Node)","text":""},{"location":"devops/pipeline-runbook/#step-81-clone-all-repos","title":"Step 8.1: Clone all repos","text":"<pre><code>mkdir -p $IONIS_WORKSPACE &amp;&amp; cd $IONIS_WORKSPACE\nfor repo in ionis-core ionis-apps ionis-cuda ionis-docs ionis-training ionis-devel ionis-tools; do\n    git clone git@github.com:IONIS-AI/${repo}.git\ndone\n</code></pre>"},{"location":"devops/pipeline-runbook/#step-82-verify-clickhouse-connectivity-over-dac","title":"Step 8.2: Verify ClickHouse connectivity over DAC","text":"<pre><code>clickhouse-client --host 10.60.1.1 --query \"SELECT version()\"\nclickhouse-client --host 10.60.1.1 --query \"SELECT count() FROM wspr.bronze\"\n</code></pre>"},{"location":"devops/pipeline-runbook/#step-83-set-up-python-venv","title":"Step 8.3: Set up Python venv","text":"<pre><code>cd $IONIS_WORKSPACE/ionis-training\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n</code></pre>"},{"location":"devops/pipeline-runbook/#phase-9-train-and-validate-v20-m3-ultra","title":"Phase 9: Train and Validate V20 (M3 Ultra)","text":""},{"location":"devops/pipeline-runbook/#step-91-train-v20","title":"Step 9.1: Train V20","text":"<pre><code>cd $IONIS_WORKSPACE/ionis-training\nsource .venv/bin/activate\npython train.py --config versions/v20/config_v20.json\n# Expected: ~4h 16m on M3 Ultra (MPS backend)\n</code></pre>"},{"location":"devops/pipeline-runbook/#step-92-run-validation-suite","title":"Step 9.2: Run validation suite","text":"<pre><code>python versions/v20/verify_v20.py\npython versions/v20/test_v20.py\npython versions/v20/validate_v20.py\n</code></pre>"},{"location":"devops/pipeline-runbook/#step-93-psk-reporter-live-validation","title":"Step 9.3: PSK Reporter live validation","text":"<pre><code>python versions/v20/validate_v20_pskr.py\n# Target: &gt; 84% recall on independent spots\n</code></pre>"},{"location":"devops/pipeline-runbook/#step-94-acceptance-criteria","title":"Step 9.4: Acceptance criteria","text":"Metric Target V20 Reference Pearson &gt; +0.48 +0.4879 Kp sidecar &gt; +3.0 sigma +3.487 sigma SFI sidecar &gt; +0.4 sigma +0.482 sigma RMSE &lt; 0.87 sigma 0.862 sigma"},{"location":"devops/pipeline-runbook/#summary-full-stack-build-order","title":"Summary: Full Stack Build Order","text":"<pre><code>Phase 1: Install Packages\n  1.1  dnf install ionis-core ionis-apps\n  1.2  Verify versions, DDL count (32), script count (12)\n\nPhase 2: Schema\n  2.1  ionis-db-init                                         (&lt;1 min)\n  2.2  Verify table count (38)\n\nPhase 3: Bronze Ingest\n  3.1  solar-backfill                solar.bronze             (&lt;1s)\n  3.2  wspr-turbo                    wspr.bronze              (~8m)   RUN SOLO\n  3.3  rbn-ingest                    rbn.bronze               (~3m30s)\n  3.4  contest-ingest                contest.bronze           (~22m)\n  3.5  pskr-ingest                   pskr.bronze              (varies)\n\nPhase 4: Population Scripts (Tier 1 \u2192 2 \u2192 3)\n  4.1  populate_callsign_grid.sh     wspr.callsign_grid       (~3.6M)\n  4.2  populate_signatures.sh        wspr.signatures_v1       (~93.8M)\n  4.3  populate_continuous.sh        wspr.gold_continuous      (10M)\n  4.4  populate_stratified.sh        wspr.gold_stratified      (10M)\n  \u2500\u2500 Tier 2 \u2500\u2500\n  4.5  populate_balloon_callsigns.sh wspr.balloon_callsigns_v2 (~1.4K)\n  4.6  populate_rbn_signatures.sh    rbn.signatures            (~56.7M)\n  4.7  populate_contest_signatures.sh contest.signatures       (~6.3M)\n  4.8  populate_quality_test_paths.sh validation.quality_test_paths (100K)\n  4.9  populate_v6_clean.sh          wspr.gold_v6              (10M)\n  \u2500\u2500 DXpedition \u2500\u2500\n  4.10 populate_dxpedition_catalog.sh   dxpedition.catalog            (332)\n  4.11 populate_dxpedition_paths.sh     rbn.dxpedition_paths          (~3.9M)\n                                        rbn.dxpedition_signatures     (~260K)\n  \u2500\u2500 Tier 3 \u2500\u2500\n  4.12 populate_signatures_v2_terrestrial.sh  wspr.signatures_v2_terrestrial (~93.3M)\n\nPhase 5: Silver Layer (optional, requires GPU)\n  5.1  bulk-processor (CUDA)         wspr.silver              (~4.43B, ~45m)\n\nPhase 6: Export Training Data\n  6.1  gold_v6.csv export + SCP to M3\n\nPhase 7: Verify Services\n  7.1  solar-live-update, cron jobs, pskr-collector\n\nPhase 8: M3 Ultra Setup\n  8.1  Clone repos, venv, DAC connectivity\n\nPhase 9: Train and Validate V20\n  9.1  train.py --config versions/v20/config_v20.json        (~4h16m)\n  9.2  verify_v20.py, test_v20.py, validate_v20.py\n  9.3  validate_v20_pskr.py (&gt;84% recall)\n</code></pre>"},{"location":"model/","title":"IONIS Model","text":"<p>IONIS (Ionospheric Neural Inference System) predicts HF radio signal-to-noise ratio (SNR) for any transmitter-receiver path. One model, one forward pass, six mode-aware operational verdicts \u2014 from WSPR at -28 dB to SSB at +5 dB.</p>"},{"location":"model/#current-production-ionis-v22-gamma-physicsoverridelayer","title":"Current Production: IONIS V22-gamma + PhysicsOverrideLayer","text":"Metric Value Architecture IonisGate (205,621 parameters) + PhysicsOverrideLayer Pearson correlation +0.492 RMSE 0.821\u03c3 (~5.5 dB) KI7MT operator tests 17/17 PASS TST-900 band x time 9/11 Checkpoint safetensors (805 KB) <p>Trained on 20M WSPR + 4.55M DXpedition (50x) + 6.34M Contest signatures (~31M rows) on Mac Studio M3 Ultra. PhysicsOverrideLayer adds deterministic post-inference clamping for high-band night closure.</p>"},{"location":"model/#architecture","title":"Architecture","text":"<p>IonisGate separates geography from physics by design:</p> <ul> <li>Trunk DNN: 15 geography/time features through 512 - 256 - 128 - 1</li> <li>Sun Sidecar: SFI (solar flux) through a monotonic MLP \u2014 higher SFI always helps</li> <li>Storm Sidecar: Kp (geomagnetic) through a monotonic MLP \u2014 storms always hurt</li> <li>Gated mixing: Trunk-derived gates scale sidecar contributions by geography</li> </ul> <p>The \"Nuclear Option\" \u2014 the trunk receives zero direct solar information. All physics flows through constrained sidecars that cannot violate ionospheric law.</p> <p>Read more: IonisGate Architecture | Monotonic Sidecars</p>"},{"location":"model/#methodology","title":"Methodology","text":"<p>The training pipeline transforms 14B+ raw radio observations into model-ready signatures through a medallion architecture:</p> <ul> <li>Bronze: Raw ingest from WSPR, RBN, contest logs, PSK Reporter</li> <li>Silver: CUDA-accelerated embeddings with solar enrichment</li> <li>Gold: Aggregated signatures \u2014 grid-pair, band, time, solar, SNR</li> </ul> <p>Read more: Data Pipeline | Training</p>"},{"location":"model/#validation","title":"Validation","text":"<p>V22-gamma is validated against multiple independent benchmarks:</p> <ol> <li>KI7MT operator-grounded tests \u2014 17/17 hard pass (18 tests from 49K QSOs + 5.7M contest signatures)</li> <li>TST-900 band x time discrimination \u2014 9/11 across all HF bands and time periods</li> <li>PhysicsOverrideLayer verification \u2014 deterministic clamp fires on high-band night paths</li> </ol> <p>V20 historical validation (VOACAP comparison, PSK Reporter acid test) provides the foundation that V22-gamma inherits and improves upon.</p> <p>Read more: Validation Overview | Link Budget Battery</p>"},{"location":"model/physics-vs-ml/","title":"From Empirical Physics to Neural Prediction","text":"<p>While legacy tools like VOACAP rely on empirical formulas derived from 1960s ionospheric measurement campaigns, IONIS uses physics-constrained PyTorch neural networks to predict HF path viability from first principles of observed behavior. Trained on over 14 billion real amateur radio observations from WSPR, the Reverse Beacon Network, and contest logs, IONIS captures nonlinear ionospheric behaviors \u2014 sporadic-E openings, real-time solar variability, grey-line enhancement \u2014 that traditional mathematical models miss. On 1 million real contest paths, IONIS achieves 96.38% recall versus VOACAP's 75.82%.</p> <p>VOACAP (Voice of America Coverage Analysis Program) has been the standard HF propagation prediction tool since the 1980s. Built on decades of ionospheric research at NTIA/ITS, it uses empirical ionospheric coefficients and ray-tracing geometry to estimate circuit reliability for voice communication.</p> <p>IONIS takes a fundamentally different approach: learn propagation behavior directly from 14 billion real radio observations, constrained by known physics.</p> <p>This page documents where we are, what we've proven, and what we're still working on.</p>"},{"location":"model/physics-vs-ml/#validating-neural-networks-vs-voacap-v20-baseline","title":"Validating Neural Networks vs. VOACAP (V20 Baseline)","text":"<p>IONIS V20 was the first production model validated against both historical contest data and live PSK Reporter observations. The results established that a physics-constrained neural network can outperform empirical models on real amateur radio paths.</p>"},{"location":"model/physics-vs-ml/#head-to-head-1-million-contest-paths","title":"Head-to-Head: 1 Million Contest Paths","text":"<p>Both models were given 1M real contest QSOs (CQ WW, CQ WPX, ARRL DX \u2014 2005 to 2025) and asked: \"was this band open?\" Every QSO actually happened, so the ground truth is always YES.</p> Model Recall Delta IONIS V20 96.38% \u2014 VOACAP 0.7.5 75.82% -20.56 pp <p>The gap was largest on 10m (+38.1 pp) where VOACAP misses sporadic-E and day-to-day solar variability, and on SSB (+22.6 pp) \u2014 the mode VOACAP was specifically designed for.</p> <p>See IONIS vs VOACAP Comparison for full results by mode and band.</p>"},{"location":"model/physics-vs-ml/#independent-live-validation","title":"Independent Live Validation","text":"<p>V20 achieved 84.14% recall on 100K live PSK Reporter spots the model had never seen during training. This confirmed that IONIS generalizes to independent real-time data, not just historical patterns.</p>"},{"location":"model/physics-vs-ml/#physics-constraints-hold","title":"Physics Constraints Hold","text":"<p>The architecture enforces two non-negotiable ionospheric laws through monotonic neural network sidecars:</p> <ul> <li>Sun sidecar: Higher solar flux (SFI) always improves propagation (+0.482\u03c3, ~3.2 dB)</li> <li>Storm sidecar: Higher geomagnetic activity (Kp) always degrades propagation (+3.487\u03c3, ~23.4 dB)</li> </ul> <p>These constraints cannot be overridden by the DNN trunk. See Monotonic Sidecars for the full design.</p>"},{"location":"model/physics-vs-ml/#refining-the-deep-learning-architecture-auroral-zones-and-daynight-physics","title":"Refining the Deep Learning Architecture: Auroral Zones and Day/Night Physics","text":"<p>V20 proved the architecture works. The ongoing refinement series focuses on giving the model better tools to distinguish when and where propagation behaves differently \u2014 auroral zone vulnerability, band-specific day/night behavior, and the separation of storm physics from temporal artifacts.</p>"},{"location":"model/physics-vs-ml/#modeling-auroral-zone-vulnerability-for-polar-hf-paths","title":"Modeling Auroral Zone Vulnerability for Polar HF Paths","text":"<p>Problem: V20 treated all paths equally during geomagnetic storms. In reality, a path crossing the auroral zone (high latitude) is far more vulnerable to storm absorption than an equatorial path at the same Kp.</p> <p>Solution: <code>vertex_lat</code> \u2014 the latitude of the highest point on the great circle path. Computed from TX/RX grids via spherical trigonometry:</p> <pre><code>vertex_lat = arccos(|sin(bearing) * cos(tx_lat)|)\n</code></pre> <p>High vertex latitude means the path crosses the polar region where storm particles precipitate. Low vertex latitude means the path stays in the mid-latitudes where storms have minimal effect. This gives the Kp sidecar path-specific context instead of treating storms as a global scalar.</p>"},{"location":"model/physics-vs-ml/#the-10-mhz-pivot-mathematically-modeling-day-and-night-hf-bands","title":"The 10 MHz Pivot: Mathematically Modeling Day and Night HF Bands","text":"<p>Problem: Darkness helps low-band propagation (160m, 80m, 40m) but kills high-band propagation (10m, 15m, 17m, 20m). The crossover is around 10 MHz (30m band). V20 had no way to express this \u2014 the model could learn that darkness matters, but not that it matters in opposite directions depending on frequency.</p> <p>Solution: Solar depression angles at both TX and RX locations, combined with frequency-centered cross-products:</p> <ul> <li><code>tx_solar_dep</code>, <code>rx_solar_dep</code> \u2014 continuous day/night indicators (positive = daylight, negative = darkness depth)</li> <li><code>freq_centered = (freq_mhz - 10.0) / scale</code> \u2014 centers frequency around the 10 MHz ionospheric crossover</li> <li><code>freq_x_tx_dark</code>, <code>freq_x_rx_dark</code> \u2014 cross-products that flip sign at the pivot</li> </ul> <p>When the cross-product is positive (high band + darkness, or low band + daylight), propagation is degraded. When negative (high band + daylight, or low band + darkness), propagation is enhanced. The model learns the magnitude; the math enforces the direction.</p>"},{"location":"model/physics-vs-ml/#isolating-geomagnetic-storm-physics-from-temporal-artifacts","title":"Isolating Geomagnetic Storm Physics from Temporal Artifacts","text":"<p>An unexpected discovery during V21 training: the V20 storm sidecar's +3.49\u03c3 cost was approximately 60% temporal contamination. The sidecar had been compensating for missing time-of-day features \u2014 storms correlate with certain hours, and without explicit day/night tools, the Kp sidecar absorbed that temporal signal.</p> <p>Adding solar depression angles gave the DNN trunk its own time-of-day tools. The Kp sidecar shed its temporal weight and distilled down to pure geomagnetic storm physics. This is the correct behavior: the sidecar should model absorption and fading, not sunrise timing.</p> <p>The SFI/Kp asymmetry (~3:1 ratio in sigma) is itself physically meaningful. Solar flux acts like a power plant \u2014 it lifts the MUF with diminishing returns as ionization saturates. Geomagnetic storms act like a governor \u2014 D-layer absorption is violent and nonlinear with no ceiling. Building is bounded; destroying is not.</p>"},{"location":"model/physics-vs-ml/#scaling-training-data-integrating-2-billion-cwrtty-observations","title":"Scaling Training Data: Integrating 2 Billion CW/RTTY Observations","text":"<p>V17\u2013V19 failed when RBN data (2.18B CW/RTTY spots) was added to training. The post-mortem revealed this wasn't because RBN data was poison \u2014 the architectural constraints were incomplete. With the V16 Physics Laws intact plus the frequency pivot, V22 tests whether the \"container\" is now strong enough to hold the full dataset.</p> <p>RBN provides critical low-band coverage: 3.18M 160m signatures (nearly 2x WSPR's 1.69M on that band) and 16.3% low-band concentration versus WSPR's 8.1%. If the model needs to learn 160m behavior, it needs RBN data to learn from.</p>"},{"location":"model/physics-vs-ml/#where-voacap-still-has-physics-we-dont","title":"Where VOACAP Still Has Physics We Don't","text":"<p>VOACAP's empirical coefficients encode 60 years of ionospheric measurement campaigns. Some of that physics is not yet available to IONIS:</p> <p>Path-specific ionospheric state: VOACAP uses ionospheric models to compute the critical frequency (foF2) and peak height (hmF2) at each point along the path. IONIS receives only a global solar flux index \u2014 two paths at the same SFI can have wildly different ionospheric conditions depending on latitude, local time, season, and magnetic geometry.</p> <p>MUF estimation: VOACAP computes the Maximum Usable Frequency for each circuit. IONIS infers this indirectly from frequency, distance, and solar features. A direct MUF signal would tell the model immediately whether the operating frequency can propagate.</p> <p>D-layer absorption: VOACAP models absorption through the D and E layers explicitly. IONIS handles this through the Kp sidecar globally, without path-specific absorption context.</p> <p>These gaps point directly to the next phase of model development.</p>"},{"location":"model/physics-vs-ml/#next-physics-model-integration","title":"Next: Physics Model Integration","text":"<p>Two open-source tools fill the gaps between what IONIS has learned and what ionospheric physics can provide:</p> <p>dvoacap-python (pure Python VOACAP port) enables systematic comparison: generate VOACAP predictions for every path in the validation set, then build a diagnostic matrix showing where IONIS succeeds and VOACAP fails, where VOACAP succeeds and IONIS fails, and where both struggle. The paths where VOACAP is right and IONIS is wrong point to known physics we haven't captured yet.</p> <p>PyIRI (pure Python IRI-2020) provides the path-specific ionospheric features IONIS currently lacks. IRI computes foF2, hmF2, and foE for any location, date, and solar activity level \u2014 covering the full training dataset from 1958 to present with no coverage gaps. The foF2/frequency ratio is particularly valuable: it tells the model directly whether the operating frequency is above or below the MUF at each point along the path.</p> <p>These features would replace the global SFI scalar with a path-specific ionospheric scalpel \u2014 giving the model the same physics VOACAP has, plus everything it learns from 14 billion observations that VOACAP has never seen.</p>"},{"location":"model/physics-vs-ml/#the-larger-picture","title":"The Larger Picture","text":"<p>Empirical models like VOACAP represent the ceiling of what physics alone can predict from averaged ionospheric measurements. Neural networks like IONIS represent what machine learning can extract from billions of individual observations. Neither approach is complete on its own.</p> <p>The path forward combines both: use physics models to diagnose where the neural network is weak, use ionospheric models to provide features the neural network can't derive from radio data alone, and use the neural network to capture patterns that no empirical model can express \u2014 sporadic-E openings, trans-equatorial propagation, grey-line enhancement, and the thousands of subtle effects buried in 14 billion data points.</p> <p>The logs were speaking for decades. Now we're listening \u2014 and teaching a model to understand what they're saying.</p>"},{"location":"model/physics-vs-ml/#project-resources","title":"Project Resources","text":"<ul> <li>Validation Suite: ionis-validate on PyPI \u2014 run the 29-test operator-grounded physics battery locally</li> <li>Live Predictions: ham-stats.com \u2014 band conditions and IONIS predictions updated every 3 hours</li> <li>Source Code: IONIS-AI on GitHub \u2014 all repos, open source, GPLv3</li> <li>VOACAP Comparison Data: Full results by mode and band</li> <li>Model Architecture: IonisGate and Monotonic Sidecars</li> </ul>"},{"location":"model/architecture/ionisgate/","title":"IonisGate Architecture","text":"<p>Production: IONIS V22-gamma + PhysicsOverrideLayer</p> <p>IonisGate architecture validated with V22-gamma production checkpoint.</p> <ul> <li>Pearson: +0.492</li> <li>RMSE: 0.821\u03c3 (~5.5 dB)</li> <li>KI7MT operator tests: 17/17 PASS</li> <li>TST-900 band x time: 9/11</li> <li>Parameters: 205,621</li> <li>PhysicsOverrideLayer: deterministic high-band night clamp</li> </ul>"},{"location":"model/architecture/ionisgate/#design-rationale","title":"Design Rationale","text":"<p>An additive sidecar architecture produces global constants \u2014 the same SFI benefit and Kp penalty for every path on Earth:</p> Finding Impact Storm cost is flat everywhere Polar paths should suffer 3\u20135x more SFI benefit is flat on all bands 10m should benefit far more than 160m No geographic modulation of solar effects Equatorial vs. auroral zones identical <p>The DNN cannot modulate the sidecars because the interaction is purely additive. The sidecars are \"tone-deaf\" to geography and frequency.</p>"},{"location":"model/architecture/ionisgate/#solution-multiplicative-interaction-gates","title":"Solution: Multiplicative Interaction Gates","text":"<pre><code>output = base_snr + sun_scaler \u00d7 SunSidecar(sfi)\n                  + storm_scaler \u00d7 StormSidecar(kp)\n</code></pre> <p>The DNN splits into a shared trunk with three heads:</p> <pre><code>Input (17 features)\n    \u2502\n    \u251c\u2500\u2500 features 0-14 (geography/time/solar depression)\n    \u2502       \u2502\n    \u2502    Trunk: 15 \u2192 512 \u2192 256\n    \u2502       \u2502\n    \u2502       \u251c\u2500\u2500 Base Head: 256 \u2192 128 \u2192 1  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba base_snr\n    \u2502       \u2502\n    \u2502       \u251c\u2500\u2500 Sun Scaler: 256 \u2192 64 \u2192 1 \u2192 gate() \u2500\u2500\u25ba sun_scaler \u2208 [0.5, 2.0]\n    \u2502       \u2502                                              \u2502\n    \u2502       \u2514\u2500\u2500 Storm Scaler: 256 \u2192 64 \u2192 1 \u2192 gate() \u2500\u2500\u25ba storm_scaler \u2208 [0.5, 2.0]\n    \u2502                                                      \u2502\n    \u251c\u2500\u2500 feature 15 (sfi) \u2500\u2500\u25ba SunSidecar(8) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u00d7 sun_scaler \u2500\u2500\u25ba sun_term\n    \u2502                                                                    \u2502\n    \u2514\u2500\u2500 feature 16 (kp_penalty) \u2500\u2500\u25ba StormSidecar(8) \u2500\u2500 \u00d7 storm_scaler \u2500\u2500\u25ba storm_term\n                                                                          \u2502\n                                                Output = base_snr + sun_term + storm_term\n</code></pre>"},{"location":"model/architecture/ionisgate/#gate-function","title":"Gate Function","text":"<pre><code>gate(x) = 0.5 + 1.5 \u00d7 sigmoid(x)\n</code></pre> Property Value Purpose Range [0.5, 2.0] Never zero, never too large Identity x = -ln(2) \u2248 -0.693 gate(-0.693) = 1.0 Differentiable Everywhere Standard backprop Bounded Always Cannot reverse sidecar direction <p>The gate acts as a volume control: it can turn the sidecar effect up (to 2x) or down (to 0.5x), but it can never mute it entirely or reverse it. This preserves the monotonic physics guarantee.</p>"},{"location":"model/architecture/ionisgate/#what-the-gates-enable","title":"What the Gates Enable","text":"Scenario sun_scaler storm_scaler Physical Meaning 10m equatorial path &gt; 1.0 &lt; 1.0 Strong SFI benefit, mild storm impact 160m high-latitude path &lt; 1.0 &gt; 1.0 Weak SFI benefit, severe storm impact 20m mid-latitude (reference) \u2248 1.0 \u2248 1.0 Baseline behavior"},{"location":"model/architecture/ionisgate/#parameter-budget","title":"Parameter Budget","text":"Component Parameters Trunk (15\u2192512\u2192256) 139,520 Base head (256\u2192128\u21921) 33,025 Sun scaler head (256\u219264\u21921) 16,513 Storm scaler head (256\u219264\u21921) 16,513 Sun Sidecar (1\u21928\u21921) 25 Storm Sidecar (1\u21928\u21921) 25 Total 205,621"},{"location":"model/architecture/ionisgate/#physicsoverridelayer-post-inference","title":"PhysicsOverrideLayer (Post-Inference)","text":"<p>A deterministic, non-trainable clamp applied after model inference:</p> <pre><code>IF freq &gt;= 21 MHz\n   AND tx_solar_depression &lt; -6\u00b0\n   AND rx_solar_depression &lt; -6\u00b0\n   AND prediction &gt; -1.0\u03c3\nTHEN clamp prediction to -1.0\u03c3\n</code></pre> <p>This closes high bands (15m, 12m, 10m) when both endpoints are in darkness. The override fires only when the neural network produces a physically impossible positive prediction for nighttime high-band paths. Pure numpy \u2014 no gradients, no training interference.</p>"},{"location":"model/architecture/ionisgate/#anti-collapse-regularization","title":"Anti-Collapse Regularization","text":"<p>Without explicit encouragement, the optimizer may find it easier to keep the scaler heads constant (collapsing to gate \u2248 1.0 everywhere). The scaler variance loss prevents this:</p> <pre><code>L_var = -\u03bb \u00d7 (Var(sun_gate) + Var(storm_gate))\n</code></pre> <p>Negative variance is added to the total loss, so the optimizer is incentivized to produce diverse gate values across the batch. If the gates collapse to a constant, the variance term becomes zero and the penalty is maximized.</p>"},{"location":"model/architecture/ionisgate/#sidecar-constraints","title":"Sidecar Constraints","text":"<p>The sidecars enforce physics constraints the DNN cannot override:</p> Property Value Enforced by Architecture MonotonicMLP (1\u21928\u21921) Class definition Weight range [0.5, 2.0] Post-optimizer clamp Monotonicity Non-negative weights via abs() Forward pass fc1.bias Frozen requires_grad = False fc2.bias Learnable Relief valve for calibration Activation Softplus Smooth, always positive slope <p>The DNN can only \"turn up or down the volume\" on the sidecar output \u2014 it cannot reverse the direction. Higher SFI always helps; storms always hurt. The gates modulate how much, not whether.</p>"},{"location":"model/architecture/ionisgate/#gate-initialization","title":"Gate Initialization","text":"<p>For identity-equivalent behavior at initialization:</p> <ol> <li><code>gate(x) = 1.0</code> when <code>sigmoid(x) = 1/3</code></li> <li><code>sigmoid(x) = 1/3</code> when <code>x = -ln(2) \u2248 -0.693</code></li> <li>Set final layer bias of each scaler head to -0.693</li> <li>Zero-initialize final layer weights so output \u2248 -0.693 for all inputs</li> </ol> <p>This ensures the model starts training from a known baseline \u2014 the gates are invisible until training data drives them to differentiate by geography and frequency.</p>"},{"location":"model/architecture/ionisgate/#files","title":"Files","text":"File Purpose <code>ionis-training/scripts/models/ionisgate.py</code> PyTorch module + self-verification <code>ionis-docs/docs/architecture/ionisgate.md</code> This document"},{"location":"model/architecture/sidecars/","title":"Monotonic Sidecars \u2014 Physics Constraints","text":""},{"location":"model/architecture/sidecars/#the-problem","title":"The Problem","text":"<p>WSPR data contains survivorship bias: during geomagnetic storms (high Kp), only strong signals are decoded. A naive DNN learns \"storms = good\" \u2014 the Kp Inversion Problem.</p>"},{"location":"model/architecture/sidecars/#the-solution-dual-monotonic-sidecars","title":"The Solution: Dual Monotonic Sidecars","text":"<p>Two small MonotonicMLP networks enforce physics constraints that the DNN cannot override:</p>"},{"location":"model/architecture/sidecars/#sun-sidecar-sfi-snr-boost","title":"Sun Sidecar (SFI \u2192 SNR boost)","text":"<ul> <li>Input: Solar Flux Index (SFI), normalized as SFI / 300</li> <li>Constraint: Monotonic increasing \u2014 higher SFI always improves SNR</li> <li>Physics: More solar flux \u2192 more ionization \u2192 better HF propagation</li> </ul>"},{"location":"model/architecture/sidecars/#storm-sidecar-kp-snr-penalty","title":"Storm Sidecar (Kp \u2192 SNR penalty)","text":"<ul> <li>Input: <code>kp_penalty = 1 - Kp/9</code> (inverted so monotonic increasing = storms degrade)</li> <li>Constraint: Monotonic increasing \u2014 higher penalty (lower Kp) always improves SNR</li> <li>Physics: Geomagnetic storms \u2192 ionospheric disturbance \u2192 absorption/fading</li> </ul>"},{"location":"model/architecture/sidecars/#relief-valve-design","title":"Relief Valve Design","text":"Parameter Value Purpose Weight Clamp Range 0.5 \u2013 2.0 Prevents collapse AND explosion fc1.bias Frozen Maintains activation shape fc2.bias Learnable (-10.65) Relief valve for calibration Initial fc2.bias -10.0 Defibrillator jump-start"},{"location":"model/architecture/sidecars/#physics-verification","title":"Physics Verification","text":"Test Condition Result Grade Sun Test SFI 70 \u2192 200 +0.482\u03c3 (~3.2 dB) PASS Storm Test Kp 0 \u2192 9 +3.487\u03c3 (~23.4 dB) PASS Polar Storm Kp 2 \u2192 8 (polar) +2.5 dB PASS D-Layer 80m vs 20m noon +0.0 dB PASS <p>Training on aggregated signatures shows strong physics response with correct monotonicity.</p>"},{"location":"model/architecture/sidecars/#sfi-kp-matrix","title":"SFI \u00d7 Kp Matrix","text":"<p>Reference path: W3 \u2192 G (5,900 km, 20m)</p> SFI \\ Kp Kp=0 Kp=2 Kp=5 Kp=9 SFI 70 -20.0 -21.1 -22.0 -24.0 SFI 150 -19.0 -20.0 -21.0 -23.0 SFI 200 -18.0 -19.0 -20.0 -22.0 <p>Down = higher SFI = better. Right = higher Kp = worse. Correct physics.</p>"},{"location":"model/methodology/bronze_stack/","title":"Bronze Stack","text":"<p>Reproduction guide for the IONIS bronze layer \u2014 raw data loaded into ClickHouse from source archives on ZFS.</p>"},{"location":"model/methodology/bronze_stack/#overview","title":"Overview","text":"<p>The bronze stack contains raw and lightly transformed data loaded directly from source archives. All tables are reproducible from ZFS-stored archives using deterministic DDL and CLI tools from <code>ionis-core</code> and <code>ionis-apps</code>.</p> <p>Bronze is self-contained \u2014 users who only need the dataset can stop here.</p>"},{"location":"model/methodology/bronze_stack/#prerequisites","title":"Prerequisites","text":"<ol> <li>ClickHouse running on the target host (default <code>192.168.1.90</code>)</li> <li>ZFS datasets mounted:<ul> <li><code>/mnt/wspr-data</code> \u2014 WSPR raw CSV archives (.csv.gz)</li> <li><code>/mnt/contest-logs</code> \u2014 CQ + ARRL Cabrillo log files</li> <li><code>/mnt/rbn-data</code> \u2014 RBN daily ZIP archives</li> <li><code>/mnt/pskr-data</code> \u2014 PSK Reporter MQTT collection (gzip JSONL)</li> </ul> </li> <li>RPM packages installed (v3.0.6+):<ul> <li><code>ionis-core</code> \u2014 DDL schemas (32 files), population scripts (12 files), and static data</li> <li><code>ionis-apps</code> \u2014 Go ingesters (wspr-turbo, rbn-ingest, contest-ingest, solar-backfill, pskr-ingest)</li> </ul> </li> </ol>"},{"location":"model/methodology/bronze_stack/#step-1-apply-ddl-schemas","title":"Step 1: Apply DDL Schemas","text":"<p>All DDL files live in <code>/usr/share/ionis-core/ddl/</code> (installed by the RPM). Each file is idempotent (<code>CREATE TABLE IF NOT EXISTS</code>). Apply in numerical order:</p> <pre><code>for f in /usr/share/ionis-core/ddl/*.sql; do\n    echo \"Applying: $f\"\n    clickhouse-client --multiquery &lt; \"$f\"\ndone\n</code></pre> <pre><code>DDL Files (32 total):\n\n  #   File                              Database      Creates\n  --  --------------------------------  -----------   ----------------------------------------\n  01  wspr_schema_v2.sql                wspr          bronze, v_schema_contract, v_data_integrity\n  02  solar_indices.sql                 solar         bronze\n  03  solar_silver.sql                  solar         v_daily_indices\n  04  data_mgmt.sql                     data_mgmt     config\n  05  geo_functions.sql                 geo           v_grid_validation_example\n  06  lab_versions.sql                  data_mgmt     lab_versions, v_lab_versions_latest\n  07  callsign_grid.sql                 wspr          callsign_grid\n  08  model_features.sql                wspr          silver\n  09  quality_distribution_mv.sql       wspr          v_quality_distribution (MV \u2192 silver)\n  10  rbn_schema_v1.sql                 rbn           bronze\n  11  contest_schema_v1.sql             contest       bronze\n  12  signatures_v1.sql                 wspr          signatures_v1\n  13  training_stratified.sql           wspr          gold_stratified\n  14  training_continuous.sql           wspr          gold_continuous\n  15  training_v6_clean.sql             wspr          gold_v6\n  16  validation_step_i.sql             validation    step_i_paths, step_i_voacap\n  17  balloon_callsigns.sql             wspr          balloon_callsigns\n  18  validation_quality_test.sql       validation    quality_test_paths, quality_test_voacap\n  19  dxpedition_synthesis.sql          dxpedition    catalog; rbn.dxpedition_paths\n  20  signatures_v2_terrestrial.sql     wspr          signatures_v2_terrestrial\n  21  balloon_callsigns_v2.sql          wspr          balloon_callsigns_v2\n  22  pskr_schema_v1.sql                pskr          bronze\n  23  contest_signatures.sql            contest       signatures\n  24  rbn_signatures.sql                rbn           signatures\n  25  live_conditions.sql               wspr          live_conditions\n  26  validation_model_results.sql      validation    model_results\n  27  mode_thresholds.sql               validation    mode_thresholds\n  28  pskr_ingest_log.sql               pskr          ingest_log\n  29  rbn_dxpedition_signatures.sql     rbn           dxpedition_signatures\n  30  rbn_ingest_log.sql                rbn           ingest_log\n  31  wspr_ingest_log.sql               wspr          ingest_log\n  32  contest_ingest_log.sql            contest       ingest_log\n</code></pre> <p>DDL 09 depends on DDL 08</p> <p>The <code>v_quality_distribution</code> materialized view reads from <code>wspr.silver</code>. DDL 08 must be applied first. Sequential numbering handles this automatically.</p>"},{"location":"model/methodology/bronze_stack/#step-2-load-solar-data","title":"Step 2: Load Solar Data","text":"<p>Load historical SSN, SFI, and Kp from GFZ Potsdam. This must run before WSPR so that solar indices are available for downstream JOINs.</p> <pre><code>solar-backfill -start 2000-01-01\nclickhouse-client --query \"OPTIMIZE TABLE solar.bronze FINAL\"\n</code></pre> <p>Additional solar sources</p> <p><code>solar-backfill</code> loads GFZ Potsdam historical data only (~76K rows). Additional data comes from <code>solar-history-load</code> (NOAA, 6-hour cron) and <code>solar-live-update</code> (SWPC, 15-min cron). Run those manually or wait for cron cycles to fully populate <code>solar.bronze</code> and <code>wspr.live_conditions</code>.</p> <p>Verification:</p> <pre><code>clickhouse-client --query \"SELECT count() FROM solar.bronze\"\n# Expected: ~76,000 (GFZ only; grows with NOAA cron)\n\nclickhouse-client --query \"SELECT min(date), max(date) FROM solar.bronze\"\n# Expected: 2000-01-01 to ~today\n</code></pre>"},{"location":"model/methodology/bronze_stack/#step-3-load-wspr-data","title":"Step 3: Load WSPR Data","text":"<p>Stream all WSPR CSV archives into ClickHouse. This is the largest ingest and uses 16 workers \u2014 run it alone to avoid OOM.</p> <pre><code>wspr-turbo -ch-host 192.168.1.90:9000 -source-dir /mnt/wspr-data -workers 16\n</code></pre> <p>Run wspr-turbo solo</p> <p>With 16 workers, wspr-turbo consumes ~80 GB RAM. Do not run other ingesters concurrently.</p> <p>Verification:</p> <pre><code>clickhouse-client --query \"SELECT count() FROM wspr.bronze\"\n# Expected: ~10,800,000,000\n\nclickhouse-client --query \"SELECT uniq(band) FROM wspr.bronze WHERE band BETWEEN 102 AND 111\"\n# Expected: 10 (all HF bands)\n</code></pre>"},{"location":"model/methodology/bronze_stack/#step-4-load-rbn-data","title":"Step 4: Load RBN Data","text":"<p>Ingest Reverse Beacon Network CW/RTTY spots from daily ZIP archives.</p> <pre><code>rbn-ingest -host 192.168.1.90:9000 -src /mnt/rbn-data\n</code></pre> <p>Verification:</p> <pre><code>clickhouse-client --query \"SELECT count() FROM rbn.bronze\"\n# Expected: ~2,180,000,000\n</code></pre>"},{"location":"model/methodology/bronze_stack/#step-5-load-contest-data","title":"Step 5: Load Contest Data","text":"<p>Parse CQ and ARRL Cabrillo log files. The <code>-enrich</code> flag populates <code>wspr.callsign_grid</code> from logs that contain grid locator headers.</p> <pre><code>contest-ingest -host 192.168.1.90:9000 -src /mnt/contest-logs -enrich\n</code></pre> <p>Verification:</p> <pre><code>clickhouse-client --query \"SELECT count() FROM contest.bronze\"\n# Expected: ~234,000,000\n\nclickhouse-client --query \"SELECT contest, count() FROM contest.bronze GROUP BY contest ORDER BY count() DESC FORMAT PrettyCompact\"\n\nclickhouse-client --query \"SELECT count() FROM wspr.callsign_grid FINAL\"\n# Expected: ~38,500 (from contest enrichment)\n</code></pre>"},{"location":"model/methodology/bronze_stack/#step-6-load-psk-reporter-data","title":"Step 6: Load PSK Reporter Data","text":"<p>Ingest collected PSK Reporter MQTT spots from gzip JSONL files. Uses <code>pskr.ingest_log</code> watermark to track loaded files.</p> <pre><code># First run: load all collected files\npskr-ingest --src /mnt/pskr-data --host 192.168.1.90:9000\n\n# Subsequent runs (cron): only loads new files since last run\npskr-ingest --src /mnt/pskr-data --host 192.168.1.90:9000\n</code></pre> <p>The <code>--min-age</code> flag (default 5 min) automatically skips the currently-open hourly rotation file being written by <code>pskr-collector</code>.</p> <p>Verification:</p> <pre><code>clickhouse-client --query \"SELECT count() FROM pskr.bronze\"\n# Expected: varies (depends on collection window; ~26M spots/day since 2026-02-10)\n\nclickhouse-client --query \"SELECT count() FROM pskr.ingest_log FINAL WHERE row_count &gt; 0\"\n# Shows how many files have been loaded\n</code></pre>"},{"location":"model/methodology/bronze_stack/#qa-actuals","title":"QA Actuals","text":"<p>Clean-slate rebuild on 9975WX (2026-02-13):</p> <pre><code>Table                Rows              Time     Throughput\n-------------------  ----------------  -------  ----------\nsolar.bronze         76,000+           &lt;1s      --\nwspr.bronze          10,798,087,395    8m13s    21.91 Mrps\nrbn.bronze           2,184,591,303     3m32s    10.30 Mrps\ncontest.bronze       234,268,090       21m32s   --\npskr.bronze          81,000,000+       varies   --\nwspr.callsign_grid   38,622            --       (contest enrichment)\n-------------------  ----------------  -------  ----------\nTotal wall time      ~35 min (sequential, excluding pskr)\n</code></pre>"},{"location":"model/methodology/bronze_stack/#next-steps","title":"Next Steps","text":"<ul> <li>Silver layer: See Silver Layer for CUDA embeddings and aggregated signatures</li> <li>Gold layer: See Gold Layer for training tables and CSV export</li> </ul>"},{"location":"model/methodology/coverage/","title":"Coverage &amp; Confidence","text":"<p>Garbage in, garbage out. If we don't have coverage, we don't have a high-confidence model.</p>"},{"location":"model/methodology/coverage/#the-problem","title":"The Problem","text":"<p>IONIS learns from real observations. But the ionosphere doesn't care about our data collection \u2014 paths exist whether anyone is listening or not. The model can only be as good as the data that feeds it.</p> <p>32,400 possible grids. The Maidenhead grid system has 18 longitude fields (A-R) \u00d7 18 latitude fields \u00d7 10 longitude squares \u00d7 10 latitude squares = 32,400 unique 4-character grid locators.</p> <p>Not all grids are equal:</p> <ul> <li>Dense coverage: FN31 (Northeast US), JN48 (Central Europe) \u2014 thousands   of active stations, high observation counts</li> <li>Sparse coverage: Remote land areas with few stations \u2014 limited observations</li> <li>Permanent gaps: Mid-ocean grids, Antarctica, uninhabited regions \u2014 no   stations possible (but propagation still happens)</li> </ul>"},{"location":"model/methodology/coverage/#interpolation-vs-observation","title":"Interpolation vs Observation","text":"<p>When IONIS has direct observations for a path (e.g., FN31\u2192JN48 on 20m at 14 UTC), confidence is high. The model learned from actual measurements.</p> <p>When IONIS has no observations for a path, it must interpolate from nearby grids, similar hours, adjacent bands. The further the interpolation, the lower the confidence should be.</p> <p>Analogy: Weather forecasts are more accurate where there are weather stations. Predictions for the middle of the ocean rely on satellite data and models, not ground truth. Same principle here.</p>"},{"location":"model/methodology/coverage/#coverage-as-a-confidence-metric","title":"Coverage as a Confidence Metric","text":"<p>A coverage analysis would provide:</p> <ol> <li> <p>Observation density map: For each of the 32,400 grids, count observations    (as TX, as RX, or both). Visualize as a heatmap.</p> </li> <li> <p>Gap classification:</p> </li> <li>Permanent gaps: Ocean, uninhabited \u2014 mark as \"interpolation only\"</li> <li>Sparse coverage: &lt; N observations \u2014 mark as \"low confidence\"</li> <li> <p>Dense coverage: &gt; M observations \u2014 mark as \"high confidence\"</p> </li> <li> <p>Interpolation distance: For any query path, calculate the \"distance\" to    the nearest observed signatures. Longer distance = lower confidence.</p> </li> <li> <p>Per-band breakdown: 10m coverage differs from 40m coverage. Report    confidence per band.</p> </li> </ol>"},{"location":"model/methodology/coverage/#why-this-matters","title":"Why This Matters","text":"<p>When IONIS predicts \"20m open from FN31 to JN48 at 14 UTC with SNR -8 dB\", a coverage metric could add:</p> <ul> <li>Confidence: HIGH \u2014 50,000 observations for this path/band/hour combination</li> <li>Confidence: MEDIUM \u2014 500 observations, reliable pattern</li> <li>Confidence: LOW \u2014 5 observations, use with caution</li> <li>Confidence: INTERPOLATED \u2014 No direct observations, prediction based on   nearby grids</li> </ul> <p>This helps users understand when to trust the prediction and when to be skeptical.</p>"},{"location":"model/methodology/coverage/#implementation-notes","title":"Implementation Notes","text":"<p>The coverage analysis is a roadmap candidate, not yet implemented. When built:</p> <ul> <li>Query <code>wspr.signatures_v2_terrestrial</code> for grid observation counts</li> <li>Cross-reference with RBN and contest data for additional coverage</li> <li>Generate static heatmaps for documentation</li> <li>Consider adding confidence scores to IONIS inference output</li> </ul>"},{"location":"model/methodology/coverage/#related","title":"Related","text":"<ul> <li>Aggregated Signatures \u2014 how observations become signatures</li> </ul> <p>Last updated: 2026-02-08</p>"},{"location":"model/methodology/data_pipeline/","title":"Data Pipeline","text":""},{"location":"model/methodology/data_pipeline/#wspr-ingestion","title":"WSPR Ingestion","text":"<p>Source: 10.94B WSPR spots from wsprnet.org CSV archives</p> Tool Method Throughput <code>wspr-turbo</code> Streaming .gz \u2192 ClickHouse 22.55 Mrps (16 workers) <code>wspr-shredder</code> Raw CSV \u2192 ClickHouse 21.81 Mrps <p>All ingesters normalize band via <code>bands.GetBand(freqMHz)</code> \u2014 single source of truth.</p>"},{"location":"model/methodology/data_pipeline/#band-ids-adif","title":"Band IDs (ADIF)","text":"ID Band ID Band 102 160m 108 17m 103 80m 109 15m 104 60m 110 12m 105 40m 111 10m 106 30m 107 20m"},{"location":"model/methodology/data_pipeline/#solar-pipeline","title":"Solar Pipeline","text":"<p>Source: GFZ Potsdam (SSN, SFI, Kp) \u2014 ~17,840 rows, 2000-2026</p> Tool Schedule Purpose <code>solar-live-update</code> 15-min cron Real-time NOAA/SIDC <code>solar-history-load</code> 6-hour cron Historical backfill <code>solar-backfill</code> Manual GFZ Potsdam 1932\u2013present"},{"location":"model/methodology/data_pipeline/#kp-alignment","title":"Kp Alignment","text":"<p>WSPR spots are aligned with Kp values using 3-hour bucket JOINs:</p> <pre><code>intDiv(toHour(timestamp), 3)\n</code></pre> <p>This matches the Kp publication cadence from GFZ Potsdam.</p>"},{"location":"model/methodology/data_pipeline/#cuda-signature-engine","title":"CUDA Signature Engine","text":"<p>Generates float4 embeddings from WSPR+solar data:</p> <ul> <li>Input: <code>wspr.bronze</code> + <code>solar.bronze</code></li> <li>Output: <code>wspr.silver</code> (4.4B embeddings, 41 GiB)</li> <li>Throughput: 4.43B embeddings in 45m13s</li> </ul>"},{"location":"model/methodology/data_pipeline/#rbn-ingestion","title":"RBN Ingestion","text":"<p>Source: 2.26B Reverse Beacon Network spots from daily ZIP archives (2009-02-21 to 2026)</p> Tool Method Throughput <code>rbn-download</code> Daily ZIP download \u2192 <code>/mnt/rbn-data</code> 6,183 daily files <code>rbn-ingest</code> CSV \u2192 ClickHouse (<code>rbn.bronze</code>) 2.26B rows in 3m35s (10.15 Mrps) <ul> <li>Archive: <code>https://data.reversebeacon.net/rbn_history/YYYYMMDD.zip</code></li> <li>Size: ~21 GB compressed, ~135 GB uncompressed</li> <li>Format: CSV, 13 columns: <code>callsign, de_pfx, de_cont, freq, band, dx, dx_pfx, dx_cont, mode, db, date, speed, tx_mode</code></li> <li>Limitation: No grid squares for transmitters \u2014 requires callsign-to-grid mapping (Rosetta Stone)</li> <li>Grid coverage: 525.8M spots geocoded (24.07%) via <code>wspr.callsign_grid</code>; 121,307 of 2.12M unique DX callsigns matched (5.71%)</li> <li>Zero failures, zero skipped rows on full ingest</li> </ul>"},{"location":"model/methodology/data_pipeline/#contest-log-ingestion","title":"Contest Log Ingestion","text":"<p>Source: 491K Cabrillo log files across 15 contests (CQ + ARRL, 2005-2025)</p> Tool Method Throughput <code>contest-download</code> Index scrape + hash-based download \u2192 <code>/mnt/contest-logs</code> 491K files, 3.5 GB <code>contest-ingest</code> Cabrillo V2/V3 parser \u2192 ClickHouse (<code>contest.bronze</code>) 234M QSOs"},{"location":"model/methodology/data_pipeline/#contests-downloaded","title":"Contests Downloaded","text":"Source Contests Years Files CQ WW, WPX, WPX-RTTY, WW-RTTY, 160, WW-Digi 2005-2025 ~120 log sets ARRL DX CW/Ph, SS CW/Ph, 10m, 160m, RTTY, Digi, IARU HF 2018-2025 ~475K logs <ul> <li>Format: Cabrillo v2 and v3 (parser handles both)</li> <li>Bonus: 98.5% of ARRL logs include <code>HQ-GRID-LOCATOR</code> header \u2014 free grid squares</li> <li>Limitation: Signal reports useless (always 59/599) except digital contests</li> <li>Download etiquette: Rate limited (2-3s delays), max 3 concurrent ARRL streams</li> </ul>"},{"location":"model/methodology/data_pipeline/#propagation-data-sources","title":"Propagation Data Sources","text":"<p>Four pillars of propagation truth, each on a dedicated ZFS dataset:</p> Source Tool Volume Modes Grid Quality WSPR <code>wspr-turbo</code> 10.94B spots WSPR only 4-char Maidenhead RBN <code>rbn-ingest</code> 2.26B spots CW, RTTY DXCC prefix only (24% geocoded via Rosetta Stone) Contest Logs <code>contest-ingest</code> 234M QSOs (491K files) CW/SSB/RTTY/Digi HQ-GRID-LOCATOR (98.5% ARRL) + callsign lookup PSK Reporter <code>pskr-collector</code> ~26M HF spots/day (live since 2026-02-10) FT8/FT4/WSPR/JS8/CW 4-6 char Maidenhead"},{"location":"model/methodology/data_pipeline/#psk-reporter-forward-collection-active","title":"PSK Reporter (Forward Collection \u2014 Active)","text":"<p>Created by Philip Gladstone, N1DQ. MQTT feed provided by Tom Sevart, M0LTE.</p> <ul> <li>No bulk archive exists \u2014 forward-only, collection started 2026-02-09</li> <li>MQTT firehose at <code>mqtt.pskreporter.info:1883</code> (~26M HF spots/day)</li> <li>Best data quality: machine-decoded SNR, 4-6 char grids, multi-mode</li> <li>Collection tool: <code>pskr-collector</code> \u2014 Go MQTT subscriber \u2192 hourly-rotated gzip JSONL \u2192 <code>/mnt/pskr-data</code></li> <li>Running as systemd service since 2026-02-10 (~19 bytes/spot compressed, ~15 GB/year)</li> <li>Observed throughput: ~300 HF spots/sec sustained, all 10 HF bands</li> <li>Mode mix: 88.7% FT8, 9.1% WSPR, 1.5% FT4, 0.5% JS8</li> <li>Grid coverage: 28% receiver grids, 15% sender grids (per-spot)</li> <li>Dual purpose: Training feed for future models + validation feed for live scoring</li> <li>Stage 2 (live): <code>pskr-ingest</code> JSONL \u2192 ClickHouse <code>pskr.bronze</code> (hourly cron, watermark-tracked via <code>pskr.ingest_log</code>)</li> </ul>"},{"location":"model/methodology/data_pipeline/#storage-layout-9975wx","title":"Storage Layout (9975WX)","text":""},{"location":"model/methodology/data_pipeline/#zfs-archive-pool","title":"ZFS Archive Pool","text":"<p>7.12 TB mirrored Samsung 990 Pro on <code>archive-pool</code>:</p> Dataset Mountpoint Compression Purpose <code>archive-pool</code> <code>/mnt/archive-pool</code> \u2014 Pool root (unused) <code>archive-pool/wspr-data</code> <code>/mnt/wspr-data</code> lz4 WSPR raw CSV archives (.csv.gz) <code>archive-pool/contest-logs</code> <code>/mnt/contest-logs</code> zstd-9 CQ + ARRL Cabrillo logs <code>archive-pool/rbn-data</code> <code>/mnt/rbn-data</code> lz4 RBN daily ZIP archives <code>archive-pool/pskr-data</code> <code>/mnt/pskr-data</code> lz4 PSK Reporter MQTT collection (pre-compressed gzip) <p>Compression rationale:</p> <ul> <li><code>zstd-9</code> for text data (Cabrillo logs) \u2014 10-20x compression ratio</li> <li><code>lz4</code> for pre-compressed archives (RBN ZIPs, PSK Reporter gzip JSONL) \u2014 near-zero CPU overhead on incompressible data</li> </ul> <p>Each dataset can be independently snapshotted, replicated (<code>zfs send</code>), and quota'd.</p>"},{"location":"model/methodology/data_pipeline/#nvme-layout","title":"NVMe Layout","text":"Mount Device Purpose <code>/mnt/ai-stack</code> NVMe Source code, working data <code>/var/lib/clickhouse</code> NVMe (separate) ClickHouse storage (3.7T, I/O decoupled)"},{"location":"model/methodology/data_pipeline/#clickhouse-tables","title":"ClickHouse Tables","text":"Table Rows Size Purpose <code>wspr.bronze</code> 10.94B 191 GiB Raw WSPR spots <code>rbn.bronze</code> 2.26B 45.3 GiB Raw RBN CW/RTTY spots <code>contest.bronze</code> 234M 4.1 GiB Parsed contest QSOs (15 contests) <code>wspr.silver</code> 4.4B 41 GiB CUDA float4 embeddings <code>wspr.signatures_v2_terrestrial</code> 93.6M 2.3 GiB Aggregated signatures (training source, balloon-filtered) <code>wspr.callsign_grid</code> 38.6K \u2014 Rosetta Stone: callsign \u2192 grid lookup <code>wspr.gold_continuous</code> 10M 218 MiB IFW-weighted training set <code>wspr.gold_stratified</code> 10M 167 MiB SSN-stratified training set <code>wspr.gold_v6</code> 10M 240 MiB V6 training set (continuous + kp_penalty) <code>pskr.bronze</code> 514M+ \u2014 PSK Reporter reception spots (accumulating since 2026-02-10) <code>solar.bronze</code> 77K 868 KiB SSN, SFI, Kp daily/3-hourly <code>solar.dscovr</code> 15K \u2014 DSCOVR L1 solar wind (Bz, speed, density)"},{"location":"model/methodology/gold_layer/","title":"Gold Layer","text":"<p>Training-ready tables built from bronze + solar data. The gold layer provides balanced, weighted datasets for IONIS model training.</p> <p>Gold tables are derived directly from <code>wspr.bronze</code> + <code>solar.bronze</code> \u2014 they do not depend on the silver layer or CUDA embeddings.</p>"},{"location":"model/methodology/gold_layer/#prerequisites","title":"Prerequisites","text":"<ul> <li><code>wspr.bronze</code> fully populated (~10.8B rows)</li> <li><code>solar.bronze</code> populated (~17.8K rows)</li> <li>Gold DDL applied (DDLs 13-15, see Bronze Stack)</li> </ul>"},{"location":"model/methodology/gold_layer/#step-1-populate-gold_stratified","title":"Step 1: Populate gold_stratified","text":"<p>SSN-stratified training set: 200K rows per (band x SSN quintile) = 10M total. Ensures equal representation across solar cycle conditions.</p> <pre><code>bash /usr/share/ionis-core/scripts/populate_stratified.sh\n# Or with custom host:\n# CH_HOST=10.60.1.1 bash /usr/share/ionis-core/scripts/populate_stratified.sh\n</code></pre> <p>Verification:</p> <pre><code>clickhouse-client --query \"SELECT count() FROM wspr.gold_stratified\"\n# Expected: 10,000,000\n</code></pre>"},{"location":"model/methodology/gold_layer/#step-2-populate-gold_continuous","title":"Step 2: Populate gold_continuous","text":"<p>IFW-weighted training set using Efraimidis-Spirakis weighted reservoir sampling against a 2D (SSN, midpoint_lat) density histogram. Eliminates stair-step artifacts from discrete SSN quintile bins.</p> <pre><code>bash /usr/share/ionis-core/scripts/populate_continuous.sh\n# Or with custom host:\n# CH_HOST=10.60.1.1 bash /usr/share/ionis-core/scripts/populate_continuous.sh\n</code></pre> <p>Verification:</p> <pre><code>clickhouse-client --query \"SELECT count() FROM wspr.gold_continuous\"\n# Expected: 10,000,000\n</code></pre>"},{"location":"model/methodology/gold_layer/#step-3-populate-gold_v6","title":"Step 3: Populate gold_v6","text":"<p>Phase 6 training set: <code>gold_continuous</code> + <code>kp_penalty</code> constraint column. Used for Phase 6+ training (Kp inversion fix).</p> <p>Depends on gold_continuous</p> <p>This step must run after Step 2 \u2014 it reads from <code>wspr.gold_continuous</code>.</p> <pre><code>bash /usr/share/ionis-core/scripts/populate_v6_clean.sh\n# Or with custom host:\n# CH_HOST=10.60.1.1 bash /usr/share/ionis-core/scripts/populate_v6_clean.sh\n</code></pre> <p>Verification:</p> <pre><code>clickhouse-client --query \"SELECT count() FROM wspr.gold_v6\"\n# Expected: 10,000,000\n\nclickhouse-client --query \"SELECT min(kp_penalty), max(kp_penalty) FROM wspr.gold_v6\"\n# Expected: ~0.0 to 1.0\n</code></pre>"},{"location":"model/methodology/gold_layer/#step-4-export-gold_v6csv","title":"Step 4: Export gold_v6.csv","text":"<p>Export the training set as CSV for use on the M3 Ultra (or any training host).</p> <pre><code>mkdir -p $IONIS_WORKSPACE/ionis-training/data\n\nclickhouse-client --query \"SELECT * FROM wspr.gold_v6 FORMAT CSV\" \\\n    &gt; $IONIS_WORKSPACE/ionis-training/data/gold_v6.csv\n</code></pre> <p>Transfer to training host via DAC link:</p> <pre><code>scp $IONIS_WORKSPACE/ionis-training/data/gold_v6.csv &lt;user&gt;@&lt;sage-host&gt;:$IONIS_WORKSPACE/ionis-training/data/\n</code></pre> <p>Verification:</p> <pre><code>wc -l data/gold_v6.csv\n# Expected: 10,000,000\n\nls -lh data/gold_v6.csv\n# Expected: ~838 MB\n</code></pre>"},{"location":"model/methodology/gold_layer/#training-table-lineage","title":"Training Table Lineage","text":"<pre><code>V1  training_set_v1   First attempt from silver. Dropped (no solar backfill).\nV2  (experimental)    Uniform random sampling. Never formalized.\nV3  (experimental)    Distance-weighted sampling. Never formalized.\nV4  gold_stratified   SSN-stratified quintile bins. Retained for ablation studies.\nV5  gold_continuous   IFW-weighted continuous sampling. Production training source.\nV6  gold_v6           V5 + kp_penalty constraint column. Phase 6+ training.\n</code></pre>"},{"location":"model/methodology/gold_layer/#qa-actuals","title":"QA Actuals","text":"<p>Clean-slate rebuild on 9975WX (2026-02-07):</p> <pre><code>Table                Rows        Time    Size\n-------------------  ----------  ------  -------\nwspr.gold_stratified 10,000,000  6m50s   167 MiB\nwspr.gold_continuous 10,000,000  3m36s   218 MiB\nwspr.gold_v6         10,000,000  &lt;30s    240 MiB\ngold_v6.csv          10,000,000  --      838 MB\n</code></pre>"},{"location":"model/methodology/gold_layer/#full-stack-build-order","title":"Full Stack Build Order","text":"<p>For reference, the complete pipeline from clean slate:</p> <pre><code>Phase 1: DDL (see Bronze Stack)\n  Apply all /usr/share/ionis-core/ddl/*.sql in order (01-15)\n\nPhase 2: Bronze Ingest (see Bronze Stack)\n  2a. solar-backfill             solar.bronze          (&lt;1s)\n  2b. wspr-turbo                 wspr.bronze           (~8m)  RUN SOLO\n  2c. rbn-ingest                 rbn.bronze            (~3m30s)\n  2d. contest-ingest -enrich     contest.bronze        (~24m)\n\nPhase 3: Silver Layer (see Silver Layer)\n  3a. bulk-processor (CUDA)      wspr.silver           (~45m)\n  3b. populate_signatures.sh     wspr.signatures_v2_terrestrial  (~3m30s)\n\nPhase 4: Gold Layer (this page)\n  4a. populate_stratified.sh     wspr.gold_stratified  (~7m)\n  4b. populate_continuous.sh     wspr.gold_continuous   (~4m)\n  4c. populate_v6_clean.sh       wspr.gold_v6          (&lt;30s)\n  4d. Export gold_v6.csv         CSV for M3 training\n\nTotal wall time: ~2h on 9975WX\n</code></pre>"},{"location":"model/methodology/silver_layer/","title":"Silver Layer","text":"<p>Derived tables built from the bronze stack. The silver layer transforms raw spots into embeddings and aggregated signatures for downstream analysis and model training.</p>"},{"location":"model/methodology/silver_layer/#prerequisites","title":"Prerequisites","text":"<ul> <li>Bronze stack fully populated (see Bronze Stack)</li> <li><code>solar.bronze</code> populated (required for all JOINs)</li> </ul>"},{"location":"model/methodology/silver_layer/#step-1-generate-cuda-embeddings","title":"Step 1: Generate CUDA Embeddings","text":"<p>The bulk-processor generates float4 embeddings from WSPR spots joined with solar indices, stored in <code>wspr.silver</code>.</p> <pre><code>bulk-processor --host 192.168.1.90\n</code></pre> <p>Requires NVIDIA GPU</p> <p>The bulk-processor requires an NVIDIA GPU with sufficient VRAM. The RTX PRO 6000 (96 GB) processes all 10.8B spots in a single pass.</p> <p>Not in RPM</p> <p><code>bulk-processor</code> is not yet packaged in the <code>ionis-cuda</code> RPM. Build locally: <code>cd ionis-cuda &amp;&amp; mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; make</code></p> <p>Verification:</p> <pre><code>clickhouse-client --query \"SELECT count() FROM wspr.silver\"\n# Expected: ~4,430,000,000\n</code></pre> <p>The <code>v_quality_distribution</code> materialized view auto-populates as rows are inserted into <code>wspr.silver</code>:</p> <pre><code>clickhouse-client --query \"SELECT count() FROM wspr.v_quality_distribution\"\n# Expected: ~6,100,000\n</code></pre>"},{"location":"model/methodology/silver_layer/#step-2-build-aggregated-signatures","title":"Step 2: Build Aggregated Signatures","text":"<p>Signatures compress 10.8B raw spots into ~93M median-bucketed entries \u2014 a 115:1 compression ratio that strips site-level noise and reveals the atmospheric transfer function.</p> <p>See Aggregated Signatures for full methodology and per-band distribution.</p> <pre><code>bash /usr/share/ionis-core/scripts/populate_signatures.sh\n# Or with custom host:\n# CH_HOST=10.60.1.1 bash /usr/share/ionis-core/scripts/populate_signatures.sh\n</code></pre> <p>Verification:</p> <pre><code>clickhouse-client --query \"SELECT count() FROM wspr.signatures_v2_terrestrial\"\n# Expected: ~93,600,000\n</code></pre>"},{"location":"model/methodology/silver_layer/#qa-actuals","title":"QA Actuals","text":"<p>Clean-slate rebuild on 9975WX (2026-02-07):</p> <pre><code>Table                   Rows            Time\n----------------------  --------------  ---------\nwspr.silver             4,430,000,000   ~45 min\nwspr.signatures_v2_terrestrial  93,600,000      3m31s\nv_quality_distribution  ~6,100,000      (auto)\n</code></pre>"},{"location":"model/methodology/silver_layer/#next-steps","title":"Next Steps","text":"<ul> <li>Gold layer: See Gold Layer for training tables and CSV export</li> <li>Training: See Training for model architecture and training methodology</li> </ul>"},{"location":"model/methodology/step_f_signatures/","title":"Aggregated Signatures","text":"<p>Status: COMPLETE (2026-02-05) Executed on: Threadripper 9975WX (64 threads, ClickHouse on dedicated NVMe)</p>"},{"location":"model/methodology/step_f_signatures/#objective","title":"Objective","text":"<p>Transform 10.8B individual WSPR spots into a high-precision signature library by aggregating reports into median-based physical buckets. This strips site-level noise (local QRM, antenna inefficiency, ground fading) and reveals the atmospheric transfer function.</p>"},{"location":"model/methodology/step_f_signatures/#table-wsprsignatures_v1","title":"Table: <code>wspr.signatures_v1</code>","text":""},{"location":"model/methodology/step_f_signatures/#dimensions","title":"Dimensions","text":"Column Type Description <code>tx_grid_4</code> FixedString(4) 4-char TX Maidenhead grid (field level) <code>rx_grid_4</code> FixedString(4) 4-char RX Maidenhead grid (field level) <code>band</code> Int32 ADIF band ID (102-111) <code>hour</code> UInt8 Hour of day UTC (0-23) <code>month</code> UInt8 Month (1-12)"},{"location":"model/methodology/step_f_signatures/#metrics","title":"Metrics","text":"Column Type Description <code>median_snr</code> Float32 quantile(0.5)(snr) \u2014 site entropy filter <code>spot_count</code> UInt32 Number of spots in bucket (minimum 5) <code>snr_std</code> Float32 SNR standard deviation (dB) <code>reliability</code> Float32 Fraction of spots with SNR &gt; -20 dB <code>avg_sfi</code> Float32 Average Solar Flux Index for bucket <code>avg_kp</code> Float32 Average Kp index for bucket <code>avg_distance</code> UInt32 Average great-circle distance (km) <code>avg_azimuth</code> UInt16 Average azimuth (degrees) <p>ORDER BY: <code>(band, hour, tx_grid_4, rx_grid_4)</code> for fast training access.</p>"},{"location":"model/methodology/step_f_signatures/#feature-derivation","title":"Feature Derivation","text":"<p>All 13 IONIS features are derivable from the signature table:</p> Feature Source distance <code>avg_distance</code> freq_log Derived from <code>band</code> \u2192 frequency mapping hour_sin / hour_cos Derived from <code>hour</code> az_sin / az_cos Derived from <code>avg_azimuth</code> lat_diff Computed from grid centroids midpoint_lat Computed from grid centroids season_sin / season_cos Derived from <code>month</code> day_night_est Derived from <code>hour</code> + grid longitude sfi (sidecar) <code>avg_sfi / 300</code> kp_penalty (sidecar) <code>1 - avg_kp / 9</code>"},{"location":"model/methodology/step_f_signatures/#filters-applied","title":"Filters Applied","text":"Filter Value Rationale Band 102-111 HF amateur only Distance &gt;= 500 km Ground-wave contamination rejection Spot count &gt;= 5 Noise floor rejection Median (quantile 0.5) \u2014 Outlier-resistant central tendency"},{"location":"model/methodology/step_f_signatures/#aggregation-method","title":"Aggregation Method","text":"<p>Per-band <code>INSERT INTO ... SELECT</code> from <code>wspr.bronze</code> joined with <code>solar.bronze</code> on date + 3-hour Kp bucket. Processing is sequential by band to stay within memory limits (quantile computation stores all values per group).</p>"},{"location":"model/methodology/step_f_signatures/#results","title":"Results","text":"Metric Value Total signatures 93,785,013 Processing time 3 min 10 sec (10 bands sequential) Compression ratio 115:1 (10.8B \u2192 93.8M) Average bucket size 96 spots Zero SFI buckets 25,433 (0.03%) NaN values 0"},{"location":"model/methodology/step_f_signatures/#per-band-distribution","title":"Per-Band Distribution","text":"Band ID Buckets Total Spots Avg Median SNR Avg Reliability 160m 102 1.69M 116M -18.1 dB 0.477 80m 103 5.85M 532M -17.9 dB 0.495 60m 104 0.91M 81M -17.6 dB 0.499 40m 105 21.67M 2.80B -17.4 dB 0.537 30m 106 15.98M 1.62B -18.1 dB 0.497 20m 107 27.59M 2.74B -17.5 dB 0.533 17m 108 6.35M 373M -18.4 dB 0.477 15m 109 6.26M 360M -18.3 dB 0.480 12m 110 2.12M 104M -18.8 dB 0.453 10m 111 5.37M 267M -17.9 dB 0.505 <p>20m and 40m dominate (as expected \u2014 most active WSPR bands).</p>"},{"location":"model/methodology/step_f_signatures/#sanity-check-fn31-jo21-20m","title":"Sanity Check: FN31 \u2192 JO21 (20m)","text":"<p>The reference path (Connecticut to Belgium, ~5,900 km) shows a smooth, physically consistent diurnal curve:</p> <ul> <li>SNR peaks at 15-18 UTC (late afternoon, path fully sunlit)</li> <li>SNR drops overnight (02-04 UTC)</li> <li>Summer months show extended propagation windows into evening</li> <li>Winter months concentrate propagation into midday hours</li> <li>Reliability tracks SNR \u2014 higher during peak propagation</li> </ul> <p>No stair-step artifacts. The median successfully strips individual spot noise and reveals the atmospheric transfer function.</p>"},{"location":"model/methodology/step_f_signatures/#clickhouse-performance-settings","title":"ClickHouse Performance Settings","text":"<pre><code>SETTINGS\n    max_threads = 64,\n    max_memory_usage = 80000000000,\n    max_bytes_before_external_group_by = 20000000000,\n    join_use_nulls = 0\n</code></pre> <p>Memory Limit</p> <p>A single-pass aggregation of all 10 bands exceeded 74.5 GiB memory due to <code>quantile(0.5)</code> storing all values per group. Per-band processing reduces peak memory to ~8 GiB per band.</p>"},{"location":"model/methodology/step_f_signatures/#signatures-v2-balloon-filtered-2026-02-09","title":"Signatures V2 \u2014 Balloon-Filtered (2026-02-09)","text":"<p>Training from V14 onward uses <code>wspr.signatures_v2_terrestrial</code> (93.3M rows) which excludes balloon and telemetry contamination identified by the V2 detection system.</p> <ul> <li>V1 balloon filter (deprecated): flagged 276M spots (2.56%) \u2014 99.7% false positives</li> <li>V2 balloon filter (current): date-level velocity detection + full Rosetta Stone (3.64M callsigns) \u2014 1,443 entries, 950K spots (0.009%) \u2014 surgical</li> </ul> <p>The V2 filter correctly excludes only confirmed high-altitude balloon transmissions while preserving legitimate ground station data. The difference is quantified in the V14-TP vs V14-TP-v2 A/B comparison (+1.3 pp Pearson improvement from corrected filter).</p> <p>DDL: <code>21-balloon_callsigns_v2.sql</code>, <code>19-signatures_v2_terrestrial.sql</code></p>"},{"location":"model/methodology/step_f_signatures/#ddl-location","title":"DDL Location","text":"<p><code>/usr/share/ionis-core/ddl/12-signatures_v1.sql</code></p>"},{"location":"model/methodology/training/","title":"Training Methodology","text":""},{"location":"model/methodology/training/#training-architecture","title":"Training Architecture","text":"<p>IONIS is trained on aggregated signatures (<code>wspr.signatures_v2_terrestrial</code>) rather than raw spots. This strips site-level noise and reveals the atmospheric transfer function.</p> Setting Raw spots Aggregated signatures Training rows 10M spots 20M signatures Target Individual SNR Median SNR per bucket RMSE 2.48 dB 0.821\u03c3 (V22-gamma) Pearson +0.24 +0.492 (V22-gamma)"},{"location":"model/methodology/training/#differential-learning-rate","title":"Differential Learning Rate","text":"<p>Two-speed optimizer lets the trunk learn slowly while sidecars maintain physics:</p> Component Learning Rate Purpose Trunk + Heads 1e-5 Slow \u2014 learns geography/time Sun Sidecar 1e-3 Fast \u2014 maintains SFI monotonicity Storm Sidecar 1e-3 Fast \u2014 maintains Kp monotonicity"},{"location":"model/methodology/training/#weight-clamping","title":"Weight Clamping","text":"<p>Sidecar weights are clamped to <code>[0.5, 2.0]</code> after each optimizer step:</p> <ul> <li>Lower bound (0.5): Prevents sidecar collapse to zero influence</li> <li>Upper bound (2.0): Prevents sidecar explosion</li> </ul>"},{"location":"model/methodology/training/#gated-architecture","title":"Gated Architecture","text":"<p>The trunk produces three outputs:</p> <ol> <li>base_snr \u2014 geography-driven baseline</li> <li>sun_scaler \u2014 gate \u2208 [0.5, 2.0] modulating SFI effect by path</li> <li>storm_scaler \u2014 gate \u2208 [0.5, 2.0] modulating Kp effect by latitude</li> </ol> <pre><code>output = base_snr + sun_scaler \u00d7 SunSidecar(sfi)\n                  + storm_scaler \u00d7 StormSidecar(kp)\n</code></pre>"},{"location":"model/methodology/training/#the-nuclear-option-starvation-protocol","title":"The Nuclear Option (Starvation Protocol)","text":"<p>The DNN receives zero direct solar/storm features. This forces the model to:</p> <ol> <li>Learn geography, time, and seasonal patterns from the trunk</li> <li>Learn solar physics exclusively through the constrained sidecars</li> <li>Prevent the trunk from learning the survivorship bias shortcut</li> </ol>"},{"location":"model/methodology/training/#training-hardware","title":"Training Hardware","text":"Setting Value Hardware Mac Studio M3 Ultra (96 GB unified) Backend PyTorch MPS Data Path ClickHouse via DAC link (10 Gbps+) at <code>10.60.1.1:9000</code> Workers 0 (MPS memory safety) Epochs 100 Epoch Time ~9s Total Time ~15 min"},{"location":"model/methodology/training/#convergence","title":"Convergence","text":"<p>Physics constraints remain positive throughout training. Aggregated signatures produce stronger physics response than raw spots. V22-gamma production achieves Pearson +0.492 and RMSE 0.821\u03c3 after 100 epochs on MPS.</p>"},{"location":"model/validation/","title":"Validation Reports","text":"<p>Automated test results from IONIS model evaluations.</p>"},{"location":"model/validation/#current-status-ionis-v22-gamma-physicsoverridelayer-phase-40","title":"Current Status: IONIS V22-gamma + PhysicsOverrideLayer (Phase 4.0)","text":"<p>V22-gamma Production \u2014 Best Physics Model</p> <p>V22-gamma extends V20 with solar depression features and a deterministic PhysicsOverrideLayer for high-band night closure.</p> Metric V22-gamma V20 Baseline Pearson +0.492 +0.4879 RMSE 0.821\u03c3 0.862\u03c3 KI7MT operator tests 17/17 16/17 TST-900 band x time 9/11 \u2014 Parameters 205,621 203,573 <p>Checkpoint: <code>ionis_v22_gamma.safetensors</code> (805 KB) PhysicsOverrideLayer: deterministic clamp for freq &gt;= 21 MHz night paths.</p>"},{"location":"model/validation/#mode-aware-validation","title":"Mode-Aware Validation","text":"<p>IONIS predicts signal-to-noise ratio (SNR) \u2014 a physical quantity. The operational question \"Can I work this path right now, on my mode?\" is answered by applying mode-specific thresholds to that prediction:</p> Mode Family Threshold Recall Interpretation WSPR -28 dB ~97% Model sees nearly all beacon paths FT8/FT4 -20 dB 93.29% Digital modes decode deep in the noise CW -10 dB 93.77% Most CW-viable paths detected RTTY -5 dB 99.37% Contest anchoring taught RTTY ceiling SSB +5 dB 98.40% Contest anchoring taught voice ceiling <p>Curriculum learning: WSPR taught the floor (-28 dB), contest logs taught the ceiling (+10 dB). The model now knows the full dynamic range.</p>"},{"location":"model/validation/#voacap-comparison-context","title":"VOACAP Comparison Context","text":"<p>VOACAP (ITS/NTIA) was designed for SSB voice circuits using 1960s-era ionosonde coefficients. It has no concept of digital mode decode thresholds.</p> <ul> <li>SSB is the only direct comparison \u2014 both models target voice-viable paths</li> <li>For digital modes (FT8, FT4, WSPR) and CW/RTTY, IONIS provides predictions where no comparable reference model exists</li> <li>When FT8 operators use VOACAP and find \"closed\" paths that are wide open at -20 dB, that's not a VOACAP failure \u2014 it was never designed for that world</li> </ul>"},{"location":"model/validation/#psk-reporter-acid-test-2026-02-10","title":"PSK Reporter Acid Test (2026-02-10)","text":"<p>84.14% Recall on Independent Data \u2014 Model Generalizes</p> <p>Validated against 100K spots from 16.5M PSK Reporter observations. Real solar conditions (SFI=140, Kp=1.6). Data the model has never seen.</p> Test Recall Notes IONIS vs VOACAP (training domain) 96.38% Contest paths PSK Reporter (independent) 84.14% Acid test <p>By Mode:</p> Mode Recall Spots FT8 83.61% 91,682 WSPR 100% 4,729 FT4 82.30% 2,729 CW 59.33% 804 <p>By Band:</p> Band Recall Notes 15m-10m 94-96% F2 mastery 20m-17m 81-89% Solid 160m-80m 45-69% NVIS gap <p>Key insight: -3 pp drop with real SFI (140 vs 150 default) proves model responds to solar conditions \u2014 physics, not memorization.</p>"},{"location":"model/validation/#ionis-vs-voacap-2026-02-11","title":"IONIS vs VOACAP (2026-02-11)","text":"<p>IONIS 96.38% vs VOACAP 75.82% \u2014 1M Contest QSOs</p> <p>Comparison on 1,000,000 real contest QSO paths. IONIS showed +20.56 percentage point improvement over VOACAP.</p> Model Overall Recall vs VOACAP IONIS 96.38% +20.56 pp VOACAP 75.82% \u2014 <p>See IONIS vs VOACAP for full results by mode, band, and methodology.</p>"},{"location":"model/validation/#prediction-quality-2026-02-09","title":"Prediction Quality (2026-02-09)","text":"<p>IONIS Pearson r=+0.3675 vs VOACAP r=+0.0218</p> <p>100K high-confidence signatures (spot_count &gt; 50), per-band Pearson correlation. IONIS showed higher correlation on 9 of 10 bands. VOACAP anti-correlated on low bands (160/80/60/40/30m).</p> <p>Note: IONIS V20 achieves Pearson +0.4879 \u2014 a substantial improvement from the original +0.3675 measurement.</p> <p>See Prediction Quality for full band-by-band results.</p>"},{"location":"model/validation/#link-budget-battery-2026-02-11","title":"Link Budget Battery (2026-02-11)","text":"<p>24 Profiles Tested \u2014 Full Discrimination Curve Mapped</p> <p>Validated V20 model predictions across 24 station profiles from WSPR baseline (0 dB) to EME (+70.8 dB) against 3 ground truth sources.</p> <p>Discrimination Curve (RBN, 56.7M paths):</p> Profile Advantage Recall Tier wspr +0.0 dB 15.61% baseline qrp_portable +11.0 dB 91.86% GOLDILOCKS home_station +31.0 dB 100.00% saturated contest_cw +53.0 dB 100.00% saturated <p>Key insight: The model predicts ionospheric propagation correctly. Station profiles provide the \"gearbox\" for operational predictions. The ~92% QRP recall confirms the model discriminates between easy and hard paths \u2014 exactly what operators need.</p> <p>See Link Budget Battery for full 24-profile results, per-band analysis, and solar breakdowns.</p>"},{"location":"model/validation/#curriculum-learning","title":"Curriculum Learning","text":"<p>Training success comes from teaching sequence:</p> <ol> <li>WSPR (floor): 10.8B observations at -28 dB \u2014 \"what barely possible looks like\"</li> <li>RBN DXpedition (rare): 91K from 152 DXCC \u2014 \"unusual paths exist\"</li> <li>Contest (ceiling): 6.34M proven QSOs at +10 dB \u2014 \"strong signals exist\"</li> </ol> <p>The model learned the full dynamic range. WSPR alone only taught \"marginal.\"</p>"},{"location":"model/validation/#test-suite","title":"Test Suite","text":"<p>V22-gamma: KI7MT 18/18, TST-900 9/11 (29 tests)</p> <p>The V22-gamma test suite validates operator-grounded physics and band x time discrimination. Replaces the V20 62-test battery with focused physics gates.</p> Group Tests Purpose KI7MT Operator Tests 18 Operator-grounded paths from 49K QSOs + 5.7M contest signatures TST-900 Band x Time 11 Band discrimination across day/night/twilight periods <p>The KI7MT tests include 4 gates: raw model (16/17), PhysicsOverrideLayer (17/17), zero regressions, and acid test verification.</p>"},{"location":"model/validation/#documentation","title":"Documentation","text":"<ul> <li>Link Budget Battery \u2014 24-profile station discrimination test</li> <li>IONIS vs VOACAP \u2014 1M path comparison</li> <li>Prediction Quality \u2014 100K path Pearson correlation comparison</li> <li>Test Specification \u2014 TST-100 through TST-800 test suite</li> </ul>"},{"location":"model/validation/step_i_voacap_comparison/","title":"IONIS vs VOACAP Comparison","text":"<ul> <li>Date: 2026-02-11</li> <li>Dataset: 1,000,000 contest QSO paths (CQ WW, CQ WPX, ARRL DX \u2014 2005-2025)</li> <li>IONIS Version: IONIS (IonisGate)</li> <li>VOACAP Version: voacapl 0.7.5 (NTIA/ITS Method 30)</li> </ul>"},{"location":"model/validation/step_i_voacap_comparison/#summary","title":"Summary","text":"<p>Both models were given 1M real contest QSOs and asked: \"was this band open?\" Every QSO actually happened, so the ground truth is always YES. The question is which model correctly predicts that.</p> <pre><code>+------------+---------+\n| Model      | Recall  |\n+------------+---------+\n| IONIS      | 96.38%  |\n| VOACAP     | 75.82%  |\n+------------+---------+\n  Delta: +20.56 pp vs VOACAP\n</code></pre> <p>IONIS showed a 20.56 percentage point improvement over the reference model on real-world contest QSO recall.</p>"},{"location":"model/validation/step_i_voacap_comparison/#contest-anchoring","title":"Contest Anchoring","text":"<p>The training recipe includes 6.34M contest signatures with anchored SNR values:</p> <ul> <li>SSB QSOs \u2192 +10 dB anchor (proven voice-viable paths)</li> <li>RTTY QSOs \u2192 0 dB anchor (proven digital-viable paths)</li> </ul> <p>This taught the model the \"ceiling\" of propagation \u2014 paths where voice communication actually succeeded. WSPR alone only teaches the \"floor.\"</p>"},{"location":"model/validation/step_i_voacap_comparison/#methodology","title":"Methodology","text":""},{"location":"model/validation/step_i_voacap_comparison/#data-source","title":"Data Source","text":"<p>The 1M paths were exported by <code>validate_v12.py --export</code> from contest QSO records in <code>contest.bronze</code>. Each row represents a confirmed two-way contact between amateur radio stations during a major HF contest. These are not synthetic paths \u2014 every row is a real QSO that actually completed.</p>"},{"location":"model/validation/step_i_voacap_comparison/#ionis-scoring","title":"IONIS Scoring","text":"<p>IONIS predicts SNR for each path. Band is considered \"open\" if:</p> <pre><code>predicted_snr &gt;= mode_threshold\n</code></pre> <p>Mode thresholds: DG/CW = -22.0 dB, RY/PH = -21.0 dB.</p>"},{"location":"model/validation/step_i_voacap_comparison/#voacap-scoring","title":"VOACAP Scoring","text":"<p>Each path is converted to a VOACAP input card and run through <code>voacapl</code> (Method 30, CCIR coefficients). The same mode thresholds are applied to VOACAP's predicted SNR:</p> <pre><code>voacap_snr &gt;= mode_threshold\n</code></pre> <p>VOACAP parameters:</p> <ul> <li>TX Power: 0.01 kW (10W) via ANTENNA card</li> <li>Antenna: const17.voa (17 dBi omnidirectional)</li> <li>Coefficients: CCIR</li> <li>Method: 30 (complete system performance)</li> <li>All 24 hours predicted per circuit; matched to QSO hour</li> </ul>"},{"location":"model/validation/step_i_voacap_comparison/#execution","title":"Execution","text":"<ul> <li>Unique circuits: 965,161 (from 1M rows with dedup ratio 1.04x)</li> <li>Workers: 32 (ProcessPoolExecutor on Threadripper 9975WX)</li> <li>Throughput: ~370 circuits/sec</li> <li>Total time: ~43 minutes</li> <li>Errors: 0</li> </ul> <p>Results stored in <code>validation.step_i_voacap</code> (ClickHouse) for reproducible querying by either the 9975WX or M3 agent.</p>"},{"location":"model/validation/step_i_voacap_comparison/#results-by-mode","title":"Results by Mode","text":"<pre><code>Mode      Total       IONIS TP    IONIS %    VOACAP TP   VOACAP %    IONIS vs VOACAP\n------  ---------  -----------  ---------  -----------  ---------   -------------\nCW        459,200      430,609     93.77%      340,678     74.36%      +19.4 pp\nPH        285,083      280,521     98.40%      215,717     75.83%      +22.6 pp\nRY        233,446      231,982     99.37%      183,392     78.72%      +20.6 pp\nDG         22,269       20,773     93.29%       18,397     82.84%      +10.4 pp\n</code></pre> <p>SSB breakthrough: SSB (PH) recall reached 98.40%. Contest anchoring taught the model what \"voice-viable\" actually looks like.</p> <p>IONIS showed higher recall across all modes. The largest delta was SSB (+22.6 pp), which is notable because SSB voice circuits are VOACAP's primary design target.</p>"},{"location":"model/validation/step_i_voacap_comparison/#results-by-band","title":"Results by Band","text":"<pre><code>Band      Total     IONIS TP    IONIS %    VOACAP TP   VOACAP %    IONIS vs VOACAP\n------  ---------  ----------  ---------  ----------  ---------   -------------\n80m        95,350      93,063     97.60%      71,328     74.98%      +22.6 pp\n40m       205,856     200,281     97.29%     174,004     84.71%      +12.6 pp\n20m       348,712     335,325     96.16%     253,281     86.71%       +9.5 pp\n15m       199,503     186,718     93.59%     143,524     72.09%      +21.5 pp\n10m       150,579     148,473     98.60%      90,831     60.46%      +38.1 pp\n</code></pre>"},{"location":"model/validation/step_i_voacap_comparison/#band-analysis","title":"Band Analysis","text":"<p>10m (98.60%) \u2014 The biggest improvement. VOACAP misses sporadic-E and day-to-day solar variability. Contest anchoring taught IONIS that 10m paths actually work when conditions are right.</p> <p>80m (97.60%) \u2014 NVIS and ground-wave paths that VOACAP's ionospheric model doesn't capture. IONIS learned from real WSPR spots that include short-range contacts.</p> <p>15m (93.59%) \u2014 The contest ceiling taught the model what \"open\" really means on this band.</p> <p>20m (96.16%) \u2014 VOACAP uses monthly median SSN, missing day-to-day variability and sporadic-E openings that account for many contest QSOs on 10m, especially at solar minimum. IONIS captures these from the training data distribution.</p> <p>40m (84.71%) and 20m (86.71%) \u2014 VOACAP's strongest bands. These are the classic F2-layer DX bands where VOACAP's ionospheric model is most accurate. The remaining gap vs IONIS comes from edge cases: grey line enhancement, unusual propagation modes, and paths near the MUF limit.</p>"},{"location":"model/validation/step_i_voacap_comparison/#comparison-query","title":"Comparison Query","text":"<p>Both tables live in ClickHouse and can be queried from either agent:</p> <pre><code>SELECT\n    p.mode,\n    count() AS total,\n    sum(p.band_open) AS ionis_open,\n    sum(v.voacap_band_open) AS voacap_open,\n    round(sum(p.band_open) / count() * 100, 2) AS ionis_pct,\n    round(sum(v.voacap_band_open) / count() * 100, 2) AS voacap_pct\nFROM validation.step_i_paths p\nJOIN validation.step_i_voacap v\n    USING (tx_lat, tx_lon, rx_lat, rx_lon, freq_mhz, year, month, hour_utc)\nGROUP BY p.mode\nORDER BY p.mode\n</code></pre>"},{"location":"model/validation/step_i_voacap_comparison/#infrastructure","title":"Infrastructure","text":"<pre><code>Source table:  validation.step_i_paths   (1,000,000 rows)\nResult table:  validation.step_i_voacap  (1,000,000 rows)\nDDL:           ionis-core/src/16-validation_step_i.sql\nScript:        ionis-training/scripts/voacap_batch_runner.py\nDocs:          ionis-docs/docs/tools/voacapl.md\n</code></pre>"},{"location":"model/validation/step_i_voacap_comparison/#significance","title":"Significance","text":"<p>This is a direct comparison between a 1980s physics-based model (VOACAP) and a 2026 data-driven neural network (IONIS) on the same 1M paths. IONIS's advantage comes from:</p> <ol> <li>Training on real propagation data \u2014 10.8B WSPR spots capture actual    ionospheric behavior including sporadic-E, grey line effects, and    short-range NVIS that physics models miss</li> <li>Continuous solar features \u2014 IONIS uses actual SFI/Kp values rather    than monthly median SSN</li> <li>Learned geography \u2014 the DNN trunk learns path-specific propagation    patterns (e.g., trans-equatorial, polar) from data rather than relying    on simplified ionospheric layer models</li> </ol> <p>VOACAP remains a valuable independent baseline: its 76% recall confirms that the contest QSO dataset is physically reasonable (these paths really were open), and the band-by-band pattern matches expected ionospheric physics.</p>"},{"location":"model/validation/step_i_voacap_comparison/#a-note-on-mode-context","title":"A Note on Mode Context","text":"<p>VOACAP was designed for SSB voice circuits \u2014 its prediction algorithms, noise models, and reliability metrics assume analog telephony. The comparison above uses contest QSOs across all modes (CW, SSB, RTTY, Digital) with uniform thresholds, which is useful for overall benchmarking.</p> <p>However, the most meaningful direct comparison is SSB vs SSB, where VOACAP was specifically designed to perform. For digital modes (FT8, FT4, WSPR) and CW with decode thresholds well below VOACAP's design point, IONIS provides predictions where no comparable reference model exists. See the Validation Overview for the mode-aware recall staircase.</p> <p>V22-gamma Note</p> <p>This is a V20 historical validation report. V22-gamma (Pearson +0.492, RMSE 0.821\u03c3) inherits V20's core physics and improves on it with solar depression features and PhysicsOverrideLayer. The VOACAP comparison methodology and results validated here remain foundational.</p>"},{"location":"model/validation/step_k_quality_test/","title":"Prediction Quality (Pearson Correlation)","text":"<p>Date: 2026-02-09 Status: COMPLETE Result: IONIS showed +0.35 correlation improvement over reference model</p> <p>V20 Production</p> <p>IONIS V20 achieves Pearson +0.4879 \u2014 a substantial improvement from the +0.3675 measured in this initial test.</p>"},{"location":"model/validation/step_k_quality_test/#objective","title":"Objective","text":"<p>The IONIS vs VOACAP comparison proved IONIS correctly identifies if a band is open (Recall). This test proves IONIS tracks the quality of the opening (Correlation).</p> <p>If IONIS has higher Pearson r than VOACAP against ground truth SNR, it doesn't just know the band is open\u2014it knows how strong the signal will be.</p>"},{"location":"model/validation/step_k_quality_test/#methodology","title":"Methodology","text":""},{"location":"model/validation/step_k_quality_test/#test-dataset","title":"Test Dataset","text":"<ul> <li>Source: <code>validation.quality_test_paths</code> \u2014 100K signatures from <code>wspr.signatures_v2_terrestrial</code></li> <li>Stratification: 10K per band (160m through 10m)</li> <li>Quality filter: <code>spot_count &gt; 50</code> (high-confidence ground truth)</li> <li>Ground truth: <code>median_snr</code> from signature bucket</li> </ul>"},{"location":"model/validation/step_k_quality_test/#dual-prediction","title":"Dual Prediction","text":"Model Method IONIS <code>oracle_v13.py</code> inference on M3 Ultra VOACAP Method 30 (SNRxx) via <code>voacapl</code> on 9975WX"},{"location":"model/validation/step_k_quality_test/#metrics","title":"Metrics","text":"<ul> <li>Pearson r: Correlation between predicted SNR and actual <code>median_snr</code></li> <li>RMSE: Root mean squared error (IONIS only; VOACAP has unit incompatibility)</li> </ul>"},{"location":"model/validation/step_k_quality_test/#results","title":"Results","text":""},{"location":"model/validation/step_k_quality_test/#overall-correlation","title":"Overall Correlation","text":"Metric IONIS VOACAP Delta Pearson r +0.3675 +0.0218 +0.3456 RMSE 5.00 dB \u2014 \u2014 Bias -2.00 dB \u2014 \u2014 <p>IONIS Pearson r = +0.3675 vs VOACAP r = +0.0218 (delta: +0.3456).</p>"},{"location":"model/validation/step_k_quality_test/#per-band-breakdown","title":"Per-Band Breakdown","text":"Band N IONIS r VOACAP r Delta 160m 10,000 +0.2948 -0.1950 +0.4898 80m 10,000 +0.2664 -0.2100 +0.4764 60m 10,000 +0.2449 -0.1817 +0.4265 40m 10,000 +0.4214 -0.1717 +0.5932 30m 10,000 +0.2997 -0.0892 +0.3889 20m 10,000 +0.3850 -0.0205 +0.4054 17m 10,000 +0.4993 -0.0258 +0.5251 15m 10,000 +0.4979 +0.0468 +0.4511 12m 10,000 +0.3391 +0.2691 +0.0700 10m 10,000 +0.1244 +0.1826 -0.0583 <p>IONIS showed higher correlation on 9 of 10 bands.</p>"},{"location":"model/validation/step_k_quality_test/#low-band-analysis-160m-40m","title":"Low-Band Analysis (160m-40m)","text":"<p>VOACAP shows negative correlation on low bands\u2014when it predicts stronger signal, actual WSPR SNR is lower.</p> Model Pearson r IONIS +0.3204 VOACAP -0.1963 Delta +0.5167"},{"location":"model/validation/step_k_quality_test/#physics-interpretation","title":"Physics Interpretation","text":""},{"location":"model/validation/step_k_quality_test/#why-voacap-is-anti-correlated-on-low-bands","title":"Why VOACAP is Anti-Correlated on Low Bands","text":"<p>When VOACAP was developed (1960s-70s), the \"noise floor\" was defined by human operators with headphones. A signal at -28 dB SNR wasn't \"weak\"\u2014it was non-existent.</p> <p>VOACAP was calibrated for Information Throughput: when is a signal strong enough for 60 WPM Teletype or clear SSB voice? It effectively ignores the \"Sub-Audit Floor.\"</p> <p>On low bands, VOACAP overcompensates for D-layer absorption. It assumes high absorption = \"dead\" path.</p> <p>The WSPR reality: Paths stay open deep into the noise floor. Digital modes like WSPR and FT8 decode signals that were invisible to 1970s technology.</p>"},{"location":"model/validation/step_k_quality_test/#the-resolution-difference","title":"The Resolution Difference","text":"Model What it models VOACAP The Mirror \u2014 can it reflect a high-power beam? IONIS The Medium \u2014 can any energy get through? <p>IONIS learned the \"Deep-Tissue Physics\" of the ionosphere from 10.8B observations. It knows that absorption is a dimmer switch, not an off switch.</p>"},{"location":"model/validation/step_k_quality_test/#files","title":"Files","text":"File Location Test script <code>ionis-training/scripts/quality_test_ionis.py</code> Test paths <code>validation.quality_test_paths</code> (ClickHouse) VOACAP results <code>validation.quality_test_voacap</code> (ClickHouse) <p>Generated: 2026-02-09 IONIS \u2014 Ionospheric Neural Inference System (V20 Production)</p> <p>V22-gamma Note</p> <p>This is a V20 historical quality test. V22-gamma (Pearson +0.492, RMSE 0.821\u03c3) inherits V20's per-band prediction quality and improves aggregate metrics through solar depression features. The per-band Pearson analysis methodology validated here applies to V22-gamma.</p>"},{"location":"model/validation/test_specification/","title":"IONIS Test Specification","text":"Document Version 3.0 Model Version IonisGate V22-gamma + PhysicsOverrideLayer (Production) Checkpoint <code>ionis_v22_gamma.safetensors</code> Date 2026-02-25 Author IONIS <p>Implementation Status: COMPLETE</p> <p>V22-gamma validation uses operator-grounded tests and band x time discrimination:</p> Group Tests Description KI7MT Operator Tests 18 Operator-grounded paths (17 hard + 1 acid test) TST-900 Band x Time 11 Band discrimination across day/night/twilight Total 29 <p>Run all tests: <code>ionis-validate test</code></p> <p>V22-gamma results: KI7MT 18/18 PASS (with PhysicsOverrideLayer), TST-900 9/11.</p> <p>V20 Legacy Test Specification (TST-100 through TST-800)</p> <p>The 62-test V20 specification (TST-100 through TST-800) below is retained as historical reference. V22-gamma inherits V20's core physics and replaces the test battery with focused operator-grounded validation.</p>"},{"location":"model/validation/test_specification/#overview","title":"Overview","text":"<p>This document specifies the automated test suite for IONIS. Each test has: - ID: Unique identifier (TST-XXX) - Purpose: What physics or behavior is being validated - Method: How the test works - Expected Result: What constitutes PASS/FAIL - Failure Mode: What a failure indicates - Hallucination Trap: Tests designed to catch model overconfidence</p> <p>The test suite runs via modular test scripts in <code>versions/v20/tests/</code>:</p> <pre><code>cd $IONIS_WORKSPACE\n\n# Run complete test suite (62 tests)\n.venv/bin/python ionis-training/versions/v20/tests/run_all.py\n\n# Run individual test groups\n.venv/bin/python ionis-training/versions/v20/tests/test_tst200_physics.py\n.venv/bin/python ionis-training/versions/v20/tests/test_tst100_canonical.py\n# etc.\n</code></pre> <p>Additional validation scripts:</p> <pre><code># Legacy physics verification (standalone)\n.venv/bin/python ionis-training/versions/v20/verify_v20.py\n\n# PSK Reporter live validation\n.venv/bin/python ionis-training/versions/v20/validate_v20_pskr.py\n</code></pre>"},{"location":"model/validation/test_specification/#test-groups","title":"Test Groups","text":""},{"location":"model/validation/test_specification/#core-tests-domain-specific","title":"Core Tests (Domain-Specific)","text":"Group ID Range Purpose Canonical Paths TST-100 Known HF paths with expected behavior Physics Constraints TST-200 Monotonicity and sidecar validation Input Validation TST-300 Boundary checks and invalid input rejection Hallucination Traps TST-400 Inputs outside training domain"},{"location":"model/validation/test_specification/#extended-tests-standard-ml","title":"Extended Tests (Standard ML)","text":"Group ID Range Purpose Model Robustness TST-500 Determinism, stability, numerical safety Adversarial/Security TST-600 Malicious input handling Bias &amp; Fairness TST-700 Systematic prediction biases Regression TST-800 Catch silent degradation <p>Note: Extended tests are standard ML model validation \u2014 they apply to any neural network regardless of domain. Core tests are specific to ionospheric propagation physics.</p>"},{"location":"model/validation/test_specification/#group-1-canonical-paths-tst-100","title":"Group 1: Canonical Paths (TST-100)","text":"<p>These tests verify the model produces reasonable predictions for well-known HF propagation paths. All paths must predict SNR &gt; -2.5\u03c3 (~-17 dB) to be considered OPEN.</p> <p>Default conditions unless noted: SFI 150, Kp 2, June.</p>"},{"location":"model/validation/test_specification/#category-a-north-america-to-europe","title":"Category A: North America to Europe","text":"ID Path Band Hour UTC Purpose TST-101 W3 \u2192 G 20m 14 Classic transatlantic day path TST-102 W3 \u2192 G 20m 04 Grey line / night propagation TST-103 G \u2192 W6 20m 18 Europe to US West Coast TST-104 W3 \u2192 G 40m 22 Transatlantic on 40m (evening) TST-105 VE3 \u2192 DL 20m 14 Canada to Germany"},{"location":"model/validation/test_specification/#category-b-trans-pacific","title":"Category B: Trans-Pacific","text":"ID Path Band Hour UTC Purpose TST-110 W6 \u2192 JA 20m 16 US West Coast to Japan TST-111 JA \u2192 W3 20m 23 Japan to US East Coast (long path timing) TST-112 KH6 \u2192 JA 20m 06 Hawaii to Japan TST-113 VK \u2192 W6 20m 05 Australia to US West Coast"},{"location":"model/validation/test_specification/#category-c-europe-to-asia","title":"Category C: Europe to Asia","text":"ID Path Band Hour UTC Purpose TST-120 G \u2192 JA 20m 08 Europe to Japan TST-121 DL \u2192 VU 20m 12 Germany to India TST-122 JA \u2192 OH 20m 10 Japan to Finland (near-polar)"},{"location":"model/validation/test_specification/#category-d-africa-paths","title":"Category D: Africa Paths","text":"ID Path Band Hour UTC Purpose TST-130 ZS \u2192 G 20m 14 South Africa to Europe TST-131 ZS \u2192 W3 20m 16 South Africa to US East Coast TST-132 5H \u2192 DL 20m 14 Tanzania to Germany"},{"location":"model/validation/test_specification/#category-e-south-america-paths","title":"Category E: South America Paths","text":"ID Path Band Hour UTC Purpose TST-140 PY \u2192 W3 20m 18 Brazil to US East Coast TST-141 LU \u2192 G 20m 16 Argentina to Europe TST-142 PY \u2192 VU 20m 14 Brazil to India (equatorial long-haul)"},{"location":"model/validation/test_specification/#category-f-oceania-paths","title":"Category F: Oceania Paths","text":"ID Path Band Hour UTC Purpose TST-150 VK \u2192 G 20m 08 Australia to Europe TST-151 ZL \u2192 JA 20m 04 New Zealand to Japan TST-152 VK \u2192 ZS 20m 10 Australia to South Africa"},{"location":"model/validation/test_specification/#category-g-regional-nvis","title":"Category G: Regional / NVIS","text":"ID Path Band Hour UTC Purpose TST-160 G \u2192 DL 20m 12 Intra-Europe short path TST-161 JA \u2192 HL 20m 06 Intra-Asia (Japan to Korea) TST-162 Central US 80m 02 NVIS ~280 km (SFI 100, threshold -2.0\u03c3)"},{"location":"model/validation/test_specification/#category-h-band-specific-physics-paired-tests","title":"Category H: Band-Specific Physics (Paired Tests)","text":"ID Path Band Conditions Purpose TST-170 OX \u2192 OH 20m Kp 2 Polar path quiet baseline TST-171 OX \u2192 OH 20m Kp 8 Polar storm degradation (&gt; 1\u03c3 vs TST-170) TST-172 W3 \u2192 G 10m SFI 80 10m low SFI baseline TST-173 W3 \u2192 G 10m SFI 200 10m SFI improvement (&gt; 0.3\u03c3 vs TST-172) TST-174 W3 \u2192 G 40m 02 UTC 40m night path TST-175 VE3 \u2192 W3 160m 04 UTC 160m regional night (SFI 100)"},{"location":"model/validation/test_specification/#location-database","title":"Location Database","text":"Key Location Lat Lon W3 Maryland 39.14\u00b0N 77.01\u00b0W W6 Los Angeles 34.05\u00b0N 118.24\u00b0W VE3 Toronto 43.65\u00b0N 79.38\u00b0W KH6 Hawaii 21.31\u00b0N 157.86\u00b0W G London 51.50\u00b0N 0.12\u00b0W DL Berlin 52.52\u00b0N 13.40\u00b0E OH Helsinki 60.17\u00b0N 24.94\u00b0E JA Tokyo 35.68\u00b0N 139.69\u00b0E HL Seoul 37.57\u00b0N 126.98\u00b0E VU Bangalore 12.97\u00b0N 77.59\u00b0E VK Sydney 33.87\u00b0S 151.21\u00b0E ZL Wellington 41.29\u00b0S 174.78\u00b0E ZS Cape Town 33.93\u00b0S 18.42\u00b0E 5H Tanzania 6.17\u00b0S 35.74\u00b0E PY Sao Paulo 23.55\u00b0S 46.63\u00b0W LU Buenos Aires 34.60\u00b0S 58.38\u00b0W OX Greenland 64.18\u00b0N 51.72\u00b0W"},{"location":"model/validation/test_specification/#group-2-physics-constraints-tst-200","title":"Group 2: Physics Constraints (TST-200)","text":"<p>These tests verify the model's learned physics matches ionospheric reality.</p>"},{"location":"model/validation/test_specification/#physics-scoring-system","title":"Physics Scoring System","text":"<p>Each physics test is graded on a 0-100 scale based on how well the model matches expected ionospheric behavior.</p> Grade Score Meaning A 90-100 Excellent \u2014 matches real-world physics closely B 75-89 Good \u2014 correct direction, reasonable magnitude C 60-74 Acceptable \u2014 correct direction, weak magnitude D 40-59 Poor \u2014 barely correct or flat response F 0-39 Fail \u2014 wrong direction or no response"},{"location":"model/validation/test_specification/#scoring-criteria-by-test-type","title":"Scoring Criteria by Test Type","text":"<p>SFI Monotonicity (TST-201, TST-205) Expected: +1 to +4 dB improvement for SFI 70\u2192200</p> Delta (dB) Score Grade \u2265 +3.0 100 A +2.0 to +2.9 85 B +1.0 to +1.9 70 C +0.1 to +0.9 50 D \u2264 0 0 F <p>Kp Storm Cost (TST-202, TST-204) Expected: +2 to +6 dB degradation for Kp 0\u21929</p> Cost (dB) Score Grade \u2265 +4.0 100 A +3.0 to +3.9 90 A +2.0 to +2.9 75 B +1.0 to +1.9 60 C +0.1 to +0.9 40 D \u2264 0 0 F <p>D-Layer Absorption (TST-203) Expected: 20m better than 80m at noon by +1 to +5 dB</p> Delta (dB) Score Grade \u2265 +3.0 100 A +1.0 to +2.9 80 B 0 to +0.9 60 C -1.0 to -0.1 40 D &lt; -1.0 0 F <p>Polar Storm Sensitivity (TST-204) Expected: High-latitude paths more affected by Kp than mid-latitude</p> Polar vs Mid-lat ratio Score Grade \u2265 1.2x 100 A 1.1x to 1.19x 80 B 1.0x to 1.09x 60 C 0.9x to 0.99x 40 D &lt; 0.9x 0 F"},{"location":"model/validation/test_specification/#overall-physics-score","title":"Overall Physics Score","text":"<p>The model receives an aggregate physics score:</p> <pre><code>Physics Score = (TST-201 + TST-202 + TST-203 + TST-204 + TST-205 + TST-206) / 6\n</code></pre> Overall Score Rating 90-100 Production Ready 75-89 Research Quality 60-74 Needs Improvement &lt; 60 Not Recommended"},{"location":"model/validation/test_specification/#tst-201-sfi-monotonicity-70-vs-200","title":"TST-201: SFI Monotonicity (70 vs 200)","text":"Field Value Purpose Verify higher solar flux improves signal strength Method Compare SNR at SFI 70 vs SFI 200, all else equal Path W3 \u2192 G, 20m, Kp 2, 14:00 UTC Expected Result SNR(SFI 200) &gt; SNR(SFI 70) by at least +1 dB Pass Criteria Delta is positive Failure Mode If negative or zero: Sun sidecar physics inverted or dead Actual +0.535\u03c3 (+3.6 dB) improvement \u2014 Grade A Notes This is fundamental ionospheric physics \u2014 higher SFI = higher MUF = better HF"},{"location":"model/validation/test_specification/#tst-202-kp-monotonicity-0-vs-9","title":"TST-202: Kp Monotonicity (0 vs 9)","text":"Field Value Purpose Verify geomagnetic storms degrade signal strength Method Compare SNR at Kp 0 vs Kp 9, all else equal Path W3 \u2192 G, 20m, SFI 150, 14:00 UTC Expected Result SNR(Kp 9) &lt; SNR(Kp 0) by at least -2 dB Pass Criteria Delta is negative (storm cost positive) Failure Mode If positive: Storm sidecar physics inverted (CRITICAL BUG) Actual +1.743\u03c3 (+11.7 dB) storm cost \u2014 Grade A Notes This was the \"Kp inversion problem\" that plagued V1-V9"},{"location":"model/validation/test_specification/#tst-203-d-layer-absorption-80m-vs-20m-at-noon","title":"TST-203: D-Layer Absorption (80m vs 20m at Noon)","text":"Field Value Purpose Verify daytime D-layer absorption affects lower frequencies Method Compare 3.5 MHz vs 14.0 MHz at solar noon Path W3 \u2192 G, SFI 150, Kp 2, 12:00 UTC Expected Result SNR(20m) &gt;= SNR(80m) at noon Pass Criteria Delta &gt;= 0 dB Failure Mode If 80m better at noon: Model missing D-layer physics Actual +0.063\u03c3 (+0.4 dB) \u2014 20m slightly better \u2014 Grade C Notes Correct direction but weak magnitude; real physics expects stronger D-layer effect"},{"location":"model/validation/test_specification/#tst-204-polar-storm-degradation-kp-2-vs-8","title":"TST-204: Polar Storm Degradation (Kp 2 vs 8)","text":"Field Value Purpose Verify storms hit high-latitude paths harder Method Compare Kp 2 vs Kp 8 on polar path Path OX \u2192 OH, 20m, SFI 150, 12:00 UTC Expected Result Storm cost &gt; 2 dB Pass Criteria Significant degradation observed Failure Mode If &lt; 1 dB: Storm gate not modulating by latitude Actual +1.149\u03c3 (+7.7 dB) polar degradation; polar/mid-lat ratio 1.00x \u2014 Grade C Notes Significant storm degradation confirmed; gate not yet differentiating by latitude"},{"location":"model/validation/test_specification/#tst-205-10m-sfi-sensitivity","title":"TST-205: 10m SFI Sensitivity","text":"Field Value Purpose Verify higher bands more sensitive to SFI Method Compare SFI 80 vs 200 on 10m path Path W3 \u2192 G, 28 MHz, Kp 2, 14:00 UTC Expected Result Delta &gt; +1.5 dB Pass Criteria 10m shows strong SFI dependence Failure Mode If &lt; 1 dB: Sun sidecar not frequency-aware Actual +0.498\u03c3 (+3.3 dB) improvement; 10m/20m ratio 1.00x \u2014 Grade A Notes 10m needs high SFI; model shows strong SFI sensitivity"},{"location":"model/validation/test_specification/#tst-206-grey-line-twilight-enhancement","title":"TST-206: Grey Line / Twilight Enhancement","text":"Field Value Purpose Verify model captures grey line propagation enhancement Method Compare SNR at 14:00 UTC vs 18:00 UTC on E-W path Path W3 \u2192 G, 20m, SFI 150, Kp 2 Expected Result SNR(18 UTC) &gt;= SNR(14 UTC) Pass Criteria Twilight hour shows equal or better propagation Failure Mode If negative: Model missing grey line physics Actual +0.074\u03c3 (+0.5 dB) enhancement \u2014 Grade C Notes Grey line (twilight) often enhances E-W paths due to lower D-layer absorption <p>Grey Line Scoring Criteria</p> Delta (dB) Score Grade \u2265 +1.0 100 A +0.5 to +0.9 85 B 0 to +0.4 70 C -0.5 to -0.1 50 D &lt; -0.5 0 F"},{"location":"model/validation/test_specification/#group-3-input-validation-tst-300","title":"Group 3: Input Validation (TST-300)","text":"<p>These tests verify the oracle rejects invalid inputs gracefully.</p>"},{"location":"model/validation/test_specification/#tst-301-vhf-frequency-rejection-eme-trap","title":"TST-301: VHF Frequency Rejection (EME Trap)","text":"Field Value Purpose Reject frequencies outside HF training domain Input freq_mhz = 144.0 (2m band) Expected Result ValueError raised Pass Criteria Oracle refuses to predict Failure Mode If prediction made: Model will hallucinate nonsense Notes EME at 144 MHz is lunar reflection, not ionospheric \u2014 completely different physics"},{"location":"model/validation/test_specification/#tst-302-uhf-frequency-rejection","title":"TST-302: UHF Frequency Rejection","text":"Field Value Purpose Reject UHF frequencies Input freq_mhz = 432.0 (70cm band) Expected Result ValueError raised Pass Criteria Oracle refuses to predict Failure Mode Model has no training data for UHF Notes UHF propagation is tropospheric scatter or satellite, not ionospheric"},{"location":"model/validation/test_specification/#tst-303-invalid-latitude-rejection","title":"TST-303: Invalid Latitude Rejection","text":"Field Value Purpose Reject impossible coordinates Input lat_tx = 95.0 (impossible) Expected Result ValueError raised Pass Criteria Oracle validates coordinate bounds Failure Mode Garbage coordinates produce garbage predictions Notes Latitude must be [-90, 90]"},{"location":"model/validation/test_specification/#tst-304-invalid-kp-rejection","title":"TST-304: Invalid Kp Rejection","text":"Field Value Purpose Reject out-of-range geomagnetic index Input kp = 15 (impossible, max is 9) Expected Result ValueError raised Pass Criteria Oracle validates Kp bounds Failure Mode Extrapolation beyond training domain Notes Kp index is defined as 0-9"},{"location":"model/validation/test_specification/#tst-305-valid-long-distance-path","title":"TST-305: Valid Long Distance Path","text":"Field Value Purpose Accept valid long-distance path Input ~12,000 km path (W3 \u2192 Asia) Expected Result Prediction returned (no error) Pass Criteria Oracle accepts valid input Failure Mode False rejection of valid path Notes Ensures validation isn't overly aggressive"},{"location":"model/validation/test_specification/#group-4-hallucination-traps-tst-400","title":"Group 4: Hallucination Traps (TST-400)","text":"<p>These tests catch cases where the model might produce confident but wrong answers.</p>"},{"location":"model/validation/test_specification/#tst-401-eme-path-detection","title":"TST-401: EME Path Detection","text":"Field Value Purpose Catch EME-like inputs that look ionospheric Scenario 2m, 500 km, -28 dB expected (classic EME signature) Expected Result Rejected as VHF Pass Criteria Oracle recognizes this isn't ionospheric Failure Mode Model predicts confidently for physics it never learned Notes 1500W, 500km, -28 dB on 2m = Moon bounce, not skip"},{"location":"model/validation/test_specification/#tst-402-sporadic-e-trap-future","title":"TST-402: Sporadic E Trap (Future)","text":"Field Value Purpose Identify E-skip conditions model wasn't trained on Scenario 6m, 1500 km, summer afternoon Expected Result Warning about sporadic E uncertainty Pass Criteria Oracle flags low confidence Status IMPLEMENTED \u2014 rejects 50.3 MHz with \"Sporadic E\" warning Notes 6m not in training data; oracle correctly flags as out-of-domain"},{"location":"model/validation/test_specification/#tst-403-ground-wave-confusion","title":"TST-403: Ground Wave Confusion","text":"Field Value Purpose Flag very short paths that may be ground wave Scenario 80m, 50 km path Expected Result Warning issued (likely ground wave) Pass Criteria Oracle warns about ground wave possibility Failure Mode Model predicts ionospheric SNR for ground wave path Notes WSPR &lt; 100 km is often ground wave, not skywave"},{"location":"model/validation/test_specification/#tst-404-extreme-solar-event","title":"TST-404: Extreme Solar Event","text":"Field Value Purpose Flag predictions during X-class flare conditions Scenario SFI 400+, Kp 9 Expected Result Warning about extreme conditions Pass Criteria Oracle flags low confidence Status IMPLEMENTED \u2014 SFI 400 + Kp 9 triggers \"extreme solar event\" warning with low confidence Notes Extreme space weather is outside training distribution"},{"location":"model/validation/test_specification/#test-execution","title":"Test Execution","text":""},{"location":"model/validation/test_specification/#running-the-complete-test-suite","title":"Running the Complete Test Suite","text":"<pre><code>cd $IONIS_WORKSPACE\n\n# Complete test suite (62 tests, ~2 min)\n.venv/bin/python ionis-training/versions/v20/tests/run_all.py\n</code></pre>"},{"location":"model/validation/test_specification/#expected-output-run_allpy","title":"Expected Output: run_all.py","text":"<pre><code>======================================================================\n  IONIS V20 \u2014 Complete Test Suite\n======================================================================\n\n  Date: 2026-02-16 10:47:23\n  Model: IONIS V20\n  Checkpoint: versions/v20/ionis_v20.pth\n\n  Running 8 test groups (62 total tests)...\n\n  [TST-200] Physics Constraints (6 tests)... PASS\n  [TST-300] Input Validation (5 tests)... PASS\n  [TST-500] Model Robustness (7 tests)... PASS\n  [TST-800] Regression Tests (3 tests)... PASS\n  [TST-100] Canonical Paths (30 tests)... PASS\n  [TST-400] Hallucination Traps (4 tests)... PASS\n  [TST-600] Adversarial &amp; Security (4 tests)... PASS\n  [TST-700] Bias &amp; Fairness (3 tests)... PASS\n\n======================================================================\n  TEST SUITE SUMMARY\n======================================================================\n\n  Group       Description                 Tests    Status\n  -------------------------------------------------------\n  TST-200     Physics Constraints             6      PASS\n  TST-300     Input Validation                5      PASS\n  TST-500     Model Robustness                7      PASS\n  TST-800     Regression Tests                3      PASS\n  TST-100     Canonical Paths                30      PASS\n  TST-400     Hallucination Traps             4      PASS\n  TST-600     Adversarial &amp; Security          4      PASS\n  TST-700     Bias &amp; Fairness                 3      PASS\n  -------------------------------------------------------\n  TOTAL                                      62  62/62\n\n  ==================================================\n  ALL TEST GROUPS PASSED\n  ==================================================\n\n  IONIS V20 validation complete.\n  Model is ready for production deployment.\n</code></pre>"},{"location":"model/validation/test_specification/#interpreting-failures","title":"Interpreting Failures","text":"Failure Pattern Likely Cause SFI monotonicity fails Sun sidecar broken or inverted Kp monotonicity fails Storm sidecar broken or inverted (CRITICAL) All paths show same SNR Trunk collapsed to constant VHF not rejected Input validation bypassed Polar = Equatorial storm cost Gates not differentiating"},{"location":"model/validation/test_specification/#group-5-model-robustness-tst-500","title":"Group 5: Model Robustness (TST-500)","text":"<p>Standard ML model tests \u2014 not physics-specific, applies to any neural network.</p>"},{"location":"model/validation/test_specification/#tst-501-reproducibility","title":"TST-501: Reproducibility","text":"Field Value Purpose Same input produces same output Method Run identical prediction 100 times Expected Result All outputs identical (deterministic inference) Pass Criteria Zero variance in predictions Failure Mode Non-deterministic behavior indicates dropout left on or random state leak Category Determinism"},{"location":"model/validation/test_specification/#tst-502-input-perturbation-stability","title":"TST-502: Input Perturbation Stability","text":"Field Value Purpose Small input changes produce small output changes Method Perturb inputs by \u00b10.1%, measure output variance Expected Result Output changes &lt; 0.5 dB for tiny input changes Pass Criteria No catastrophic sensitivity Failure Mode Exploding gradients, unstable regions in input space Category Stability"},{"location":"model/validation/test_specification/#tst-503-boundary-value-testing","title":"TST-503: Boundary Value Testing","text":"Field Value Purpose Model handles edge cases gracefully Method Test at domain boundaries (SFI=50, SFI=300, Kp=0, Kp=9, etc.) Expected Result Reasonable predictions, no NaN/Inf Pass Criteria All outputs finite and within plausible range Failure Mode NaN, Inf, or predictions outside [-50, +30] dB Category Boundary"},{"location":"model/validation/test_specification/#tst-504-null-input-handling","title":"TST-504: Null Input Handling","text":"Field Value Purpose Model rejects or handles missing/null values Method Pass NaN, None, or empty values Expected Result ValueError raised or graceful default Pass Criteria No silent corruption Failure Mode NaN propagates through model silently Category Input Sanitization"},{"location":"model/validation/test_specification/#tst-505-numerical-overflow","title":"TST-505: Numerical Overflow","text":"Field Value Purpose Model handles extreme (but valid) inputs Method Test with SFI=300, Kp=9, distance=19999 km simultaneously Expected Result Finite output, no overflow Pass Criteria Output in valid range Failure Mode Inf, -Inf, or NaN in computation Category Numerical Stability"},{"location":"model/validation/test_specification/#tst-506-checkpoint-integrity","title":"TST-506: Checkpoint Integrity","text":"Field Value Purpose Saved model loads correctly and matches training Method Load checkpoint, verify architecture, run reference prediction Expected Result Matches documented RMSE/Pearson within tolerance Pass Criteria Reference prediction within 0.01 dB of expected Failure Mode Corrupted checkpoint, architecture mismatch Category Serialization"},{"location":"model/validation/test_specification/#tst-507-device-portability","title":"TST-507: Device Portability","text":"Field Value Purpose Model runs on CPU, MPS, and CUDA Method Load and run on each available device Expected Result Identical predictions across devices Pass Criteria Cross-device variance &lt; 0.001 dB Failure Mode Device-specific numerical differences Category Portability"},{"location":"model/validation/test_specification/#group-6-adversarial-security-tst-600","title":"Group 6: Adversarial &amp; Security (TST-600)","text":"<p>Tests for robustness against malicious or malformed inputs.</p>"},{"location":"model/validation/test_specification/#tst-601-injection-via-string-coordinates","title":"TST-601: Injection via String Coordinates","text":"Field Value Purpose Reject non-numeric coordinate inputs Method Pass \"51.5; DROP TABLE\" as latitude Expected Result TypeError or ValueError Pass Criteria No code execution, clean rejection Failure Mode Injection vulnerability (unlikely in numeric model but test anyway) Category Input Injection"},{"location":"model/validation/test_specification/#tst-602-extremely-large-values","title":"TST-602: Extremely Large Values","text":"Field Value Purpose Reject absurdly large inputs Method Pass SFI=1e30, distance=1e20 Expected Result ValueError (out of bounds) Pass Criteria Rejected before reaching model Failure Mode Float overflow in computation Category Bounds Checking"},{"location":"model/validation/test_specification/#tst-603-negative-physical-values","title":"TST-603: Negative Physical Values","text":"Field Value Purpose Reject physically impossible negative values Method Pass SFI=-100, Kp=-5, freq=-14.0 Expected Result ValueError Pass Criteria All rejected Failure Mode Negative values accepted, nonsense predictions Category Physical Validity"},{"location":"model/validation/test_specification/#tst-604-type-coercion-attack","title":"TST-604: Type Coercion Attack","text":"Field Value Purpose Handle unexpected types gracefully Method Pass list, dict, or object instead of float Expected Result TypeError Pass Criteria Clean error message Failure Mode Silent type coercion producing wrong results Category Type Safety"},{"location":"model/validation/test_specification/#group-7-bias-fairness-tst-700","title":"Group 7: Bias &amp; Fairness (TST-700)","text":"<p>Tests for systematic biases in model predictions.</p>"},{"location":"model/validation/test_specification/#tst-701-geographic-coverage-bias","title":"TST-701: Geographic Coverage Bias","text":"Field Value Purpose Verify model doesn't favor training-dense regions Method Compare similar-distance paths in data-rich (EU) vs data-sparse (Africa) regions EU Path G \u2192 DL (London to Berlin), ~900 km Africa Path 5H \u2192 9J (Tanzania to Zambia), ~1,200 km Conditions 14 MHz, SFI 150, Kp 2, 14:00 UTC Expected Result Bias &lt; 5 dB between regions Pass Criteria Similar predictions for similar physics Failure Mode &gt;5 dB difference suggests model memorized dense regions Actual EU: -15.2 dB, Africa: -15.2 dB, Bias: 0.0 dB Category Geographic Bias Status AUTOMATED"},{"location":"model/validation/test_specification/#tst-702-temporal-bias","title":"TST-702: Temporal Bias","text":"Field Value Purpose Verify model doesn't favor specific times Method Sweep all 24 hours, verify no anomalous spikes Expected Result Smooth diurnal variation Pass Criteria No discontinuities at hour boundaries Failure Mode Training data imbalance causing time-of-day artifacts Category Temporal Bias"},{"location":"model/validation/test_specification/#tst-703-band-coverage-bias","title":"TST-703: Band Coverage Bias","text":"Field Value Purpose Verify all bands receive reasonable predictions Method Run same path on all bands 160m-10m Expected Result All predictions in valid range, physics-consistent Pass Criteria No band returns NaN or wildly different behavior Failure Mode Underrepresented bands produce poor predictions Category Feature Bias"},{"location":"model/validation/test_specification/#group-8-regression-tests-tst-800","title":"Group 8: Regression Tests (TST-800)","text":"<p>Baseline tests to catch future regressions.</p>"},{"location":"model/validation/test_specification/#tst-801-reference-prediction","title":"TST-801: Reference Prediction","text":"Field Value Purpose Catch silent model changes Method Fixed input, compare to documented output Reference Input W3\u2192G, 20m, SFI 150, Kp 2, 12:00 UTC, June Reference Output -0.328\u03c3 (\u00b10.05\u03c3 tolerance) Pass Criteria Within tolerance of documented value Failure Mode Model weights changed, retraining without version bump Category Regression"},{"location":"model/validation/test_specification/#tst-802-rmse-regression","title":"TST-802: RMSE Regression","text":"Field Value Purpose Ensure model accuracy hasn't degraded Method Check checkpoint metadata Reference Value RMSE = 0.8617\u03c3 (checkpoint <code>val_rmse</code>, \u00b10.01\u03c3 tolerance) Pass Criteria Loaded RMSE matches checkpoint value Failure Mode Wrong checkpoint loaded Category Regression"},{"location":"model/validation/test_specification/#tst-803-pearson-regression","title":"TST-803: Pearson Regression","text":"Field Value Purpose Ensure correlation hasn't degraded Method Check checkpoint metadata Reference Value Pearson = +0.4879 (checkpoint <code>val_pearson</code>, \u00b10.005 tolerance) Pass Criteria Loaded Pearson matches checkpoint value Failure Mode Wrong checkpoint loaded Category Regression"},{"location":"model/validation/test_specification/#standard-ml-test-categories-reference","title":"Standard ML Test Categories Reference","text":"Category Purpose Examples Determinism Same input \u2192 same output TST-501 Stability Small input changes \u2192 small output changes TST-502 Boundary Edge cases handled TST-503 Input Sanitization Invalid inputs rejected TST-504, TST-601-604 Numerical Stability No overflow/underflow TST-505 Serialization Save/load integrity TST-506 Portability Cross-device consistency TST-507 Bias/Fairness No systematic favoritism TST-701-703 Regression Catch silent degradation TST-801-803 Adversarial Malicious input handling TST-601-604"},{"location":"model/validation/test_specification/#version-history","title":"Version History","text":"Version Date Changes 1.0 2026-02-05 Initial specification 1.1 2026-02-05 Added TST-500 (Robustness), TST-600 (Security), TST-700 (Bias), TST-800 (Regression) 1.2 2026-02-05 Added TST-206 (Grey line twilight), automated TST-701 (Geographic bias) per Einstein review 2.0 2026-02-16 Updated for IONIS V20; fixed script paths to <code>versions/v20/</code>; documented implementation status; renamed from <code>v12_test_specification.md</code> 2.1 2026-02-16 COMPLETE IMPLEMENTATION: All 62 tests automated in modular test suite; TST-100 expanded to 30 global paths; TST-200 implemented with 6 physics tests; added <code>run_all.py</code> orchestrator 2.2 2026-02-16 SPEC RECONCILIATION: TST-100 rewritten to match 30-test implementation (8 geographic categories); TST-200 actuals updated from 9975WX CPU test run; TST-400 status flags corrected (TST-402, TST-404 now IMPLEMENTED); TST-800 baselines corrected to match checkpoint values (RMSE 0.8617\u03c3, Pearson +0.4879); verified 62/62 PASS on 9975WX"},{"location":"model/validation/test_specification/#references","title":"References","text":"<p>Test Suite (62 tests):</p> <ul> <li>Orchestrator: <code>ionis-training/versions/v20/tests/run_all.py</code></li> <li>TST-100 Canonical Paths: <code>ionis-training/versions/v20/tests/test_tst100_canonical.py</code></li> <li>TST-200 Physics Constraints: <code>ionis-training/versions/v20/tests/test_tst200_physics.py</code></li> <li>TST-300 Input Validation: <code>ionis-training/versions/v20/tests/test_tst300_input_validation.py</code></li> <li>TST-400 Hallucination Traps: <code>ionis-training/versions/v20/tests/test_tst400_hallucination.py</code></li> <li>TST-500 Model Robustness: <code>ionis-training/versions/v20/tests/test_tst500_robustness.py</code></li> <li>TST-600 Adversarial/Security: <code>ionis-training/versions/v20/tests/test_tst600_adversarial.py</code></li> <li>TST-700 Bias &amp; Fairness: <code>ionis-training/versions/v20/tests/test_tst700_bias.py</code></li> <li>TST-800 Regression: <code>ionis-training/versions/v20/tests/test_tst800_regression.py</code></li> </ul> <p>Model &amp; Training:</p> <ul> <li>Training: <code>ionis-training/versions/v20/train_v20.py</code></li> <li>Legacy Physics Verification: <code>ionis-training/versions/v20/verify_v20.py</code></li> <li>Sensitivity Analysis: <code>ionis-training/versions/v20/test_v20.py</code></li> <li>PSKR Live Validation: <code>ionis-training/versions/v20/validate_v20_pskr.py</code></li> <li>Model Checkpoint: <code>ionis-training/versions/v20/ionis_v20.pth</code></li> <li>Config: <code>ionis-training/versions/v20/config_v20.json</code></li> </ul>"},{"location":"model/validation/v20_link_budget_battery/","title":"IONIS-V20-LB-01: Link Budget Profile Battery","text":"<ul> <li>Timestamp: 2026-02-11 18:45 UTC</li> <li>Model Checkpoint: <code>versions/v20/ionis_v20.pth</code></li> <li>Test Objective: Validate mode viability prediction across 23 station profiles covering the full range of HF operations, from milliwatt QRP to contest super stations.</li> </ul>"},{"location":"model/validation/v20_link_budget_battery/#1-methodology","title":"1. Methodology","text":"<ul> <li>Data Sources: RBN (56.7M CW/RTTY/PSK31 paths), PSKR (91K FT8/CW spots), Contest (1M SSB/CW/RTTY QSOs)</li> <li>Profiles: 24 station profiles, advantage range +0.0 to +70.8 dB</li> <li>Metric Focus: Mode recall (binary hit/miss) across full link budget range</li> <li>Link Budget Formula:   <pre><code>adjusted_snr = predicted_snr + 10*log10(P/0.2W) + G_tx + G_rx\n</code></pre></li> </ul>"},{"location":"model/validation/v20_link_budget_battery/#profile-range","title":"Profile Range","text":"Category Profiles Advantage Range Baseline wspr, wspr_dipole, voacap_default 0 - 27 dB QRP/Portable qrp_milliwatt through pota_activator 4 - 22 dB Home home_vertical, home_station, home_beam 27 - 37 dB Amplified home_amp_dipole through big_gun 38 - 59 dB Contest contest_lp through contest_super 43 - 67 dB DXpedition dxpedition_lite through dxpedition_mega 27 - 53 dB Special maritime_mobile, extreme_hf 25 - 71 dB"},{"location":"model/validation/v20_link_budget_battery/#2-physical-verification-ionis-integrity-check","title":"2. Physical Verification (IONIS Integrity Check)","text":"Check Result Notes Waterfall Consistency PASS SSB viable =&gt; RTTY viable =&gt; CW viable =&gt; FT8 viable Monotonic Advantage PASS Higher advantage =&gt; equal or higher recall Discrimination Zone PASS Model shows &lt; 100% recall for low-advantage profiles SFI Monotonicity PASS +0.482\u03c3 benefit (SFI 70\u2192200) Kp Monotonicity PASS +3.487\u03c3 storm cost (Kp 0\u21929)"},{"location":"model/validation/v20_link_budget_battery/#3-quantitative-results","title":"3. Quantitative Results","text":""},{"location":"model/validation/v20_link_budget_battery/#31-master-battery-table","title":"3.1 Master Battery Table","text":"Profile Advantage RBN Recall PSKR Recall Contest Recall Tier wspr +0.0 dB 15.61% 97.44% 20.85% baseline qrp_portable +11.0 dB 91.86% \u2014 \u2014 GOLDILOCKS home_station +31.0 dB 100.00% 100.00% \u2014 saturated contest_cw +53.0 dB \u2014 \u2014 100.00% saturated <p>Partial Battery</p> <p>Initial results from 7 profile\u00d7source combinations (114M paths). Full 24\u00d73 battery pending.</p>"},{"location":"model/validation/v20_link_budget_battery/#32-discrimination-curve-rbn","title":"3.2 Discrimination Curve (RBN)","text":"Profile Advantage Recall Interpretation wspr +0.0 dB 15.61% Model baseline qrp_portable +11.0 dB 91.86% Goldilocks zone home_station +31.0 dB 100.00% Saturation <p>The discrimination zone spans +0 to +31 dB. Above +31 dB, all viable paths are predicted correctly.</p>"},{"location":"model/validation/v20_link_budget_battery/#33-per-band-detail-rbn-qrp-portable","title":"3.3 Per-Band Detail (RBN, QRP Portable)","text":"Band 160m 80m 40m 20m 15m 10m Recall 92.96% 92.29% 92.91% 90.57% 89.64% 96.38% Paths 2.73M 6.46M 14.3M 16.5M 7.63M 3.55M <p>Observation: High bands (10m-12m) easier when open. Mid-bands (15m-20m) most challenging.</p>"},{"location":"model/validation/v20_link_budget_battery/#34-solar-condition-breakdown","title":"3.4 Solar Condition Breakdown","text":"<p>From test_v20.py physics sensitivity analysis:</p> SFI Kp=0 Kp=2 Kp=4 Kp=6 Kp=8 80 -0.16\u03c3 -0.58\u03c3 -0.98\u03c3 -1.36\u03c3 -1.73\u03c3 120 -0.00\u03c3 -0.42\u03c3 -0.82\u03c3 -1.21\u03c3 -1.57\u03c3 150 +0.12\u03c3 -0.30\u03c3 -0.70\u03c3 -1.08\u03c3 -1.45\u03c3 200 +0.33\u03c3 -0.09\u03c3 -0.49\u03c3 -0.87\u03c3 -1.24\u03c3 250 +0.55\u03c3 +0.13\u03c3 -0.27\u03c3 -0.66\u03c3 -1.02\u03c3 <p>Units: sigma (Z-normalized). Multiply by 6.7 for approximate dB.</p>"},{"location":"model/validation/v20_link_budget_battery/#4-visual-evidence","title":"4. Visual Evidence","text":""},{"location":"model/validation/v20_link_budget_battery/#discrimination-curve","title":"Discrimination Curve","text":"<pre><code>Recall\n  100% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u25cf\n   90% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cf\n   50%\n   20% \u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n   16% \u25cf\n    0%\n       \u2514\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u25ba\n         0  10  20  30  40  50  60  70 dB\n                   Advantage\n</code></pre>"},{"location":"model/validation/v20_link_budget_battery/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   IONIS V20  \u2502 --&gt; \u2502 Link Budget  \u2502 --&gt; \u2502  Threshold   \u2502\n\u2502 (ionosphere) \u2502     \u2502  (station)   \u2502     \u2502   (mode)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     Frozen              Thin layer          Mode decode\n   Physics only         Arithmetic          viability\n</code></pre>"},{"location":"model/validation/v20_link_budget_battery/#5-analysis-conclusion","title":"5. Analysis &amp; Conclusion","text":"<p>The V20 link budget battery validates three key claims:</p> <ol> <li> <p>The model predicts ionospheric propagation correctly. Without any station advantage (wspr profile), it identifies 15-20% of paths as viable \u2014 matching the fraction of extreme low-SNR paths that would work for 200 mW WSPR.</p> </li> <li> <p>Station profiles provide a gearbox for operational predictions. Adding +11 dB (QRP portable) jumps recall to 92%. Adding +31 dB (home station) reaches 100%. This matches amateur experience: marginal paths need power.</p> </li> <li> <p>The ~92% QRP recall is \"Goldilocks\". Per Einstein's architectural review: \"The model is correctly identifying the 'grey line' where power actually matters. Do not tune the profiles further; you have found the 'truth.'\"</p> </li> </ol>"},{"location":"model/validation/v20_link_budget_battery/#key-metrics-summary","title":"Key Metrics Summary","text":"Metric Target V20 Result Status Pearson &gt;= +0.48 +0.4879 PASS Kp storm cost &gt;= +3.0\u03c3 +3.487\u03c3 PASS SFI benefit &gt;= +0.4\u03c3 +0.482\u03c3 PASS Recall (vs VOACAP) &gt; 86.89% 95.91% PASS Discrimination present yes 15%\u219292%\u2192100% PASS"},{"location":"model/validation/v20_link_budget_battery/#band-level-physics","title":"Band-Level Physics","text":"<p>The per-band breakdown at QRP portable (+11 dB) reveals expected physics:</p> <ul> <li>Low bands (160m-80m): 92-93% \u2014 F-layer absorption limits even good conditions</li> <li>Mid bands (40m-20m): 90-93% \u2014 most variable, condition-dependent</li> <li>High bands (10m-12m): 94-96% \u2014 when open, robustly open</li> </ul> <p>This ordering matches real-world experience and validates the model's physics encoding.</p>"},{"location":"model/validation/v20_link_budget_battery/#future-work","title":"Future Work","text":"<p>The full 24-profile \u00d7 3-source battery (72 runs, ~13-16 hours) will provide:</p> <ul> <li>Complete discrimination curve with 23 data points per source</li> <li>Statistical confidence on saturation thresholds</li> <li>Per-band heatmaps for all profile combinations</li> <li>Solar condition \u00d7 profile interaction matrix</li> </ul> <p>Test ID: IONIS-V20-LB-01 Author: IONIS Team Status: PASS \u2014 Initial validation complete, full battery pending</p> <p>V22-gamma Note</p> <p>This is a V20 historical validation report. V22-gamma inherits V20's core IonisGate physics and adds solar depression features + PhysicsOverrideLayer for high-band night closure. The link budget physics validated here remains foundational to V22-gamma production.</p>"},{"location":"testing/","title":"Testing","text":"<p>The IONIS validation suite lets you verify the V22-gamma model against your own operating experience. Install the package, run the tests, predict your paths, and tell us what the model gets wrong.</p> <p>This is end-user model testing \u2014 you do not need ClickHouse, training scripts, or any understanding of the IONIS pipeline. Everything runs locally with the shipped checkpoint.</p>"},{"location":"testing/#what-you-can-do","title":"What You Can Do","text":"Command Purpose <code>ionis-validate test</code> Run the full 29-test automated battery <code>ionis-validate predict</code> Predict a single HF path from your grid <code>ionis-validate custom</code> Batch-test your own paths from a JSON file <code>ionis-validate report</code> Generate a structured report for GitHub Issues <code>ionis-validate info</code> Show model version, system info, and diagnostics <code>ionis-validate ui</code> Launch browser-based validation dashboard"},{"location":"testing/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+</li> <li>~1 GB disk (PyTorch + model checkpoint)</li> <li>No GPU required (CPU inference)</li> <li>No database, no special hardware</li> <li>Works on Windows, macOS, and Linux</li> </ul>"},{"location":"testing/#quick-start","title":"Quick Start","text":"<pre><code>pip install ionis-validate\n</code></pre> <pre><code>ionis-validate info\nionis-validate test\n</code></pre> <p>See Getting Started for platform-specific setup instructions.</p>"},{"location":"testing/#documentation","title":"Documentation","text":"<ul> <li>Getting Started \u2014 Installation and first run</li> <li>Beta Test Plan \u2014 Step-by-step testing checklist (start here after install)</li> <li>Test Suite \u2014 What the 29 tests cover and how to read results</li> <li>Single Path Prediction \u2014 Predict any HF path from the command line</li> <li>Custom Path Tests \u2014 Define your own test paths in JSON</li> <li>Reporting Issues \u2014 How to file feedback and what to include</li> </ul>"},{"location":"testing/beta-test-plan/","title":"V22-gamma Beta Test Plan","text":"<p>This page walks you through every test we need you to run. Follow the tests in order. Each test tells you exactly what to enter, what to expect, and what to record.</p> <p>You can use either the command line (CLI) or the browser UI. Both produce identical results \u2014 pick whichever you prefer.</p> <p>Before you start</p> <p>Complete the Getting Started installation first. Run <code>ionis-validate --version</code> and confirm you see <code>4.0.0</code> or later.</p>"},{"location":"testing/beta-test-plan/#test-1-verify-installation","title":"Test-1: Verify Installation","text":"<p>Objective: Confirm the model loads and reports correct metadata.</p> CLIBrowser UI <pre><code>ionis-validate info\n</code></pre> <pre><code>ionis-validate ui\n</code></pre> <p>Click the Info tab.</p> <p>Expected results:</p> Field Expected Value Version V22-gamma + PhysicsOverrideLayer Architecture IonisGate Parameters 205,621 Device cpu, cuda, or mps <p>Record: Your device type (cpu, cuda, or mps).</p> <p>Stop condition</p> <p>If any value is missing or wrong, do not continue. Skip to Test-8 and report the problem.</p>"},{"location":"testing/beta-test-plan/#test-2-automated-test-suite","title":"Test-2: Automated Test Suite","text":"<p>Objective: Run all 29 operator-grounded and band x time tests.</p> CLIBrowser UI <pre><code>ionis-validate test\n</code></pre> <p>Click the Report tab. Leave \"Include test suite results\" on. Click Generate Report. The test results appear in the report body.</p> <p>Expected result: KI7MT 18/18 PASS, TST-900 9/11 (TST-903/904 are known).</p> <p>Record: KI7MT pass count and TST-900 score.</p> <p>Stop condition</p> <p>If any test fails, do not continue. Skip to Test-8 and report the failure. Failed automated tests on your system are high-priority findings.</p>"},{"location":"testing/beta-test-plan/#test-3-reference-path-good-conditions","title":"Test-3: Reference Path \u2014 Good Conditions","text":"<p>Objective: Predict a well-known 20m transatlantic path under quiet solar conditions. This gives us a baseline to compare across all testers.</p> CLI (Windows)CLI (macOS / Linux)Browser UI <pre><code>ionis-validate predict --tx-grid FN31 --rx-grid IO91 --band 20m --sfi 150 --kp 2 --hour 14 --month 6 --day-of-year 172\n</code></pre> <pre><code>ionis-validate predict \\\n    --tx-grid FN31 --rx-grid IO91 \\\n    --band 20m --sfi 150 --kp 2 \\\n    --hour 14 --month 6 --day-of-year 172\n</code></pre> <p>Predict tab. Enter these values:</p> Field Value TX Grid <code>FN31</code> RX Grid <code>IO91</code> Band 20m SFI 150 Kp 2 Hour UTC 14 Month 6 Day of Year 172 <p>Click Predict.</p> <p>Expected results:</p> <ul> <li>Predicted dB: -18.9 dB (exactly, on all platforms)</li> <li>WSPR: OPEN</li> <li>FT8: OPEN</li> <li>CW: closed (below the -15 dB threshold)</li> <li>SSB: closed</li> </ul> <p>Record: The exact predicted dB value and all five mode verdicts.</p>"},{"location":"testing/beta-test-plan/#test-4-reference-path-marginal-conditions","title":"Test-4: Reference Path \u2014 Marginal Conditions","text":"<p>Objective: Predict a difficult 15m path with moderate solar flux. This tests whether the model correctly identifies marginal openings.</p> CLI (Windows)CLI (macOS / Linux)Browser UI <pre><code>ionis-validate predict --tx-grid DN46 --rx-grid PM95 --band 15m --sfi 120 --kp 2 --hour 6 --month 12 --day-of-year 350\n</code></pre> <pre><code>ionis-validate predict \\\n    --tx-grid DN46 --rx-grid PM95 \\\n    --band 15m --sfi 120 --kp 2 \\\n    --hour 6 --month 12 --day-of-year 350\n</code></pre> <p>Predict tab. Click Clear first, then enter:</p> Field Value TX Grid <code>DN46</code> RX Grid <code>PM95</code> Band 15m SFI 120 Kp 2 Hour UTC 6 Month 12 Day of Year 350 <p>Click Predict.</p> <p>Expected results:</p> <ul> <li>Predicted dB: -17.1 dB (exactly, on all platforms)</li> <li>WSPR: OPEN</li> <li>FT8: OPEN</li> <li>CW: closed</li> <li>SSB: closed</li> </ul> <p>Record: The exact predicted dB value and all five mode verdicts.</p>"},{"location":"testing/beta-test-plan/#test-5-reference-path-geomagnetic-storm","title":"Test-5: Reference Path \u2014 Geomagnetic Storm","text":"<p>Objective: Repeat the Test-3 path but under severe storm conditions (Kp 7). The model should predict significantly worse propagation.</p> CLI (Windows)CLI (macOS / Linux)Browser UI <pre><code>ionis-validate predict --tx-grid FN31 --rx-grid IO91 --band 20m --sfi 150 --kp 7 --hour 14 --month 6 --day-of-year 172\n</code></pre> <pre><code>ionis-validate predict \\\n    --tx-grid FN31 --rx-grid IO91 \\\n    --band 20m --sfi 150 --kp 7 \\\n    --hour 14 --month 6 --day-of-year 172\n</code></pre> <p>Predict tab. Click Clear first, then enter:</p> Field Value TX Grid <code>FN31</code> RX Grid <code>IO91</code> Band 20m SFI 150 Kp 7 Hour UTC 14 Month 6 Day of Year 172 <p>Click Predict.</p> <p>Expected results:</p> <ul> <li>Predicted dB: -24.1 dB (exactly, on all platforms)</li> <li>This is 5.2 dB worse than the Kp 2 result in Test-3 \u2014 the storm   sidecar is applying a real penalty</li> <li>FT8 is now closed (below -21 dB threshold) \u2014 the storm killed the opening</li> <li>If your value does not match, that is a finding worth reporting</li> </ul> <p>Record: The exact predicted dB value. Confirm it is worse than Test-3.</p>"},{"location":"testing/beta-test-plan/#test-6-your-own-path-known-good","title":"Test-6: Your Own Path \u2014 Known Good","text":"<p>Objective: Predict a path you work regularly. You are the ground truth.</p> <p>Think of an HF path you know well \u2014 one you work often enough to know when it opens and closes. Enter your own grid, their grid, the band you use, and the time and month when you typically make the contact.</p> CLIBrowser UI <pre><code>ionis-validate predict --tx-grid YOURGRID --rx-grid THEIRGRID --band 20m --sfi 150 --kp 2 --hour 14 --month 6 --day-of-year 172\n</code></pre> <p>Replace <code>YOURGRID</code>, <code>THEIRGRID</code>, band, hour, and month with your real values.</p> <p>Predict tab. Click Clear first, then enter your own values. Click Predict.</p> <p>Record:</p> <ul> <li>The grids, band, hour, and month you used</li> <li>The predicted dB value and mode verdicts</li> <li>Whether the model agrees with your experience</li> <li>If it disagrees, note the details \u2014 this is exactly what we need</li> </ul>"},{"location":"testing/beta-test-plan/#test-7-your-own-path-known-bad","title":"Test-7: Your Own Path \u2014 Known Bad","text":"<p>Objective: Predict a path you know does NOT work. Confirming negatives is as valuable as confirming positives.</p> <p>Think of a path you have tried and failed \u2014 for example, 10m to Australia from your grid at midnight, or 160m to Japan. Enter it with realistic conditions.</p> CLIBrowser UI <p>Same command as Test-6 but with a path you know is dead.</p> <p>Predict tab. Click Clear first, then enter a path you know does not open. Click Predict.</p> <p>Expected result: The model should predict your mode as closed.</p> <p>Record:</p> <ul> <li>The grids, band, hour, and month you used</li> <li>Whether the model correctly predicted it as closed</li> <li>If the model says OPEN for a dead path, that is a finding</li> </ul>"},{"location":"testing/beta-test-plan/#test-8-submit-your-results","title":"Test-8: Submit Your Results","text":"<p>Objective: Generate a report and submit it so we can review your findings.</p> CLI (Windows)CLI (macOS / Linux)Browser UI <pre><code>ionis-validate report\n</code></pre> <p>Copy the output from the terminal.</p> <pre><code># macOS \u2014 copies to clipboard\nionis-validate report | pbcopy\n\n# Linux \u2014 copies to clipboard\nionis-validate report | xclip -selection clipboard\n</code></pre> <p>Click the Report tab. Click Generate Report. Click Copy to Clipboard.</p> <p>Where to submit:</p> <p>Open a new issue here and paste your report:</p> <p>https://github.com/IONIS-AI/ionis-validate/issues/new/choose</p> <p>Include in your issue:</p> <ol> <li>The generated report (paste from clipboard)</li> <li>Your Test-3, Test-4, Test-5 dB values (reference predictions)</li> <li>Your Test-6 and Test-7 results (did the model agree with your    experience?)</li> <li>Anything that surprised you \u2014 good or bad</li> </ol>"},{"location":"testing/beta-test-plan/#quick-reference-card","title":"Quick Reference Card","text":"Test What Key Input Pass Criteria Test-1 Verify install <code>ionis-validate info</code> V22-gamma, 205,621 params Test-2 Automated suite <code>ionis-validate test</code> KI7MT 18/18, TST-900 9/11 Test-3 Good path FN31 &gt; IO91, 20m, Kp 2 -18.9 dB, FT8 OPEN Test-4 Marginal path DN46 &gt; PM95, 15m, SFI 120 -17.1 dB, FT8 OPEN Test-5 Storm path FN31 &gt; IO91, 20m, Kp 7 -24.1 dB (5.2 dB worse) Test-6 Your good path Your grids, your band Matches your experience Test-7 Your bad path A path you know is dead Predicts closed Test-8 Submit results <code>ionis-validate report</code> GitHub Issue filed"},{"location":"testing/custom-paths/","title":"Custom Path Tests","text":"<p>Define your own test paths in a JSON file and batch-validate them against the V22-gamma model. This is the best way to check whether IONIS matches your on-air experience.</p>"},{"location":"testing/custom-paths/#usage","title":"Usage","text":"<pre><code>ionis-validate custom my_paths.json\n</code></pre>"},{"location":"testing/custom-paths/#json-format","title":"JSON Format","text":"<pre><code>{\n  \"description\": \"My 20m paths from KI7MT\",\n  \"conditions\": {\n    \"sfi\": 140,\n    \"kp\": 1.5\n  },\n  \"paths\": [\n    {\n      \"tx_grid\": \"DN26\",\n      \"rx_grid\": \"IO91\",\n      \"band\": \"20m\",\n      \"hour\": 14,\n      \"month\": 6,\n      \"label\": \"KI7MT to G\"\n    },\n    {\n      \"tx_grid\": \"DN26\",\n      \"rx_grid\": \"PM95\",\n      \"band\": \"20m\",\n      \"hour\": 6,\n      \"month\": 12,\n      \"expect_open\": true,\n      \"mode\": \"CW\",\n      \"label\": \"KI7MT to JA \u2014 CW should decode\"\n    },\n    {\n      \"tx_grid\": \"DN26\",\n      \"rx_grid\": \"GG66\",\n      \"band\": \"15m\",\n      \"hour\": 16,\n      \"month\": 3,\n      \"sfi\": 200,\n      \"label\": \"KI7MT to VK (high SFI override)\"\n    }\n  ]\n}\n</code></pre>"},{"location":"testing/custom-paths/#fields","title":"Fields","text":"<p>Top-level <code>conditions</code> (optional) \u2014 default solar conditions applied to all paths unless overridden per-path:</p> Field Default Description <code>sfi</code> 150 Solar Flux Index <code>kp</code> 2.0 Kp geomagnetic index <p>Per-path fields:</p> Field Required Description <code>tx_grid</code> Yes Transmitter 4-char Maidenhead grid <code>rx_grid</code> Yes Receiver 4-char Maidenhead grid <code>band</code> Yes Band label (20m, 15m, etc.) <code>hour</code> Yes UTC hour (0-23) <code>month</code> Yes Month (1-12) <code>label</code> No Human-readable path description (not shown in table) <code>sfi</code> No Per-path SFI override <code>kp</code> No Per-path Kp override <code>expect_open</code> No Boolean \u2014 assert the path should be open (true) or closed (false) <code>mode</code> No Mode to test against: WSPR, FT8, CW, RTTY, or SSB (default: WSPR)"},{"location":"testing/custom-paths/#expectations-and-mode-testing","title":"Expectations and Mode Testing","text":"<p>Add <code>\"expect_open\": true</code> or <code>\"expect_open\": false</code> to assert model behavior. The optional <code>\"mode\"</code> field controls which decode threshold is used for the PASS/FAIL verdict:</p> <pre><code>{\n  \"tx_grid\": \"DN26\",\n  \"rx_grid\": \"IO91\",\n  \"band\": \"20m\",\n  \"hour\": 14,\n  \"month\": 6,\n  \"expect_open\": true,\n  \"mode\": \"CW\"\n}\n</code></pre> <p>This path passes if the predicted dB is at or above the CW threshold (-15 dB). Without a <code>\"mode\"</code> field, expectations test against the WSPR threshold (-28 dB).</p> Mode Threshold Meaning WSPR -28 dB Beacon decode floor FT8 -21 dB Digital decode limit CW -15 dB Readable by experienced operator RTTY -5 dB Machine-copy reliable SSB +3 dB Voice-quality communication <p>If the model disagrees with your expectation, the test reports FAIL and exits with a non-zero return code. This is the feedback mechanism \u2014 paths where the model and your experience diverge are exactly what we need to know about.</p>"},{"location":"testing/custom-paths/#example-output","title":"Example Output","text":"<pre><code>======================================================================\n  IONIS V22-gamma \u2014 Custom Path Tests\n======================================================================\n\n  Stress test \u2014 20 paths across good, marginal, bad, and storm conditions\n  Device: cuda\n\n      #  Path           Band      dB       km  SFI   Kp  Hour  Mon  WSPR   FT8    CW   SSB  Result\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n      1  DN26 &gt; IO91    20m    -18.8    7,432  160    1    14    6  OPEN  OPEN    --    --    PASS\n      2  FN31 &gt; JO31    20m     -1.7    5,912  140    2    18    3  OPEN  OPEN  OPEN    --    PASS\n      3  PM95 &gt; QF56    40m     -5.0    7,773  120    1    10   10  OPEN  OPEN  OPEN    --    PASS\n      4  DN26 &gt; IO91    10m    -22.5    7,432   70    2    14    6  OPEN    --    --    --    FAIL\n      5  DN26 &gt; IO91    20m    -29.0    7,432  160    9    14    6    --    --    --    --    PASS\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n  Expectations: 4/5 passed (mode: WSPR)\n  1 path(s) did not match expected open/closed state\n</code></pre> <p>Reading the table:</p> <ul> <li>Path: TX and RX grids</li> <li>dB: Predicted SNR in decibels \u2014 the primary output</li> <li>SFI, Kp, Hour, Mon: The resolved conditions for each path (per-path override or default)</li> <li>WSPR, FT8, CW, SSB: Inline mode verdicts \u2014 <code>OPEN</code> if the predicted dB meets that mode's decode threshold, <code>--</code> if not</li> <li>Result: <code>PASS</code>/<code>FAIL</code> for paths with expectations, <code>OPEN</code>/<code>closed</code> for paths without</li> </ul>"},{"location":"testing/custom-paths/#tips-for-writing-good-tests","title":"Tips for Writing Good Tests","text":"<ol> <li> <p>Test paths you actually work. The value is in comparing model predictions    to your real experience \u2014 not hypothetical paths.</p> </li> <li> <p>Vary conditions. Test the same path at different hours, months, and SFI    values. If 20m to Europe opens at 14 UTC for you, does the model agree?</p> </li> <li> <p>Include known failures. If you know 160m from your grid to VK never    works, add it with <code>\"expect_open\": false</code>. Confirming negatives is as    valuable as confirming positives.</p> </li> <li> <p>Use the <code>mode</code> field for SSB/CW tests. If you work SSB to Europe and    the model says the path is open for WSPR but not SSB, set    <code>\"mode\": \"SSB\", \"expect_open\": true</code> to flag the disagreement.</p> </li> <li> <p>Use real solar conditions. Check current SFI at    NOAA SWPC and test with today's actual value    instead of the default 150.</p> </li> <li> <p>Share your results. Custom path test files that expose model weaknesses    are the most valuable feedback you can provide. See    Reporting Issues.</p> </li> </ol>"},{"location":"testing/getting-started/","title":"Getting Started","text":""},{"location":"testing/getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+</li> <li>No GPU, no database, no special hardware</li> </ul> <p>Check your Python version</p> <p>Open a terminal (or Command Prompt on Windows) and run:</p> <pre><code>python --version\n</code></pre> <p>If you see <code>Python 3.10</code> or higher, you're good. If you don't have Python installed, download it from python.org.</p>"},{"location":"testing/getting-started/#install","title":"Install","text":"<p>Use a virtual environment</p> <p>We strongly recommend installing into a virtual environment, not your system Python. This keeps your system clean and makes cleanup easy \u2014 when you are done testing, just delete the folder.</p>"},{"location":"testing/getting-started/#step-1-create-a-virtual-environment","title":"Step 1 \u2014 Create a virtual environment","text":"WindowsmacOSLinux <p>Open Command Prompt or PowerShell:</p> <pre><code>python -m venv .venv\n.venv\\Scripts\\activate\n</code></pre> <p>Open Terminal:</p> <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\n</code></pre> <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\n</code></pre> <p>You should see <code>(.venv)</code> at the start of your prompt. This means the virtual environment is active and all installs will go into the <code>.venv</code> folder instead of your system Python.</p> <p>Using uv instead</p> <p>If you have uv installed, you can use it for faster setup:</p> <pre><code>uv venv .venv\nsource .venv/bin/activate      # macOS / Linux\n.venv\\Scripts\\activate         # Windows\n</code></pre>"},{"location":"testing/getting-started/#step-2-install-ionis-validate","title":"Step 2 \u2014 Install ionis-validate","text":"<pre><code>pip install ionis-validate\n</code></pre> <p>This installs:</p> <ul> <li><code>ionis-validate</code> \u2014 the CLI tool</li> <li>The V22-gamma model checkpoint and config (safetensors, ~50 MB)</li> <li>PyTorch, NumPy, and safetensors (pulled automatically, ~800 MB)</li> </ul>"},{"location":"testing/getting-started/#verify-installation","title":"Verify Installation","text":"<pre><code>ionis-validate info\n</code></pre> <p>Expected output includes model version (V22-gamma), parameter count (205,621), PhysicsOverrideLayer status, and your system's PyTorch device (CPU, CUDA, or MPS).</p>"},{"location":"testing/getting-started/#first-run","title":"First Run","text":"<p>Run the full test suite:</p> <pre><code>ionis-validate test\n</code></pre> <p>This executes 29 tests across 2 groups:</p> Group Tests What It Checks KI7MT Operator Tests 18 Operator-grounded paths from 49K QSOs + 5.7M contest signatures TST-900 Band x Time 11 Band discrimination across day/night/twilight periods <p>Expected: KI7MT 18/18 PASS, TST-900 9/11 (TST-903 and TST-904 are known). If any KI7MT test fails, see Reporting Issues.</p>"},{"location":"testing/getting-started/#try-a-prediction","title":"Try a Prediction","text":"<p>Predict a 20m path from your grid:</p> WindowsmacOS / Linux <pre><code>ionis-validate predict --tx-grid FN20 --rx-grid IO91 --band 20m --sfi 150 --kp 2 --hour 14 --month 6 --day-of-year 172\n</code></pre> <pre><code>ionis-validate predict \\\n    --tx-grid FN20 --rx-grid IO91 \\\n    --band 20m --sfi 150 --kp 2 \\\n    --hour 14 --month 6 --day-of-year 172\n</code></pre> <p>The output shows predicted SNR (in sigma and dB) and per-mode verdicts: WSPR, FT8, CW, RTTY, and SSB \u2014 open or closed.</p>"},{"location":"testing/getting-started/#browser-ui","title":"Browser UI","text":"<p>The optional browser UI wraps every command in a point-and-click dashboard. Install the UI extras and launch:</p> <pre><code>pip install \"ionis-validate[ui]\"\nionis-validate ui\n</code></pre> <p>This opens a browser tab at <code>http://localhost:8765</code> with tabs for Predict, Custom, Report, and Info.</p>"},{"location":"testing/getting-started/#cleanup","title":"Cleanup","text":"<p>When you are done testing, deactivate the virtual environment and delete the folder. Nothing else to uninstall.</p> WindowsmacOS / Linux <pre><code>deactivate\nrmdir /s /q .venv\n</code></pre> <pre><code>deactivate\nrm -rf .venv\n</code></pre>"},{"location":"testing/getting-started/#whats-next","title":"What's Next","text":"<ul> <li>Test Suite \u2014 understand what each test group validates</li> <li>Single Path Prediction \u2014 full CLI reference</li> <li>Custom Path Tests \u2014 batch-test your own paths</li> </ul>"},{"location":"testing/predict/","title":"Single Path Prediction","text":"<p>Predict the signal-to-noise ratio for any HF path from the command line.</p>"},{"location":"testing/predict/#usage","title":"Usage","text":"<pre><code>ionis-validate predict \\\n    --tx-grid &lt;grid&gt; --rx-grid &lt;grid&gt; \\\n    --band &lt;band&gt; \\\n    --sfi &lt;value&gt; --kp &lt;value&gt; \\\n    --hour &lt;utc_hour&gt; --month &lt;month&gt; \\\n    --day-of-year &lt;day&gt;\n</code></pre>"},{"location":"testing/predict/#parameters","title":"Parameters","text":"Parameter Required Description Example <code>--tx-grid</code> Yes Transmitter grid (4-char Maidenhead) <code>FN20</code> <code>--rx-grid</code> Yes Receiver grid (4-char Maidenhead) <code>IO91</code> <code>--band</code> Yes Band (160m, 80m, 60m, 40m, 30m, 20m, 17m, 15m, 12m, 10m) <code>20m</code> <code>--sfi</code> Yes Solar Flux Index <code>140</code> <code>--kp</code> Yes Kp geomagnetic index 0-9 <code>3</code> <code>--hour</code> Yes UTC hour 0-23 <code>14</code> <code>--month</code> Yes Month 1-12 <code>6</code> <code>--day-of-year</code> Yes Day of year 1-366 <code>172</code>"},{"location":"testing/predict/#example","title":"Example","text":"<pre><code>ionis-validate predict \\\n    --tx-grid DN26 --rx-grid IO91 \\\n    --band 20m --sfi 150 --kp 2 \\\n    --hour 14 --month 6 --day-of-year 172\n</code></pre> <p>Output:</p> <pre><code>============================================================\n  IONIS V22-gamma \u2014 Path Prediction\n============================================================\n\n  TX Grid:    DN26 (46.5N, -113.0E)\n  RX Grid:    IO91 (51.5N, -1.0E)\n  Distance:   7,842 km\n  Band:       20m (14.097 MHz)\n  Conditions: SFI 150, Kp 2.0\n  Time:       14:00 UTC, month 6, day 172\n\n  TX Solar:   +49.1 deg\n  RX Solar:   +54.2 deg\n\n  Raw Model:  +0.432 sigma\n  Override:   not triggered\n  Final SNR:  +0.432 sigma (-6.8 dB)\n\n  Mode Verdicts:\n    &gt;&gt;&gt; WSPR   OPEN    (threshold: -28 dB)\n    &gt;&gt;&gt; FT8    OPEN    (threshold: -21 dB)\n    &gt;&gt;&gt; CW     OPEN    (threshold: -15 dB)\n        RTTY   closed  (threshold: -5 dB)\n        SSB    closed  (threshold: +3 dB)\n</code></pre>"},{"location":"testing/predict/#how-it-works","title":"How It Works","text":"<p>The predictor:</p> <ol> <li>Converts Maidenhead grids to latitude/longitude</li> <li>Computes path geometry (distance, azimuth, midpoint)</li> <li>Calculates solar depression angles for both endpoints</li> <li>Engineers 17 features matching training exactly</li> <li>Runs the V22-gamma checkpoint (single forward pass)</li> <li>Applies PhysicsOverrideLayer (clamps high-band night paths if triggered)</li> <li>Denormalizes the sigma output to dB using per-band WSPR norm constants</li> <li>Applies mode thresholds to produce open/closed verdicts</li> </ol>"},{"location":"testing/predict/#physicsoverridelayer","title":"PhysicsOverrideLayer","text":"<p>After neural inference, a deterministic post-processing clamp is applied:</p> <ul> <li>Condition: freq &gt;= 21 MHz AND both endpoints below -6 deg solar depression AND prediction &gt; -1.0 sigma</li> <li>Action: Clamp prediction to -1.0 sigma</li> <li>Purpose: Close high bands (15m, 12m, 10m) when both endpoints are in darkness</li> </ul> <p>The override status is shown in the output as \"triggered\" or \"not triggered.\"</p>"},{"location":"testing/predict/#mode-thresholds","title":"Mode Thresholds","text":"Mode Threshold What It Means WSPR -28 dB Beacon minimum \u2014 signal floor FT8/FT4 -21 dB Digital decode limit CW -15 dB Readable by experienced operator RTTY -5 dB Machine-copy reliable SSB +3 dB Voice-quality communication <p>A prediction of -6.8 dB means WSPR, FT8, and CW will work. RTTY is marginal. SSB needs a stronger path.</p>"},{"location":"testing/predict/#tips","title":"Tips","text":"<ul> <li>Try different hours: HF propagation changes dramatically by time of day.   Sweep <code>--hour 0</code> through <code>--hour 23</code> to find your opening.</li> <li>Check SFI sensitivity: Compare <code>--sfi 70</code> (solar minimum) vs <code>--sfi 200</code>   (solar maximum) to see how much the sun matters for your path.</li> <li>Storm impact: Compare <code>--kp 1</code> (quiet) vs <code>--kp 5</code> (moderate storm) \u2014   high-latitude paths are most affected.</li> <li>Band comparison: The same path may be open on 20m but closed on 10m   depending on solar conditions.</li> <li>Day of year: Use <code>--day-of-year</code> to capture seasonal effects. The model   uses this for solar depression angle calculations.</li> </ul>"},{"location":"testing/reporting/","title":"Reporting Issues","text":"<p>Found a path where the model disagrees with your on-air experience? That's exactly the feedback we need.</p>"},{"location":"testing/reporting/#the-easy-way-ionis-validate-report","title":"The Easy Way: <code>ionis-validate report</code>","text":"<p>One command generates a complete, structured report you can paste directly into a GitHub Issue:</p> <pre><code># System info + full test suite results\nionis-validate report\n\n# Include your custom path tests\nionis-validate report --custom my_paths.json\n\n# System info only (skip test suite)\nionis-validate report --skip-tests\n</code></pre> <p>Progress prints to stderr. The report prints to stdout as markdown \u2014 copy it, open an issue, paste it in.</p> <pre><code># Pipe directly to clipboard (Linux)\nionis-validate report | xclip -selection clipboard\n\n# Save to file\nionis-validate report --custom my_paths.json &gt; report.md\n</code></pre>"},{"location":"testing/reporting/#where-to-report","title":"Where to Report","text":"<p>File an issue on the ionis-training repository. Structured templates guide you through each report type:</p> <p>https://github.com/IONIS-AI/ionis-training/issues/new/choose</p> <p>Three templates:</p> Template When to Use Test Suite Failure <code>ionis-validate test</code> reports a failure Prediction Disagreement Model prediction contradicts your on-air experience Custom Path Results Sharing results from <code>ionis-validate custom</code> <p>Each template has structured fields \u2014 fill in what you can, paste the <code>ionis-validate report</code> output in the \"Full Report\" field, and submit.</p>"},{"location":"testing/reporting/#what-to-include","title":"What to Include","text":""},{"location":"testing/reporting/#test-suite-failures","title":"Test Suite Failures","text":"<p>If <code>ionis-validate test</code> reports failures:</p> <ol> <li>Run <code>ionis-validate report</code> and paste the full output</li> <li>Or manually include: <code>ionis-validate info</code> output, failing test ID, expected vs actual</li> </ol>"},{"location":"testing/reporting/#prediction-disagreements","title":"Prediction Disagreements","text":"<p>If <code>ionis-validate predict</code> contradicts your experience:</p> <ol> <li>The exact command you ran (all arguments)</li> <li>What you expected and why (e.g., \"I work this path on FT8 every evening\")</li> <li>Approximate date and UTC time of your observation</li> <li>Solar conditions if you know them (SFI, Kp)</li> <li>Station details if relevant (antenna, power class)</li> </ol>"},{"location":"testing/reporting/#custom-path-results","title":"Custom Path Results","text":"<p>If your JSON file with <code>expect_open</code> assertions has failures:</p> <ol> <li>Run <code>ionis-validate report --custom your_file.json</code></li> <li>The report includes your JSON, the output, and system info \u2014 all in one paste</li> </ol>"},{"location":"testing/reporting/#what-happens-next","title":"What Happens Next","text":"<p>Every beta test result gets reviewed. Reports are tagged by model version in GitHub Issues, so feedback flows directly into the next version's development cycle.</p> <p>Paths where the model consistently disagrees with experienced operators become training data for the next version. Your custom path JSON files are particularly valuable \u2014 they represent real-world ground truth that no public dataset captures.</p>"},{"location":"testing/test-suite/","title":"Test Suite","text":"<p>The IONIS validation suite runs 29 automated tests that verify the V22-gamma model behaves correctly \u2014 operator-grounded physics gates and band x time discrimination.</p>"},{"location":"testing/test-suite/#running","title":"Running","text":"<pre><code>ionis-validate test\n</code></pre> <p>All tests run sequentially. Each prints PASS or FAIL with details. The runner exits with code 0 if all pass, non-zero otherwise.</p>"},{"location":"testing/test-suite/#test-groups","title":"Test Groups","text":""},{"location":"testing/test-suite/#ki7mt-operator-tests-18-tests","title":"KI7MT Operator Tests (18 tests)","text":"<p>Eighteen operator-grounded test paths derived from 49,000 QSOs and 5.7 million contest signatures. Each path has a physically-motivated expectation based on real operating experience from KI7MT (DN13, Idaho).</p> <p>The tests are organized into 4 gates:</p> Gate Tests Purpose Raw model 17 hard pass V22-gamma predictions without override PhysicsOverrideLayer 17 hard pass + acid test Override clamps high-band night Regression 17 No paths that passed raw should fail with override Acid test 1 10m EU at night must be negative (override fires) <p>Examples:</p> <ul> <li>20m FN31 to JO21 at 14 UTC in June (US East Coast to England, daytime)</li> <li>160m DN13 to EM73 at 03 UTC (domestic NVIS, nighttime)</li> <li>10m DN13 to JN48 at 03 UTC (acid test \u2014 both endpoints dark, override fires)</li> </ul>"},{"location":"testing/test-suite/#tst-900-band-x-time-discrimination-11-tests","title":"TST-900: Band x Time Discrimination (11 tests)","text":"<p>Eleven band x time combinations testing whether the model correctly discriminates propagation across HF bands and time periods:</p> Test Band Time Expected TST-901 20m Day Positive SNR TST-902 40m Night Positive SNR TST-903 10m Day, low SFI Marginal (known fail) TST-904 15m Twilight Marginal (known fail) TST-905\u2013911 Various Various Band-appropriate response <p>Expected score: 9/11. TST-903 and TST-904 are known limitations \u2014 the model predicts these marginal conditions slightly outside the expected range. These are tracked for future model versions.</p>"},{"location":"testing/test-suite/#interpreting-results","title":"Interpreting Results","text":"<p>A passing run looks like:</p> <pre><code>============================================================\n  IONIS V22-gamma \u2014 Validation Suite\n============================================================\n\n  KI7MT Operator Tests\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Gate 1: Raw Model ................ 16/17 hard pass\n  Gate 2: Override ................. 17/17 hard pass\n  Gate 3: Regression ............... 0 regressions\n  Gate 4: Acid Test ................ PASS (override fired)\n  KI7MT Result: 18/18 PASS\n\n  TST-900 Band x Time\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  TST-901 .... PASS\n  TST-902 .... PASS\n  ...\n  TST-900 Result: 9/11\n\n  Summary: KI7MT 18/18 PASS | TST-900 9/11\n</code></pre> <p>If a test fails, the output includes:</p> <ul> <li>The test ID and description</li> <li>Expected vs actual values</li> <li>Suggested diagnostic steps</li> </ul> <p>Report failures via Reporting Issues.</p>"},{"location":"testing/test-suite/#v20-legacy-test-suite","title":"V20 Legacy Test Suite","text":"<p>The V20 test specification (TST-100 through TST-800, 62 tests) is documented in the Test Specification for historical reference. V22-gamma replaces this battery with the focused operator-grounded validation above.</p>"},{"location":"tools/","title":"Pipeline Apps","text":"<p>The IONIS data pipeline ships 19 CLI apps across three packages, plus one external tool used for validation. All pipeline apps use the <code>ch-go</code> native protocol for ClickHouse connectivity with LZ4 compression. The PSK Reporter collector uses MQTT for real-time spot streaming.</p>"},{"location":"tools/#wspr-ingestion","title":"WSPR Ingestion","text":"App Type Package Description wspr-turbo Go ionis-apps Streaming .gz \u2192 ClickHouse, 22 Mrps (16 workers) wspr-shredder Go ionis-apps Uncompressed CSV \u2192 ClickHouse, 21 Mrps wspr-parquet-native Go ionis-apps Parquet \u2192 ClickHouse, 8.4 Mrps wspr-download Go ionis-apps Parallel archive downloader from wsprnet.org"},{"location":"tools/#solar-pipeline","title":"Solar Pipeline","text":"App Type Package Description solar-download Go ionis-apps Multi-source downloader (10 NOAA/SIDC endpoints) solar-ingest Go ionis-apps Solar/geomagnetic data ingester solar-backfill Go ionis-apps GFZ Potsdam historical SSN/SFI/Kp (1932\u2013present) solar-refresh Shell ionis-apps Download + truncate + ingest pipeline solar-live-update Shell ionis-apps Now-Casting updater, 15-min cron solar-history-load Shell ionis-apps Training data loader, 6-hour cron"},{"location":"tools/#contest-rbn","title":"Contest &amp; RBN","text":"App Type Package Description contest-download Go ionis-apps CQ/ARRL Cabrillo log downloader (15 contests) contest-ingest Go ionis-apps Cabrillo V2/V3 parser \u2192 ClickHouse with enrichment rbn-download Go ionis-apps RBN daily ZIP downloader (2009\u2013present) rbn-ingest Go ionis-apps RBN ZIP \u2192 CSV \u2192 ClickHouse ingester"},{"location":"tools/#psk-reporter","title":"PSK Reporter","text":"App Type Package Description pskr-collector Go ionis-apps MQTT real-time spot collector \u2192 gzip JSONL (~22M spots/day) pskr-ingest Go ionis-apps Incremental JSONL \u2192 ClickHouse loader with watermark tracking"},{"location":"tools/#database","title":"Database","text":"App Type Package Description ionis-db-init Shell ionis-core Initialize ClickHouse schemas (idempotent) ionis-env Shell ionis-core Standardized environment variables (sourceable) db-validate Go ionis-apps Validate ClickHouse table row counts"},{"location":"tools/#cuda-engine","title":"CUDA Engine","text":"App Type Package Description bulk-processor CUDA ionis-cuda Float4 embedding generator \u2192 wspr.silver"},{"location":"tools/#validation-external","title":"Validation (External)","text":"App Type Package Description voacapl Fortran External (local build) NTIA/ITS HF propagation prediction engine"},{"location":"tools/contest/","title":"Contest &amp; RBN Apps","text":"<p>Four Go binaries for downloading and ingesting amateur radio contest logs and Reverse Beacon Network spot data.</p>"},{"location":"tools/contest/#contest-download","title":"contest-download","text":"<p>Downloads public Cabrillo logs from CQ and ARRL contest websites. Supports 15 contest series with configurable year/mode filtering and rate limiting. Part of <code>ionis-apps</code> (Go binary).</p> <pre><code>contest-download v3.0.2 \u2014 Contest Log Downloader\n\nUsage: contest-download [flags]\n\nDownloads public Cabrillo logs from CQ and ARRL contest websites.\nGood neighbor: sequential requests, configurable delay, resume-friendly.\n\n  -contest string\n        Contest key (use --list to see options, or 'all') (default \"all\")\n  -delay duration\n        Delay between HTTP requests (default 3s)\n  -dest string\n        Destination directory (default \"/mnt/contest-logs\")\n  -dry-run\n        Fetch indexes and build manifests only, no log downloads\n  -list\n        List available contests and exit\n  -mode string\n        Download only this mode: ph, cw (empty = all modes)\n  -refresh\n        Re-fetch index pages even if manifest exists\n  -timeout duration\n        HTTP request timeout (default 1m0s)\n  -year int\n        Download only this year (0 = all years)\n\nContests:\n  cq-ww            CQ WW          CQ     modes: ph, cw         years: 2005-2025\n  cq-wpx           CQ WPX         CQ     modes: ph, cw         years: 2008-2025\n  cq-ww-rtty       CQ WW RTTY     CQ     modes: (single mode)  years: 2009-2024\n  cq-wpx-rtty      CQ WPX RTTY    CQ     modes: (single mode)  years: 2012-2025\n  cq-160           CQ 160         CQ     modes: ph, cw         years: 2022-2025\n  ww-digi          WW Digi        CQ     modes: (single mode)  years: 2019-2025\n  arrl-dx-cw       ARRL DX CW     ARRL   modes: (single mode)  years: 2018-2025\n  arrl-dx-ph       ARRL DX Phone  ARRL   modes: (single mode)  years: 2018-2025\n  arrl-10m         ARRL 10m       ARRL   modes: (single mode)  years: 2018-2024\n  arrl-160m        ARRL 160m      ARRL   modes: (single mode)  years: 2018-2024\n  arrl-ss-cw       ARRL SS CW     ARRL   modes: (single mode)  years: 2018-2024\n  arrl-ss-ph       ARRL SS Phone  ARRL   modes: (single mode)  years: 2018-2024\n  arrl-rtty        ARRL RTTY RU   ARRL   modes: (single mode)  years: 2018-2025\n  arrl-digi        ARRL Digital   ARRL   modes: (single mode)  years: 2022-2025\n  iaru-hf          IARU HF        ARRL   modes: (single mode)  years: 2018-2025\n\nExamples:\n  contest-download --list\n  contest-download --contest cq-ww --year 2024 --mode cw\n  contest-download --contest arrl-dx-cw --year 2024\n  contest-download --dry-run\n  contest-download --delay 5s\n</code></pre>"},{"location":"tools/contest/#contest-ingest","title":"contest-ingest","text":"<p>Walks contest log directories, parses Cabrillo V2/V3 headers and QSO lines, normalizes bands via ADIF lookup, and bulk-inserts into <code>contest.bronze</code>. Optionally enriches <code>wspr.callsign_grid</code> with grid locators. Part of <code>ionis-apps</code> (Go binary).</p> <pre><code>contest-ingest v3.0.5 \u2014 Parse Cabrillo contest logs into ClickHouse\n\nUsage: contest-ingest [flags]\n\nWalks --src/{contest}/{yearmode}/*.log, parses Cabrillo headers\nand QSO lines, normalizes band via ADIF lookup, and inserts into\nClickHouse using ch-go native protocol with LZ4 compression.\n\nUses contest.ingest_log watermark table for incremental loading.\n\n  -batch int\n        Rows per INSERT batch (default 100000)\n  -contest string\n        Process only this contest key (empty = all)\n  -db string\n        ClickHouse database (default \"contest\")\n  -dry-run\n        List files that would be processed, then exit\n  -enrich\n        Also insert GRID-LOCATOR into wspr.callsign_grid\n  -full\n        Full reload: process all files regardless of watermark\n  -host string\n        ClickHouse host:port (default \"192.168.1.90:9000\")\n  -prime\n        Bootstrap watermark for existing files (no data loaded)\n  -src string\n        Source directory with {contest}/{yearmode}/*.log (default \"/mnt/contest-logs\")\n  -table string\n        ClickHouse table (default \"bronze\")\n  -workers int\n        Parallel file workers (default 8)\n\nExamples:\n  contest-ingest --contest cq-ww --workers 4\n  contest-ingest --enrich\n  contest-ingest --prime                           # Bootstrap watermark\n  contest-ingest --dry-run                         # Preview what would load\n  contest-ingest --full                            # Reload all files\n  contest-ingest --src /mnt/contest-logs --host 10.60.1.1:9000\n</code></pre>"},{"location":"tools/contest/#rbn-download","title":"rbn-download","text":"<p>Downloads daily ZIP archives of CW/RTTY spots from the Reverse Beacon Network. Covers the full archive from 2009 to present (~6,183 files, ~21 GB). Part of <code>ionis-apps</code> (Go binary).</p> <pre><code>rbn-download v3.0.2 \u2014 Reverse Beacon Network Archive Downloader\n\nUsage: rbn-download [flags]\n\nDownloads daily ZIP archives of CW/RTTY spots from the RBN.\nEach ZIP contains a CSV with 13 columns (callsign, freq, SNR, etc.).\nGood neighbor: sequential requests, configurable delay, resume-friendly.\n\n  -delay duration\n        Delay between HTTP requests (default 3s)\n  -dest string\n        Destination directory (default \"/mnt/rbn-data\")\n  -dry-run\n        Show what would be downloaded, don't fetch\n  -from string\n        Start date (YYYY-MM-DD) (default \"2009-02-21\")\n  -list\n        List available year ranges and estimated sizes\n  -timeout duration\n        HTTP request timeout (default 2m0s)\n  -to string\n        End date (YYYY-MM-DD, default: yesterday)\n  -year int\n        Download only this year (0 = all years)\n\nData source: https://data.reversebeacon.net/rbn_history/\nArchive range: 2009-02-21 to present (~6,183 files, ~21 GB)\n\nExamples:\n  rbn-download --list\n  rbn-download --year 2024\n  rbn-download --from 2024-01-01 --to 2024-12-31\n  rbn-download --dry-run\n  rbn-download --delay 5s\n</code></pre>"},{"location":"tools/contest/#rbn-ingest","title":"rbn-ingest","text":"<p>Streams RBN daily ZIP archives into ClickHouse. Handles all three CSV format eras (11-column 2009\u20132010, 13-column 2011+) with automatic detection. Part of <code>ionis-apps</code> (Go binary).</p> <pre><code>rbn-ingest v3.0.5 \u2014 Stream RBN ZIP archives into ClickHouse\n\nUsage: rbn-ingest [flags]\n\nReads daily ZIP files from --src/{year}/*.zip, parses CSV,\nnormalizes band via ADIF lookup, and inserts into ClickHouse\nusing ch-go native protocol with LZ4 compression.\n\nUses rbn.ingest_log watermark table for incremental loading.\n\nHandles all three RBN CSV format eras:\n  2009-2010: 11 columns (no speed/tx_mode)\n  2011+:     13 columns (speed + tx_mode)\n\n  -batch int\n        Rows per INSERT batch (default 100000)\n  -db string\n        ClickHouse database (default \"rbn\")\n  -dry-run\n        List files that would be processed, then exit\n  -full\n        Full reload: drop day partitions and re-ingest all files\n  -host string\n        ClickHouse host:port (default \"192.168.1.90:9000\")\n  -prime\n        Bootstrap watermark for existing files (no data loaded)\n  -src string\n        Source directory with {year}/*.zip (default \"/mnt/rbn-data\")\n  -table string\n        ClickHouse table (default \"bronze\")\n  -workers int\n        Parallel ZIP workers (default 8)\n  -year int\n        Process only this year (0 = all)\n\nExamples:\n  rbn-ingest --year 2024 --workers 4\n  rbn-ingest --workers 8\n  rbn-ingest --prime                               # Bootstrap watermark\n  rbn-ingest --dry-run                             # Preview what would load\n  rbn-ingest --full                                # Reload all files\n  rbn-ingest --src /mnt/rbn-data --host 10.60.1.1:9000\n</code></pre>"},{"location":"tools/cuda/","title":"CUDA Engine","text":"<p>Local Build Only</p> <p><code>bulk-processor</code> is not included in the <code>ionis-cuda</code> RPM. COPR build servers do not have NVIDIA GPUs or the CUDA toolkit, so this binary must be built locally on a host with a supported GPU and CUDA 13.1+.</p>"},{"location":"tools/cuda/#bulk-processor","title":"bulk-processor","text":"<p>GPU-accelerated float4 embedding generator for the WSPR silver layer. Reads date-ranged batches from <code>wspr.bronze</code>, JOINs with <code>solar.bronze</code> for solar/geomagnetic context, computes signature embeddings on the GPU, and writes results to <code>wspr.silver</code>. Part of <code>ionis-cuda</code> (CUDA binary).</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Bulk Embedding Processor - Blackwell sm_120                \u2502\n\u2502  ionis-cuda v3.0.2                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nUsage: bulk-processor --start YYYY-MM-DD --end YYYY-MM-DD [options]\n\nRequired:\n  --start DATE      Start date (inclusive)\n  --end DATE        End date (inclusive)\n\nOptions:\n  --host ADDR       ClickHouse host (default: $CH_HOST or 192.168.1.90)\n  --port N          ClickHouse port (default: $CH_PORT or 9000)\n  --hourly          Process hour-by-hour (default: daily)\n  --band N          Filter by ADIF band ID (0 = all bands)\n  --dry-run         Count rows only, don't process\n  --batch-size N    Max rows per GPU batch (default: 1000000)\n  -h, --help        Show this help\n\nExample:\n  bulk-processor --start 2025-01-01 --end 2025-12-31 --hourly\n</code></pre>"},{"location":"tools/cuda/#building-from-source","title":"Building from Source","text":"<p>Requirements:</p> <ul> <li>CUDA Toolkit 13.1+ with <code>nvcc</code></li> <li>CMake 3.20+</li> <li>C++20 compiler</li> <li><code>clickhouse-cpp</code> v2.5.1 (fetched automatically by CMake if not installed)</li> <li>NVIDIA GPU (built for sm_120 / Blackwell by default)</li> </ul> <p>Build steps:</p> <pre><code>cd ionis-cuda\nmkdir build &amp;&amp; cd build\ncmake ..\ncmake --build . -j$(nproc)\n</code></pre> <p>The binary is produced at <code>build/bulk-processor</code>.</p> <p>Install to user PATH:</p> <pre><code>cp build/bulk-processor ~/.local/bin/bulk-processor\n</code></pre>"},{"location":"tools/cuda/#supported-architectures","title":"Supported Architectures","text":"<p>The CMake build targets sm_120 (Blackwell). The alternative Makefile produces a fat binary covering multiple generations:</p> Flag Architecture GPUs sm_80 Ampere A100 sm_86 Ampere RTX 30xx sm_89 Ada Lovelace RTX 40xx sm_100 Blackwell RTX 50xx sm_120 Blackwell refresh RTX PRO 6000 compute_120 PTX JIT Future GPUs"},{"location":"tools/database/","title":"Database Apps","text":"<p>Two shell scripts and one Go binary for managing the ClickHouse environment.</p>"},{"location":"tools/database/#ionis-db-init","title":"ionis-db-init","text":"<p>Idempotent schema initializer for all ClickHouse databases and tables. Executes DDL files to create or recreate the full schema (wspr, solar, contest, rbn, data_mgmt). Part of <code>ionis-core</code> (Shell script).</p> <pre><code>Usage: ionis-db-init [OPTIONS]\nOptions:\n  --auto-confirm   Skip confirmation prompts\n  --force          Recreate tables (DESTROYS DATA)\n  --dry-run        Show what would be done without executing\n  --stamp-version  Record installed version in data_mgmt.lab_versions\n  -h, --help       Show this help message\n</code></pre>"},{"location":"tools/database/#ionis-env","title":"ionis-env","text":"<p>Standardized environment variables for the AI Lab. Exports ClickHouse connection settings, storage paths (RAID-0 NVMe optimized), application paths (FHS-compliant), and performance tuning defaults. Designed to be sourced, not executed directly. Part of <code>ionis-core</code> (Shell script).</p> <pre><code># Usage: source ionis-env\n\nIONIS Environment (3.0.2) Loaded.\n  WSPR Data.......: /mnt/ai-stack/wspr-data\n  Solar Data......: /mnt/ai-stack/solar-data\n  ClickHouse Data.: /mnt/ai-stack/clickhouse\n  ClickHouse Host.: localhost:9000\n</code></pre>"},{"location":"tools/database/#db-validate","title":"db-validate","text":"<p>Validates ClickHouse table row counts across all four data domains. Reports pass/fail status with actual counts. Useful for post-ingest verification. Part of <code>ionis-apps</code> (Go binary, not yet installed to PATH).</p> <pre><code>db-validate v3.0.2 \u2014 Validate ClickHouse table row counts\n\nUsage: db-validate [flags]\n\n  -all\n        Validate all tables (default if no flags)\n  -contest\n        Validate contest tables\n  -host string\n        ClickHouse host:port (default \"192.168.1.90:9000\")\n  -rbn\n        Validate rbn tables\n  -solar\n        Validate solar tables\n  -wspr\n        Validate wspr tables\n\nExamples:\n  db-validate --all\n  db-validate --wspr --solar\n  db-validate --rbn --host 10.60.1.1:9000\n</code></pre>"},{"location":"tools/pskr/","title":"PSK Reporter Apps","text":"<p>Real-time MQTT spot collector for PSK Reporter reception data.</p> <p>PSK Reporter (pskreporter.info) is the largest real-time amateur radio reception report network, created by Philip Gladstone, N1DQ. Over 27,000 active monitors contribute millions of FT8/FT4/WSPR spots daily. The MQTT real-time feed is provided by Tom Sevart, M0LTE.</p>"},{"location":"tools/pskr/#pskr-collector","title":"pskr-collector","text":"<p>Long-running MQTT daemon that subscribes to the PSK Reporter feed, parses JSON spots, normalizes bands via ADIF lookup, and writes hourly-rotated gzip JSONL files to <code>/mnt/pskr-data</code>. Part of <code>ionis-apps</code> (Go binary).</p> <p>This is stage 1 of a two-stage pipeline:</p> <ol> <li>Collect (this tool): MQTT \u2192 gzip JSONL files on ZFS</li> <li>Ingest (<code>pskr-ingest</code>): JSONL \u2192 ClickHouse <code>pskr.bronze</code></li> </ol> <p>Both stages are live. <code>pskr-ingest</code> runs hourly via cron, using a watermark table (<code>pskr.ingest_log</code>) to track loaded files for incremental processing.</p> <p>The disk-first design provides durability (no data loss if ClickHouse is down), replayability (re-ingest after schema changes), and consistency with the WSPR/RBN/contest pipeline pattern.</p> <pre><code>pskr-collector v3.0.2 \u2014 PSK Reporter MQTT real-time spot collector\n\nUsage: pskr-collector [flags]\n\nSubscribes to PSK Reporter MQTT feed and writes hourly-rotated\ngzip JSONL files to --outdir/YYYY/MM/DD/spots-HHMMSS.jsonl.gz.\n\nThis is a long-running daemon. Use Ctrl+C or SIGTERM for graceful shutdown.\n\n  -broker string\n        MQTT broker address (default \"mqtt.pskreporter.info:1883\")\n  -buffer int\n        Channel buffer size (default 100000)\n  -client-id string\n        MQTT client ID (default: auto-generated)\n  -hf-only\n        Filter to HF bands only (160m-10m) (default true)\n  -outdir string\n        Output directory for JSONL files (default \"/mnt/pskr-data\")\n  -rotate duration\n        File rotation interval (default 1h0m0s)\n  -stats duration\n        Stats reporting interval (default 1m0s)\n  -topic string\n        MQTT topic filter (default \"pskr/filter/v2/#\")\n\nExamples:\n  pskr-collector\n  pskr-collector --hf-only=false\n  pskr-collector --rotate 30m --outdir /tmp/pskr-test\n  pskr-collector --topic 'pskr/filter/v2/20m/#'\n</code></pre>"},{"location":"tools/pskr/#output-format","title":"Output Format","text":"<p>Hourly-rotated gzip JSONL files organized by date:</p> <pre><code>/mnt/pskr-data/\n\u2514\u2500\u2500 2026/\n    \u2514\u2500\u2500 02/\n        \u2514\u2500\u2500 09/\n            \u251c\u2500\u2500 spots-150000.jsonl.gz\n            \u251c\u2500\u2500 spots-160000.jsonl.gz\n            \u2514\u2500\u2500 ...\n</code></pre> <p>Each line is a JSON object:</p> <pre><code>{\"ts\":\"2026-02-09T22:42:30Z\",\"sc\":\"K1UHF\",\"sg\":\"FN42\",\"rc\":\"EA8BFK\",\"rg\":\"IL38bo\",\"f\":7076312,\"band\":105,\"mode\":\"FT8\",\"snr\":-12}\n</code></pre> Field Description <code>ts</code> Timestamp (UTC, ISO 8601) <code>sc</code> Sender callsign <code>sg</code> Sender grid (4-6 char Maidenhead, empty if unavailable) <code>rc</code> Receiver callsign <code>rg</code> Receiver grid (4-6 char Maidenhead) <code>f</code> Frequency in Hz <code>band</code> ADIF band ID (102-111 for HF) <code>mode</code> Mode (FT8, FT4, WSPR, JS8, CW, etc.) <code>snr</code> Signal-to-noise ratio in dB (machine-decoded)"},{"location":"tools/pskr/#observed-data-quality","title":"Observed Data Quality","text":"<p>From a 30-second test run (7,607 spots):</p> Metric Value Throughput ~300 HF spots/sec sustained SNR range -34 to +38 dB (mean -9.5) Non-zero SNR 95.8% Sender grids present 14.7% Receiver grids present 28.0% <p>Mode distribution: 88.7% FT8, 9.1% WSPR, 1.5% FT4, 0.5% JS8, 0.1% CW. All 10 HF bands represented (160m through 10m).</p>"},{"location":"tools/pskr/#mqtt-details","title":"MQTT Details","text":"<ul> <li>Broker: <code>mqtt.pskreporter.info:1883</code> (anonymous, no auth)</li> <li>Protocol: MQTT v3.1.1, QoS 0 (at-most-once)</li> <li>Topic: <code>pskr/filter/v2/{band}/{mode}/{sendercall}/{receivercall}/{senderlocator}/{receiverlocator}/{sendercountry}/{receivercountry}</code></li> <li>Wildcard: <code>pskr/filter/v2/#</code> subscribes to all spots</li> <li>Auto-reconnect: Built-in with exponential backoff (1s to 60s)</li> </ul>"},{"location":"tools/pskr/#running-as-a-service","title":"Running as a Service","text":"<p>A systemd unit file is provided in <code>ionis-apps/scripts/pskr-collector.service</code>:</p> <pre><code># Install the service\nsudo cp scripts/pskr-collector.service /etc/systemd/system/\nsudo systemctl daemon-reload\nsudo systemctl enable --now pskr-collector\n\n# Check status\nsystemctl status pskr-collector\n\n# Follow logs\njournalctl -u pskr-collector -f\n\n# Stop collection\nsudo systemctl stop pskr-collector\n</code></pre> <p>The unit runs as <code>ki7mt:ki7mt</code>, restarts on failure (30s delay), uses <code>SIGTERM</code> for graceful shutdown (flushes buffers), and is hardened with <code>ProtectSystem=strict</code> and <code>ReadWritePaths=/mnt/pskr-data</code>.</p> <p>Alternatively, for quick testing via tmux:</p> <pre><code>tmux new-session -d -s pskr 'pskr-collector 2&gt;&amp;1 | tee /var/log/pskr-collector.log'\n</code></pre>"},{"location":"tools/pskr/#estimated-collection-rates","title":"Estimated Collection Rates","text":"<p>At ~300 HF spots/sec: ~26M spots/day, ~780M spots/month. At ~19 bytes/spot compressed: ~15 GB/year on ZFS (lz4). With <code>--hf-only=false</code>: higher volume including VHF/UHF/microwave.</p>"},{"location":"tools/pskr/#clickhouse-schema","title":"ClickHouse Schema","text":"<p>The <code>pskr.bronze</code> table is defined in <code>ionis-core/src/22-pskr_schema_v1.sql</code>:</p> <pre><code>CREATE TABLE IF NOT EXISTS pskr.bronze (\n    timestamp      DateTime,\n    sender_call    String,\n    sender_grid    String,\n    receiver_call  String,\n    receiver_grid  String,\n    frequency      UInt64,\n    band           Int32,\n    mode           LowCardinality(String),\n    snr            Int16\n) ENGINE = MergeTree()\nPARTITION BY toYYYYMM(timestamp)\nORDER BY (band, timestamp, sender_grid, receiver_grid);\n</code></pre>"},{"location":"tools/pskr/#pskr-ingest","title":"pskr-ingest","text":"<p>Incremental JSONL \u2192 ClickHouse loader. Reads gzip JSONL files written by <code>pskr-collector</code> and bulk-inserts into <code>pskr.bronze</code>. Tracks loaded files via <code>pskr.ingest_log</code> watermark table for safe, idempotent cron-based loading. Part of <code>ionis-apps</code> (Go binary).</p> <pre><code>pskr-ingest v3.0.2 \u2014 PSK Reporter JSONL \u2192 ClickHouse ingester\n\nUsage: pskr-ingest [flags]\n\nReads gzip JSONL files from --src, parses spots, and inserts into\nClickHouse using ch-go native protocol with LZ4 compression.\n\nUses pskr.ingest_log watermark table to skip already-loaded files.\n\n  -batch int\n        Rows per INSERT batch (default 100000)\n  -db string\n        ClickHouse database (default \"pskr\")\n  -dry-run\n        List files that would be processed, then exit\n  -host string\n        ClickHouse host:port (default \"192.168.1.90:9000\")\n  -min-age duration\n        Minimum file age to ingest (skip active file) (default 5m0s)\n  -prime\n        Bootstrap watermark for existing files (no data loaded)\n  -src string\n        Source directory (default \"/mnt/pskr-data\")\n  -table string\n        ClickHouse table (default \"bronze\")\n  -workers int\n        Parallel file workers (default 4)\n\nExamples:\n  pskr-ingest                                  # Incremental (default)\n  pskr-ingest --prime                          # Bootstrap watermark\n  pskr-ingest --dry-run                        # Preview what would load\n  pskr-ingest --src /mnt/pskr-data --host 10.60.1.1:9000\n</code></pre>"},{"location":"tools/pskr/#watermark-tracking","title":"Watermark Tracking","text":"<p><code>pskr-ingest</code> uses the <code>pskr.ingest_log</code> table (ReplacingMergeTree) to track which files have been loaded. Each successful file insert records <code>file_path</code>, <code>file_size</code>, <code>row_count</code>, <code>elapsed_ms</code>, and <code>hostname</code>.</p> <ul> <li>Incremental (default): Skips files already in the watermark. Only   loads new files.</li> <li><code>--prime</code>: Marks all existing files as loaded (<code>row_count=0</code>) without   inserting data. Use this to bootstrap the watermark after a schema change   or on first install.</li> <li><code>--dry-run</code>: Lists files that would be processed without loading.</li> <li><code>--min-age</code>: Skips files newer than 5 minutes (default) to avoid   reading the currently-open hourly rotation file.</li> </ul>"},{"location":"tools/pskr/#cron-usage","title":"Cron Usage","text":"<pre><code>5 * * * *   pskr-ingest --src /mnt/pskr-data --host 192.168.1.90:9000 2&gt;&amp;1 | logger -t pskr-ingest\n</code></pre> <p>Runs at 5 minutes past each hour. The 5-minute offset ensures the previous hour's file has been rotated and closed by <code>pskr-collector</code>.</p>"},{"location":"tools/pskr/#data-source-attribution","title":"Data Source Attribution","text":"<p>PSK Reporter is created and operated by Philip Gladstone, N1DQ. The MQTT real-time feed is provided by Tom Sevart, M0LTE. We gratefully acknowledge their contributions to the amateur radio community.</p>"},{"location":"tools/solar/","title":"Solar Pipeline Apps","text":"<p>Four Go binaries and three shell scripts for downloading and ingesting solar flux, geomagnetic, X-ray, and solar wind data.</p>"},{"location":"tools/solar/#solar-download","title":"solar-download","text":"<p>Multi-source downloader covering 10 NOAA, SIDC, and GOES endpoints. Downloads daily/monthly sunspot numbers, F10.7 flux, Kp indices, and X-ray flux. Part of <code>ionis-apps</code> (Go binary).</p> <pre><code>solar-download v3.0.2 - Solar Data Downloader\n\nUsage: solar-download [OPTIONS]\n\nDownloads solar flux data from NOAA and SIDC sources.\n\n  -dest string\n        Destination directory (default \"/mnt/ai-stack/solar-data/raw\")\n  -list\n        List available data sources\n  -source string\n        Source to download (or 'all') (default \"all\")\n  -timeout duration\n        HTTP timeout per download (default 1m0s)\n\nData Sources:\n  sidc_daily      SIDC daily sunspot numbers (1818-present)\n  sidc_monthly    SIDC monthly sunspot numbers (1749-present)\n  noaa_sfi        NOAA solar cycle indices (F10.7 flux, SSN)\n  noaa_predicted  NOAA predicted solar cycle\n  penticton_daily Penticton 10.7cm daily flux\n  noaa_sfi_summary NOAA 10.7cm solar flux summary (live)\n  noaa_sfi_30day  NOAA 10.7cm solar flux (30-day history)\n  noaa_kp         NOAA planetary K-index (3-hourly geomagnetic)\n  goes_xray       GOES X-ray flux (6-hour rolling window)\n  goes_xray_7day  GOES X-ray flux (7-day history for training)\n</code></pre>"},{"location":"tools/solar/#solar-ingest","title":"solar-ingest","text":"<p>Parses and ingests SIDC CSV, NOAA JSON, and GOES JSON files into ClickHouse <code>solar.bronze</code>. Supports truncate-and-reload for clean refreshes. Part of <code>ionis-apps</code> (Go binary).</p> <pre><code>solar-ingest v3.0.2 - Solar Flux Data Ingester\n\nUsage: solar-ingest [OPTIONS] [files...]\n\nIngests solar flux data from NOAA/SIDC/GOES sources into ClickHouse.\n\nSupported formats:\n  - SIDC CSV (sidc_*.csv): Daily sunspot numbers\n  - SFI JSON (sfi_daily_flux.txt): NOAA solar flux indices\n  - Kp JSON (noaa_kp_index.json): Planetary K-index (3-hourly)\n  - X-ray JSON (goes_xray_flux.json): GOES X-ray flux (6-hour)\n\n  -ch-db string\n        ClickHouse database (default \"solar\")\n  -ch-host string\n        ClickHouse address (default \"127.0.0.1:9000\")\n  -ch-table string\n        ClickHouse table (default \"bronze\")\n  -source-dir string\n        Solar data source directory (default \"/mnt/ai-stack/solar-data/raw\")\n  -truncate\n        Truncate table before insert\n</code></pre>"},{"location":"tools/solar/#solar-backfill","title":"solar-backfill","text":"<p>Downloads and parses the GFZ Potsdam composite file containing SSN, SFI (F10.7), and 3-hourly Kp/ap indices from 1932 to present. Inserts into <code>solar.bronze</code>. Part of <code>ionis-apps</code> (Go binary).</p> <pre><code>solar-backfill v3.0.2 \u2014 Historical Solar Index Backfill (GFZ Potsdam)\n\nDownloads SSN, SFI (F10.7), and 3-hourly Kp/ap from GFZ Potsdam\nand inserts into ClickHouse solar.bronze.\n\nSource: https://kp.gfz-potsdam.de/app/files/Kp_ap_Ap_SN_F107_since_1932.txt\n\nUsage: solar-backfill [OPTIONS]\n\n  -ch-db string\n        ClickHouse database (default \"solar\")\n  -ch-host string\n        ClickHouse native protocol address (default \"127.0.0.1:9000\")\n  -ch-table string\n        ClickHouse table (default \"bronze\")\n  -dry-run\n        Parse only, no ClickHouse insert\n  -end string\n        End date (default: today)\n  -file string\n        Local GFZ file (skip download)\n  -start string\n        Start date (YYYY-MM-DD) (default \"2020-01-01\")\n  -timeout int\n        HTTP download timeout (seconds) (default 120)\n\nExamples:\n  solar-backfill -ch-host 192.168.1.90:9000 -start 2020-01-01\n  solar-backfill -file /tmp/Kp_ap_Ap_SN_F107_since_1932.txt -dry-run\n</code></pre>"},{"location":"tools/solar/#dscovr-ingest","title":"dscovr-ingest","text":"<p>Downloads rolling 7-day magnetometer and plasma JSON from the DSCOVR satellite at the Sun-Earth L1 Lagrange point and inserts into ClickHouse <code>solar.dscovr</code>. The key column for model training is Bz (IMF southward component), which provides 15-45 minutes of predictive lead over the Kp index. Part of <code>ionis-apps</code> (Go binary).</p> <pre><code>dscovr-ingest v3.2.0 \u2014 DSCOVR L1 Solar Wind Ingester\n\nDownloads 7-day magnetometer + plasma JSON from NOAA SWPC\nand inserts into ClickHouse solar.dscovr.\n\nSources:\n  https://services.swpc.noaa.gov/products/solar-wind/mag-7-day.json\n  https://services.swpc.noaa.gov/products/solar-wind/plasma-7-day.json\n\nUsage: dscovr-ingest [OPTIONS]\n\n  -ch-host string\n        ClickHouse native protocol address (default \"192.168.1.90:9000\")\n  -dry-run\n        Download and parse only, skip insert\n  -timeout int\n        HTTP timeout in seconds (default 60)\n\nExamples:\n  dscovr-ingest -ch-host 192.168.1.90:9000\n  dscovr-ingest -dry-run\n</code></pre> <p>Columns ingested:</p> Column Type Description bz_gsm Float32 IMF Bz, GSM coords (nT). Southward (negative) = storm coupling bt Float32 Total magnetic field magnitude (nT) bx_gsm Float32 IMF Bx, GSM coords (nT) by_gsm Float32 IMF By, GSM coords (nT) speed Float32 Solar wind bulk speed (km/s) density Float32 Solar wind proton density (protons/cm\u00b3) temperature Float32 Solar wind proton temperature (K)"},{"location":"tools/solar/#solar-refresh","title":"solar-refresh","text":"<p>Full refresh pipeline: downloads fresh solar/geomagnetic data, truncates <code>solar.bronze</code>, and reloads all sources. Part of <code>ionis-apps</code> (Shell script).</p> <pre><code>solar-refresh v3.0.2 - Solar Data Refresh Utility\n\nUsage: solar-refresh [OPTIONS]\n\nDownloads fresh solar/geomagnetic data and performs a clean reload\ninto ClickHouse (truncate + ingest).\n\nOptions:\n  -d, --dest DIR     Destination directory (default: /mnt/ai-stack/solar-data/raw)\n  -n, --no-truncate  Append instead of truncate + reload\n  -q, --quiet        Suppress output\n  -h, --help         Show this help message\n\nEnvironment:\n  SOLAR_DATA_DIR     Override default data directory\n\nExamples:\n  solar-refresh                 # Full refresh (truncate + reload)\n  solar-refresh -n              # Append new data only\n  solar-refresh -d /tmp/solar   # Use alternate directory\n</code></pre>"},{"location":"tools/solar/#solar-live-update","title":"solar-live-update","text":"<p>Lightweight updater for the Now-Casting pipeline. Designed for 15-minute cron intervals to keep near-real-time solar indices current. Part of <code>ionis-apps</code> (Shell script).</p> <pre><code>Usage: solar-live-update [--refresh]\n  --refresh    Run solar-download first\n</code></pre>"},{"location":"tools/solar/#solar-history-load","title":"solar-history-load","text":"<p>Training data loader for the historical solar index pipeline. Designed for 6-hour cron intervals to keep training datasets aligned with latest observations. Part of <code>ionis-apps</code> (Shell script).</p> <pre><code>Usage: solar-history-load [--download]\n  --download    Download fresh data from NOAA SWPC first\n\nWithout --download, uses existing files in /mnt/ai-stack/solar-data/raw\n</code></pre>"},{"location":"tools/voacapl/","title":"Validation: VOACAP","text":"<p>External Tool \u2014 Local Build Only</p> <p><code>voacapl</code> is not part of the IONIS project. It is an independent HF propagation prediction engine maintained by James Watson, HZ1JW. We build it locally as a validation baseline to compare IONIS predictions against.</p>"},{"location":"tools/voacapl/#voacapl","title":"voacapl","text":"<p>VOACAP (Voice of America Coverage Analysis Program) is the NTIA/ITS professional HF propagation prediction engine, originally developed for the Voice of America. <code>voacapl</code> is the Linux port compiled with GFortran, maintaining the unchanged original prediction algorithms.</p> <p>IONIS uses VOACAP as an independent baseline: the same 1M contest QSO paths validated by <code>validate_v12.py</code> are run through VOACAP, and recall is compared side by side.</p> <pre><code>voacapl - release 0.7.5\n</code></pre>"},{"location":"tools/voacapl/#building-from-source","title":"Building from Source","text":"<p>Requirements:</p> <ul> <li>GFortran compiler</li> <li>GNU Autotools (automake, autoconf)</li> <li>~50 MB disk for the <code>itshfbc</code> data directory</li> </ul> <p>Install GFortran (Rocky Linux 9):</p> <pre><code>sudo dnf install -y gcc-gfortran\n</code></pre> <p>Build and install:</p> <pre><code>git clone https://github.com/jawatson/voacapl.git\ncd voacapl\nautoreconf -i\n./configure\nmake -j$(nproc)\nsudo make install\n</code></pre> <p>Initialize data directory:</p> <pre><code>makeitshfbc\n</code></pre> <p>This creates <code>~/itshfbc/</code> containing ionospheric coefficients (CCIR/URSI), antenna models, and propagation data tables. The engine reads from this directory at runtime.</p>"},{"location":"tools/voacapl/#usage","title":"Usage","text":"<p>Point-to-point prediction:</p> <pre><code>voacapl ~/itshfbc                              # default (voacapx.dat -&gt; voacapx.out)\nvoacapl ~/itshfbc input.dat output.out         # custom files\nvoacapl ~/itshfbc batch                        # batch mode (reads voacap.cir)\n</code></pre> <p>File arguments are relative to <code>run/</code></p> <p>The input and output filenames are resolved relative to the <code>run/</code> subdirectory inside the itshfbc root. So <code>voacapl ~/itshfbc input.dat output.out</code> reads <code>~/itshfbc/run/input.dat</code> and writes <code>~/itshfbc/run/output.out</code>. This is a Fortran heritage detail \u2014 the engine always operates inside <code>run/</code>.</p> <p>Options:</p> <pre><code>  -s, --silent           Reduce console output\n  -v                     Display version\n  --run-dir DIR          Specify input/output directory\n  --absorption-mode M    Override absorption model (W, I, A, or a)\n</code></pre>"},{"location":"tools/voacapl/#input-file-format","title":"Input File Format","text":"<p>VOACAP uses a text-based \"card deck\" format (Fortran heritage). Each line is a card specifying one parameter. A minimal input file for a single path prediction:</p> <pre><code>COEFFS    CCIR\nTIME          1   24    1    1\nMONTH      2024 6.00\nSUNSPOT    120.\nLABEL     TX Site                 RX Site\nCIRCUIT   46.50N   107.00W    48.50N    12.00E  S     0\nSYSTEM       1. 145. 0.10  90. 73.0 3.00 0.10\nFPROB      1.00 1.00 1.00 0.00\nANTENNA       1    1    2   30     0.000[default/const17.voa  ]  0.0    0.0100\nANTENNA       2    2    2   30     0.000[default/const17.voa  ]  0.0    0.0100\nFREQUENCY 14.10 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\nMETHOD       30    0\nEXECUTE\nQUIT\n</code></pre> <p>Key cards:</p> Card Purpose COEFFS Ionospheric coefficient set (CCIR or URSI88) TIME Start hour, end hour, increment, time reference (1=UT) MONTH Year and month (mm.dd format) SUNSPOT Smoothed sunspot number for the prediction period CIRCUIT TX lat/lon, RX lat/lon, path type (S=short) SYSTEM Power(kW), noise(dBW), min angle, req reliability(%), req SNR, MP tol, delay tol ANTENNA TX/RX antenna model, beam direction, and transmit power (kW) FREQUENCY Up to 11 frequencies in MHz METHOD Prediction method (30 = complete system performance)"},{"location":"tools/voacapl/#output-fields","title":"Output Fields","text":"<p>VOACAP produces hourly predictions. Fields used for IONIS comparison:</p> Field Description MUF Maximum usable frequency for the path MUFday Fraction of days the MUF supports the frequency SNR Signal-to-noise ratio (dB) REL Circuit reliability (fraction of days the link works) S DBW Signal power at receiver (dBW) LOSS Total path loss (dB) MODE Propagation mode (F2F2, E, etc.)"},{"location":"tools/voacapl/#ionis-vs-voacap-comparison","title":"IONIS vs VOACAP Comparison","text":"<p>Both systems predict whether an HF path is open for a given band, time, and solar condition. The comparison methodology:</p> <ol> <li>Load the 1M contest QSO paths from <code>validation.step_i_paths</code> (ClickHouse)</li> <li>Group by unique circuit (TX, RX, freq, year, month, SSN) \u2014 ~965K circuits</li> <li>Generate VOACAP input cards (one per circuit, all 24 hours)</li> <li>Run <code>voacapl</code> in parallel (32 workers, each with its own <code>itshfbc/</code> copy)</li> <li>Parse SNR/REL/MUFday from Method 30 output</li> <li>Apply mode thresholds: DG/CW = -22 dB, RY/PH = -21 dB</li> <li>INSERT results into <code>validation.step_i_voacap</code> (ClickHouse)</li> <li>Compare: <code>SELECT ... FROM step_i_paths p JOIN step_i_voacap v USING (...)</code></li> </ol>"},{"location":"tools/voacapl/#batch-runner","title":"Batch Runner","text":"<p>The script <code>voacap_batch_runner.py</code> automates the full VOACAP validation run.</p> <p>Location: <code>ionis-training/scripts/voacap_batch_runner.py</code></p> <p>Prerequisites:</p> <ul> <li><code>voacapl</code> installed at <code>/usr/local/bin/voacapl</code></li> <li><code>~/itshfbc/</code> initialized via <code>makeitshfbc</code></li> <li><code>validation.step_i_paths</code> loaded in ClickHouse (1M rows)</li> <li><code>validation.step_i_voacap</code> table created (DDL: <code>16-validation_step_i.sql</code>)</li> </ul> <p>Run a small test (1000 rows, dry run):</p> <pre><code>python3 voacap_batch_runner.py --sample 1000 --workers 8 --dry-run\n</code></pre> <p>Full 1M run (32 workers):</p> <pre><code>python3 voacap_batch_runner.py --workers 32\n</code></pre> <p>Options:</p> <pre><code>  --workers N    Parallel workers (default: 32)\n  --host HOST    ClickHouse host (default: localhost)\n  --port PORT    ClickHouse native port (default: 9000)\n  --sample N     Process only N rows (0 = all)\n  --dry-run      Skip ClickHouse INSERT\n  --work-dir DIR Worker directory base (default: /tmp/voacap_work)\n</code></pre> <p>How parallelization works:</p> <p>Each worker gets its own <code>itshfbc/</code> directory tree. Large read-only directories (<code>coeffs/</code>, <code>antennas/</code>) are symlinked; writable directories (<code>run/</code>, <code>database/</code>) are copied. Each worker writes its input card to <code>run/voacapx.dat</code>, invokes <code>voacapl</code>, and parses <code>run/voacapx.out</code> independently. On the 9975WX (32C/64T), this achieves ~370 circuits/sec \u2014 the full 965K circuits complete in ~43 minutes.</p>"},{"location":"tools/voacapl/#limitations","title":"Limitations","text":"<ul> <li>VOACAP predicts for a monthly median SSN, not a specific date \u2014 daily   variability is not captured</li> <li>Antenna models affect absolute signal levels but not band-open/closed decisions</li> <li>The original algorithms date to the 1980s and do not account for modern   understanding of sporadic-E or grey line propagation</li> <li>Path length limit: ~52 characters for the <code>itshfbc</code> directory path (DOS legacy)</li> </ul>"},{"location":"tools/voacapl/#references","title":"References","text":"<ul> <li>voacapl GitHub \u2014 source code and releases</li> <li>VOACAP Quick Guide \u2014 online VOACAP interface by OH6BG</li> <li>voacapl Wiki \u2014 input card documentation</li> </ul>"},{"location":"tools/wspr/","title":"WSPR Ingestion Apps","text":"<p>Four Go binaries for downloading and ingesting WSPR spot data into ClickHouse.</p>"},{"location":"tools/wspr/#wspr-turbo","title":"wspr-turbo","text":"<p>The primary ingestion engine. Streams tar.gz/csv.gz archives directly into ClickHouse using zero-copy decompression and double-buffered native blocks \u2014 no intermediate disk I/O. Part of <code>ionis-apps</code> (Go binary).</p> <pre><code>wspr-turbo v3.0.5 - Zero-Copy Streaming Pipeline\n\nUsage: wspr-turbo [OPTIONS] [archives...]\n\nStreams tar.gz/csv.gz directly to ClickHouse Native Blocks.\nNo intermediate disk I/O - bypasses the 'File Penalty'.\n\nUses wspr.ingest_log watermark table for incremental loading.\nDetects cumulative monthly archive growth by comparing file sizes.\n\nArchitecture:\n  - Stream decompression (klauspost/gzip, ASM-optimized)\n  - Vectorized CSV parsing (columnar buffers)\n  - Double-buffering (fill while sending)\n  - sync.Pool (zero allocation after warmup)\n  - ch-go native protocol with LZ4\n\n  -block-size int\n        Rows per native block (default 1000000)\n  -ch-db string\n        ClickHouse database (default \"wspr\")\n  -ch-host string\n        ClickHouse address (default \"127.0.0.1:9000\")\n  -ch-table string\n        ClickHouse table (default \"bronze\")\n  -dry-run\n        List files that would be processed, then exit\n  -full\n        Full reload: drop monthly partitions and re-ingest all archives\n  -prime\n        Bootstrap watermark for existing archives (no data loaded)\n  -report-dir string\n        Report output directory (default \"/mnt/ai-stack/wspr-data/reports-turbo\")\n  -source-dir string\n        Archive source directory (default \"/scratch/ai-stack/wspr-data/archives\")\n  -workers int\n        Parallel archive workers (default 16)\n</code></pre>"},{"location":"tools/wspr/#wspr-shredder","title":"wspr-shredder","text":"<p>Maximum throughput ingester for uncompressed CSV files. Uses 1 MB read buffers and zero-allocation CSV parsing to saturate PCIe 5.0 lanes. Part of <code>ionis-apps</code> (Go binary).</p> <pre><code>wspr-shredder v3.0.2 - Maximum Throughput WSPR Ingester\n\nUsage: wspr-shredder [OPTIONS] [path|files...]\n\nIf no paths specified, uses -source-dir default.\n\nOptimizations:\n  - ch-go native protocol (fastest ClickHouse client)\n  - 1MB read buffers (bufio.NewReaderSize)\n  - csv.Reader with ReuseRecord (zero-allocation)\n  - Per-file workers to saturate PCIe 5.0 lanes\n\n  -ch-db string\n        ClickHouse database (default \"wspr\")\n  -ch-host string\n        ClickHouse address (default \"127.0.0.1:9000\")\n  -ch-table string\n        ClickHouse table (default \"bronze\")\n  -report-dir string\n        Report output directory (default \"/mnt/ai-stack/wspr-data/reports-shredder\")\n  -source-dir string\n        Default CSV source directory (default \"/scratch/ai-stack/wspr-data/csv\")\n  -workers int\n        Number of parallel file workers (default 16)\n</code></pre>"},{"location":"tools/wspr/#wspr-parquet-native","title":"wspr-parquet-native","text":"<p>Native Go Parquet reader for ingesting Parquet-format WSPR data. Avoids ClickHouse <code>file()</code> function restrictions by reading client-side with <code>parquet-go</code>. Part of <code>ionis-apps</code> (Go binary).</p> <pre><code>wspr-parquet-native v3.0.2 - Native Go Parquet Ingester\n\nUsage: wspr-parquet-native [OPTIONS] [path|files...]\n\nIf no paths specified, uses -source-dir default.\n\nFeatures:\n  - Native Go Parquet reading (parquet-go)\n  - ch-go native protocol with LZ4\n  - No ClickHouse file() restrictions\n  - Parallel file processing\n\n  -ch-db string\n        ClickHouse database (default \"wspr\")\n  -ch-host string\n        ClickHouse address (default \"127.0.0.1:9000\")\n  -ch-table string\n        ClickHouse table (default \"bronze\")\n  -report-dir string\n        Report output directory (default \"/mnt/ai-stack/wspr-data/reports-parquet-native\")\n  -source-dir string\n        Default Parquet source directory (default \"/scratch/ai-stack/wspr-data/parquet\")\n  -workers int\n        Number of parallel file workers (default 8)\n</code></pre>"},{"location":"tools/wspr/#wspr-download","title":"wspr-download","text":"<p>Parallel archive downloader for WSPR spot data from wsprnet.org. Uses ETag validation to detect updated files and supports configurable rate limiting. Part of <code>ionis-apps</code> (Go binary).</p> <pre><code>wspr-download v3.0.2 \u2014 WSPR Archive Downloader\n\nUsage: wspr-download [flags]\n\nDownloads WSPR spot archives from wsprnet.org.\nArchives are monthly .csv.gz files (~200MB-1GB each).\nUses ETag validation to detect updated files (e.g. end-of-month finalization).\nGood neighbor: configurable workers/delay, resume-friendly.\n\n  -delay duration\n        Delay between HTTP requests per worker (default 1s)\n  -dest string\n        Destination directory (default \"/mnt/wspr-data\")\n  -end string\n        End date (YYYY-MM, default: current month)\n  -force\n        Re-download all files regardless of ETag\n  -list\n        List files without downloading\n  -start string\n        Start date (YYYY-MM) (default \"2008-03\")\n  -timeout duration\n        HTTP timeout per download (default 5m0s)\n  -workers int\n        Parallel download workers (default 4)\n\nData source: https://wsprnet.org/archive\nArchive range: 2008-03 to present (~200 files)\n\nExamples:\n  wspr-download                              # Download all, skip unchanged\n  wspr-download --start 2024-01 --end 2024-12  # Download 2024 only\n  wspr-download --list                        # List files without downloading\n  wspr-download --workers 2 --delay 3s        # Be extra polite\n  wspr-download --force                       # Re-download everything\n</code></pre>"},{"location":"userguide/","title":"Getting Started","text":""},{"location":"userguide/#what-ionis-predicts","title":"What IONIS Predicts","text":"<p>IONIS (Ionospheric Neural Inference System) predicts HF radio signal-to-noise ratio (SNR) for any transmitter-receiver path given geographic coordinates, frequency, time of day, and solar conditions.</p> <p>The model learns from 14B+ real-world amateur radio observations \u2014 WSPR beacons, Reverse Beacon Network spots, contest QSOs, and PSK Reporter \u2014 combined with solar flux and geomagnetic indices. Unlike traditional tools such as VOACAP, IONIS captures empirical propagation patterns directly from observed data.</p> <p>Key metrics (V22-gamma + PhysicsOverrideLayer):</p> Metric IONIS V22-gamma VOACAP Pearson correlation +0.492 +0.0218 KI7MT operator tests 17/17 \u2014 TST-900 band x time 9/11 \u2014 RMSE 0.821\u03c3 \u2014"},{"location":"userguide/#installation","title":"Installation","text":"<p>IONIS packages are available from the COPR repository for Rocky Linux 9 / RHEL 9 / Fedora.</p>"},{"location":"userguide/#enable-the-copr-repository","title":"Enable the COPR Repository","text":"<pre><code>sudo dnf copr enable ki7mt/ionis-ai\n</code></pre>"},{"location":"userguide/#install-packages","title":"Install Packages","text":"<pre><code># Core schemas and configuration\nsudo dnf install ionis-core\n\n# Pipeline apps (ingesters, downloaders, validators)\nsudo dnf install ionis-apps\n\n# CUDA embedding engine (requires NVIDIA GPU)\nsudo dnf install ionis-cuda\n</code></pre>"},{"location":"userguide/#verify-installation","title":"Verify Installation","text":"<pre><code># Load environment variables\nsource ionis-env\n\n# Check ClickHouse connectivity\nclickhouse-client --query \"SELECT 1\"\n\n# List installed DDL files\nls /usr/share/ionis-core/ddl/\n</code></pre>"},{"location":"userguide/#quick-start","title":"Quick Start","text":"<p>After installing the RPMs and setting up ClickHouse:</p> <pre><code># 1. Source the environment\nsource ionis-env\n\n# 2. Apply database schemas\nfor f in /usr/share/ionis-core/ddl/*.sql; do\n    clickhouse-client --multiquery &lt; \"$f\"\ndone\n\n# 3. Verify tables exist\nclickhouse-client --query \"SHOW TABLES FROM wspr\"\nclickhouse-client --query \"SHOW TABLES FROM solar\"\n\n# 4. Check table counts (after data is loaded)\ndb-validate --all\n</code></pre>"},{"location":"userguide/#whats-next","title":"What's Next","text":"<ul> <li>Full pipeline setup: See the Pipeline Runbook   for step-by-step instructions from clean slate to training-ready</li> <li>Hardware planning: See Hardware Requirements for   minimum specs and the reference build</li> <li>Running predictions: See Running Predictions for   using the trained model</li> <li>Operations: See Operations &amp; Maintenance for   cron jobs and health checks</li> </ul>"},{"location":"userguide/predictions/","title":"Running Predictions","text":"<p>IONIS provides two prediction interfaces: <code>predict.py</code> for single-path queries and version-specific oracle/validation scripts for batch evaluation.</p>"},{"location":"userguide/predictions/#single-path-prediction","title":"Single-Path Prediction","text":"<p>The unified predictor combines the neural oracle with a historical signature search, weighting results by signature density.</p>"},{"location":"userguide/predictions/#basic-usage","title":"Basic Usage","text":"<pre><code>cd ionis-training/scripts\n\npython predict.py \\\n    --tx FN31 --rx JO21 \\\n    --band 20m \\\n    --hour 14 --month 6\n</code></pre>"},{"location":"userguide/predictions/#with-solar-conditions","title":"With Solar Conditions","text":"<pre><code>python predict.py \\\n    --tx FN31 --rx JO21 \\\n    --band 20m \\\n    --hour 14 --month 6 \\\n    --sfi 180 --kp 3\n</code></pre> <p>Defaults: SFI 150, Kp 2 (moderate solar activity, quiet geomagnetic).</p>"},{"location":"userguide/predictions/#json-output","title":"JSON Output","text":"<pre><code>python predict.py \\\n    --tx FN31 --rx JO21 \\\n    --band 20m --hour 14 --month 6 \\\n    --json\n</code></pre>"},{"location":"userguide/predictions/#parameters","title":"Parameters","text":"Parameter Required Description Example <code>--tx</code> Yes Transmitter grid (4-char Maidenhead) <code>FN31</code> <code>--rx</code> Yes Receiver grid (4-char Maidenhead) <code>JO21</code> <code>--band</code> Yes Band label or ADIF ID <code>20m</code> or <code>107</code> <code>--hour</code> Yes UTC hour (0-23) <code>14</code> <code>--month</code> Yes Month (1-12) <code>6</code> <code>--sfi</code> No Solar Flux Index (default 150) <code>180</code> <code>--kp</code> No Kp geomagnetic index (default 2) <code>3</code> <code>--host</code> No ClickHouse host (default <code>10.60.1.1</code>) <code>192.168.1.90</code>"},{"location":"userguide/predictions/#interpreting-output","title":"Interpreting Output","text":"<p>The predictor returns three assessments:</p> <ol> <li>Neural Oracle \u2014 model prediction in sigma-normalized units, converted    to dB</li> <li>Signature Search \u2014 median SNR from the nearest historical signatures    in ClickHouse</li> <li>Combined \u2014 confidence-weighted blend of both</li> </ol> <p>Confidence weighting:</p> Signature Density Oracle Weight Signature Weight HIGH (dense) 30% 70% MEDIUM 50% 50% LOW (sparse) 70% 30% None found 100% \u2014 <p>Condition labels (based on combined SNR in dB):</p> SNR Threshold Condition Typical Modes &gt; -10 dB EXCELLENT SSB, Voice &gt; -15 dB GOOD CW, Digital &gt; -20 dB FAIR FT8, FT4 &gt; -28 dB MARGINAL WSPR &lt;= -28 dB CLOSED \u2014"},{"location":"userguide/predictions/#batch-validation","title":"Batch Validation","text":"<p>Version-specific oracle scripts evaluate the model against ground-truth signatures from ClickHouse.</p>"},{"location":"userguide/predictions/#standalone-validation-ionis-validate","title":"Standalone Validation (ionis-validate)","text":"<p>The easiest way to validate is with the <code>ionis-validate</code> CLI (no ClickHouse required):</p> <pre><code>pip install ionis-validate\nionis-validate test\n</code></pre> <p>This runs 29 operator-grounded tests: KI7MT 18/18 + TST-900 9/11.</p>"},{"location":"userguide/predictions/#key-metrics","title":"Key Metrics","text":"Metric Description V22-gamma Result Pearson r Correlation between predicted and observed SNR +0.492 RMSE Root mean squared error in sigma units 0.821\u03c3 KI7MT operator tests Operator-grounded physics gates 17/17 TST-900 band x time Band discrimination across time periods 9/11"},{"location":"userguide/predictions/#training-a-new-model-version","title":"Training a New Model Version","text":"<p>Training is covered in detail in the Training Methodology page. At a high level:</p> <ol> <li>Export training data: <code>gold_v6.csv</code> from ClickHouse (see Gold Layer)</li> <li>Transfer to training host (M3 Ultra via DAC link)</li> <li>Create a new version config: <code>versions/vNN/config_vNN.json</code></li> <li>Run training: <code>python train.py --config versions/vNN/config_vNN.json</code></li> <li>Validate: run <code>validate_vNN.py</code> against quality test paths</li> </ol> <p>The model architecture (IonisGate) and its six non-negotiable constraints are documented in the IonisGate Architecture page.</p>"}]}